{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"api/","text":"Cirrus CI API \u00b6 Cirrus CI exposes GraphQL API for integrators to use through https://api.cirrus-ci.com/graphql endpoint. Please check Cirrus CI GraphQL Schema for a full list of available types and methods. Or check built-in interactive GraphQL Explorer . Here is an example of how to get a build for a particular SHA of a given repository: curl -X POST --data \\ '{ \"query\": \"query BuildBySHAQuery($owner: String!, $name: String!, $SHA: String) { searchBuilds(repositoryOwner: $owner, repositoryName: $name, SHA: $SHA) { id } }\", \"variables\": { \"owner\": \"ORGANIZATION\", \"name\": \"REPOSITORY NAME\", \"SHA\": \"SOME SHA\" } }' \\ https://api.cirrus-ci.com/graphql | python -m json.tool Authorization \u00b6 In order for a tool to access Cirrus CI API, an organization admin should generate an access token through Cirrus CI Settings page for a corresponding organization. Here is a direct link to the settings page: https://cirrus-ci.com/settings/github/<ORGANIZATION> . Access tokens will allow full write and read access to both public and private repositories of your organization on Cirrus CI: it will be possible to create new builds and perform any other GraphQL mutations. If you only need read access to public repositories of your organization you can skip this step and don't provide Authorization header. Once an access token is generated and securely stored, it can be used to authorize API requests by setting Authorization header to Bearer $TOKEN . User API Token Permission Scope It is also possible to generate API tokens for personal accounts but they will be scoped only to access personal public and private repositories of a particular user. It won't be possible to access private repositories of an organization, even if they have access. WebHooks \u00b6 It is possible to subscribe for updates of builds and tasks. If a WebHook URL is configured on Cirrus CI Settings page for an organization, Cirrus CI will try to POST a webhook event payload to this URL. POST request will contain X-Cirrus-Event header to specify if the update was made to a build or a task . The event payload itself is pretty basic: { \"action\" : \"created\" | \"updated\" , \"data\" : ... } data field will be populated by executing the following GraphQL query: repository(id: $repositoryId) { id owner name isPrivate } build(id: $buildId) { id branch pullRequest changeIdInRepo changeTimestamp status } task(id: $taskId) { id name status statusTimestamp creationTimestamp uniqueLabels automaticReRun automaticallyReRunnable } Custom GraphQL Query If you'd like to customize GraphQL query which will be executed and included in the event payload please contact support for further details. Securing WebHooks \u00b6 Imagine you've been given a https://example.com/webhook endpoint by your administrator, and for some reason there's no easy way to change that. This kind of URL is easily discoverable on the internet, and an attacker can take advantage of this by sending requests to this URL, thus pretending to be the Cirrus CI. To avoid such situations, set the secret token in the repository settings, and then validate the X-Cirrus-Signature for each WebHook request. Once configured, the secret token and the request's body are fed into the HMAC algorithm to generate the X-Cirrus-Signature for each request coming from the Cirrus CI. Missing X-Cirrus-Signature header When secret token is configured in the repository settings, all WebHook requests will contain the X-Cirrus-Signature-Header . Make sure to assert the presence of X-Cirrus-Signature-Header header and correctness of its value in your validation code. Using HMAC is pretty straightforward in many languages, here's an example of how to validate the X-Cirrus-Signature using Python's hmac module : import hmac def is_signature_valid ( secret_token : bytes , body : bytes , x_cirrus_signature : str ) -> bool : expected_signature = hmac . new ( secret_token , body , \"sha256\" ) . hexdigest () return hmac . compare_digest ( expected_signature , x_cirrus_signature )","title":"API"},{"location":"api/#cirrus-ci-api","text":"Cirrus CI exposes GraphQL API for integrators to use through https://api.cirrus-ci.com/graphql endpoint. Please check Cirrus CI GraphQL Schema for a full list of available types and methods. Or check built-in interactive GraphQL Explorer . Here is an example of how to get a build for a particular SHA of a given repository: curl -X POST --data \\ '{ \"query\": \"query BuildBySHAQuery($owner: String!, $name: String!, $SHA: String) { searchBuilds(repositoryOwner: $owner, repositoryName: $name, SHA: $SHA) { id } }\", \"variables\": { \"owner\": \"ORGANIZATION\", \"name\": \"REPOSITORY NAME\", \"SHA\": \"SOME SHA\" } }' \\ https://api.cirrus-ci.com/graphql | python -m json.tool","title":"Cirrus CI API"},{"location":"api/#authorization","text":"In order for a tool to access Cirrus CI API, an organization admin should generate an access token through Cirrus CI Settings page for a corresponding organization. Here is a direct link to the settings page: https://cirrus-ci.com/settings/github/<ORGANIZATION> . Access tokens will allow full write and read access to both public and private repositories of your organization on Cirrus CI: it will be possible to create new builds and perform any other GraphQL mutations. If you only need read access to public repositories of your organization you can skip this step and don't provide Authorization header. Once an access token is generated and securely stored, it can be used to authorize API requests by setting Authorization header to Bearer $TOKEN . User API Token Permission Scope It is also possible to generate API tokens for personal accounts but they will be scoped only to access personal public and private repositories of a particular user. It won't be possible to access private repositories of an organization, even if they have access.","title":"Authorization"},{"location":"api/#webhooks","text":"It is possible to subscribe for updates of builds and tasks. If a WebHook URL is configured on Cirrus CI Settings page for an organization, Cirrus CI will try to POST a webhook event payload to this URL. POST request will contain X-Cirrus-Event header to specify if the update was made to a build or a task . The event payload itself is pretty basic: { \"action\" : \"created\" | \"updated\" , \"data\" : ... } data field will be populated by executing the following GraphQL query: repository(id: $repositoryId) { id owner name isPrivate } build(id: $buildId) { id branch pullRequest changeIdInRepo changeTimestamp status } task(id: $taskId) { id name status statusTimestamp creationTimestamp uniqueLabels automaticReRun automaticallyReRunnable } Custom GraphQL Query If you'd like to customize GraphQL query which will be executed and included in the event payload please contact support for further details.","title":"WebHooks"},{"location":"api/#securing-webhooks","text":"Imagine you've been given a https://example.com/webhook endpoint by your administrator, and for some reason there's no easy way to change that. This kind of URL is easily discoverable on the internet, and an attacker can take advantage of this by sending requests to this URL, thus pretending to be the Cirrus CI. To avoid such situations, set the secret token in the repository settings, and then validate the X-Cirrus-Signature for each WebHook request. Once configured, the secret token and the request's body are fed into the HMAC algorithm to generate the X-Cirrus-Signature for each request coming from the Cirrus CI. Missing X-Cirrus-Signature header When secret token is configured in the repository settings, all WebHook requests will contain the X-Cirrus-Signature-Header . Make sure to assert the presence of X-Cirrus-Signature-Header header and correctness of its value in your validation code. Using HMAC is pretty straightforward in many languages, here's an example of how to validate the X-Cirrus-Signature using Python's hmac module : import hmac def is_signature_valid ( secret_token : bytes , body : bytes , x_cirrus_signature : str ) -> bool : expected_signature = hmac . new ( secret_token , body , \"sha256\" ) . hexdigest () return hmac . compare_digest ( expected_signature , x_cirrus_signature )","title":"Securing WebHooks"},{"location":"examples/","text":"Examples \u00b6 Here you can find example configurations per different programming languages/frameworks. Android \u00b6 Cirrus CI has a set of Docker images ready for Android development . If these images are not the right fit for your project you can always use any custom Docker image with Cirrus CI. For those images .cirrus.yml configuration file can look like: container : image : cirrusci/android-sdk:29 check_android_task : check_script : ./gradlew check connectedCheck Or like this if a running emulator is needed for the tests: container : image : cirrusci/android-sdk:29 cpu : 4 memory : 10G check_android_task : create_device_script : echo no | avdmanager create avd --force -n test -k \"system-images;android-29;default;armeabi-v7a\" start_emulator_background_script : $ANDROID_HOME/emulator/emulator -avd test -no-audio -no-window wait_for_emulator_script : - adb wait-for-device - adb shell input keyevent 82 check_script : ./gradlew check connectedCheck Info Please don't forget to setup Remote Build Cache for your Gradle project. Or at least basic folder caching . Android Lint \u00b6 The Cirrus CI annotator supports providing inline reports on PRs and can parse Android Lint reports. Here is an example of an Android Lint task that you can add to your .cirrus.yml : task : name : Android Lint lint_script : ./gradlew lintDebug always : android-lint_artifacts : path : \"**/reports/lint-results-debug.xml\" type : text/xml format : android-lint Bazel \u00b6 Bazel Team provides a set of official Docker images with Bazel pre-installed . Here is an example of how .cirrus.yml can look like for Bazel: amd64 container : image : l.gcr.io/google/bazel:latest task : build_script : bazel build //... arm64 arm_container : image : l.gcr.io/google/bazel:latest task : build_script : bazel build //... If these images are not the right fit for your project you can always use any custom Docker image with Cirrus CI. Remote Cache \u00b6 Cirrus CI has built-in HTTP Cache which is compatible with Bazel's remote cache . Here is an example of how Cirrus CI HTTP Cache can be used with Bazel: amd64 container : image : l.gcr.io/google/bazel:latest task : build_script : bazel build --spawn_strategy=sandboxed --strategy=Javac=sandboxed --genrule_strategy=sandboxed --remote_http_cache=http://$CIRRUS_HTTP_CACHE_HOST //... arm64 arm_container : image : l.gcr.io/google/bazel:latest task : build_script : bazel build --spawn_strategy=sandboxed --strategy=Javac=sandboxed --genrule_strategy=sandboxed --remote_http_cache=http://$CIRRUS_HTTP_CACHE_HOST //... C++ \u00b6 Official GCC Docker images can be used for builds. Here is an example of a .cirrus.yml that runs tests: amd64 container : image : gcc:latest task : tests_script : make tests arm64 arm_container : image : gcc:latest task : tests_script : make tests Crystal \u00b6 Official Crystal Docker images can be used for builds. Here is an example of a .cirrus.yml that caches dependencies and runs tests: container : image : crystallang/crystal:latest spec_task : shard_cache : fingerprint_script : cat shard.lock populate_script : shards install folder : lib spec_script : crystal spec Elixir \u00b6 Official Elixir Docker images can be used for builds. Here is an example of a .cirrus.yml that runs tests: amd64 test_task : container : image : elixir:latest mix_cache : folder : deps fingerprint_script : cat mix.lock populate_script : mix deps.get compile_script : mix compile test_script : mix test arm64 test_task : arm_container : image : elixir:latest mix_cache : folder : deps fingerprint_script : cat mix.lock populate_script : mix deps.get compile_script : mix compile test_script : mix test Erlang \u00b6 Official Erlang Docker images can be used for builds. Here is an example of a .cirrus.yml that runs tests: amd64 test_task : container : image : erlang:latest rebar3_cache : folder : _build fingerprint_script : cat rebar.lock populate_script : rebar3 compile --deps_only compile_script : rebar3 compile test_script : rebar3 ct arm64 test_task : arm_container : image : erlang:latest rebar3_cache : folder : _build fingerprint_script : cat rebar.lock populate_script : rebar3 compile --deps_only compile_script : rebar3 compile test_script : rebar3 ct Flutter \u00b6 Cirrus CI provides a set of Docker images with Flutter and Dart SDK pre-installed . Here is an example of how .cirrus.yml can be written for Flutter: container : image : cirrusci/flutter:latest test_task : pub_cache : folder : ~/.pub-cache test_script : flutter test -machine > report.json always : report_artifacts : path : report.json format : flutter If these images are not the right fit for your project you can always use any custom Docker image with Cirrus CI. Flutter Web \u00b6 Our Docker images with Flutter and Dart SDK pre-installed have special *-web tags with Chromium pre-installed. You can use these tags to run Flutter Web First define a new chromium platform in your dart_test.yaml : define_platforms : chromium : name : Chromium extends : chrome settings : arguments : --no-sandbox executable : linux : chromium Now you'll be able to run tests targeting web via pub run test test -p chromium Go \u00b6 The best way to test Go projects is by using official Go Docker images . Here is an example of how .cirrus.yml can look like for a project using Go Modules: amd64 container : image : golang:latest test_task : modules_cache : fingerprint_script : cat go.sum folder : $GOPATH/pkg/mod get_script : go get ./... build_script : go build ./... test_script : go test ./... arm64 arm_container : image : golang:latest test_task : modules_cache : fingerprint_script : cat go.sum folder : $GOPATH/pkg/mod get_script : go get ./... build_script : go build ./... test_script : go test ./... GolangCI Lint \u00b6 We highly recommend to configure some sort of linting for your Go project. One of the options is GolangCI Lint . The Cirrus CI annotator supports providing inline reports on PRs and can parse GolangCI Lint reports. Here is an example of a GolangCI Lint task that you can add to your .cirrus.yml : amd64 task : name : GolangCI Lint container : image : golangci/golangci-lint:latest run_script : golangci-lint run -v --out-format json > lint-report.json always : golangci_artifacts : path : lint-report.json type : text/json format : golangci arm64 task : name : GolangCI Lint arm_container : image : golangci/golangci-lint:latest run_script : golangci-lint run -v --out-format json > lint-report.json always : golangci_artifacts : path : lint-report.json type : text/json format : golangci Gradle \u00b6 We recommend use of the official Gradle Docker containers since they have Gradle specific configurations already set up. For example, standard Java containers don't have a pre-configured user and as a result don't have HOME environment variable presented which makes Gradle complain. Caching \u00b6 To preserve caches between Gradle runs, add a cache instruction as shown below. The trick here is to clean up ~/.gradle/caches folder in the very end of a build. Gradle creates some unique nondeterministic files in ~/.gradle/caches folder on every run which makes Cirrus CI re-upload the cache every time . This way, you get faster builds! amd64 container : image : gradle:jdk11 check_task : gradle_cache : folder : ~/.gradle/caches check_script : gradle check cleanup_before_cache_script : - rm -rf ~/.gradle/caches/$GRADLE_VERSION/ - rm -rf ~/.gradle/caches/transforms-1 - rm -rf ~/.gradle/caches/journal-1 - rm -rf ~/.gradle/caches/jars-3/*/buildSrc.jar - find ~/.gradle/caches/ -name \"*.lock\" -type f -delete arm64 arm_container : image : gradle:jdk11 check_task : gradle_cache : folder : ~/.gradle/caches check_script : gradle check cleanup_before_cache_script : - rm -rf ~/.gradle/caches/$GRADLE_VERSION/ - rm -rf ~/.gradle/caches/transforms-1 - rm -rf ~/.gradle/caches/journal-1 - rm -rf ~/.gradle/caches/jars-3/*/buildSrc.jar - find ~/.gradle/caches/ -name \"*.lock\" -type f -delete Build Cache \u00b6 Here is how HTTP Cache can be used with Gradle by adding the following code to settings.gradle : ext . isCiServer = System . getenv (). containsKey ( \"CIRRUS_CI\" ) ext . isMasterBranch = System . getenv ()[ \"CIRRUS_BRANCH\" ] == \"master\" ext . buildCacheHost = System . getenv (). getOrDefault ( \"CIRRUS_HTTP_CACHE_HOST\" , \"localhost:12321\" ) buildCache { local { enabled = ! isCiServer } remote ( HttpBuildCache ) { url = \"http://${buildCacheHost}/\" enabled = isCiServer push = isMasterBranch } } If your project uses a buildSrc directory, the build cache configuration should also be applied to buildSrc/settings.gradle . To do this, put the build cache configuration above into a separate gradle/buildCacheSettings.gradle file, then apply it to both your settings.gradle and buildSrc/settings.gradle . In settings.gradle : apply from: new File ( settingsDir , 'gradle/buildCacheSettings.gradle' ) In buildSrc/settings.gradle : apply from: new File ( settingsDir , '../gradle/buildCacheSettings.gradle' ) Please make sure you are running Gradle commands with --build-cache flag or have org.gradle.caching enabled in gradle.properties file. Here is an example of a gradle.properties file that we use internally for all Gradle projects: org.gradle.daemon = true org.gradle.caching = true org.gradle.parallel = true org.gradle.configureondemand = true org.gradle.jvmargs = -Dfile.encoding=UTF-8 JUnit \u00b6 Here is a .cirrus.yml that, parses and uploads JUnit reports at the end of the build: junit_test_task : junit_script : <replace this comment with instructions to run the test suites> always : junit_result_artifacts : path : \"**/test-results/**.xml\" format : junit type : text/xml If it is running on a pull request, annotations will also be displayed in-line. Maven \u00b6 Official Maven Docker images can be used for building and testing Maven projects: amd64 container : image : maven:latest task : name : Cirrus CI maven_cache : folder : ~/.m2 test_script : mvn test -B arm64 arm_container : image : maven:latest task : name : Cirrus CI maven_cache : folder : ~/.m2 test_script : mvn test -B MySQL \u00b6 The Additional Containers feature makes it super simple to run the same Docker MySQL image as you might be running in production for your application. Getting a running instance of the latest GA version of MySQL can used with the following six lines in your .cirrus.yml : amd64 container : image : golang:latest additional_containers : - name : mysql image : mysql:latest port : 3306 env : MYSQL_ROOT_PASSWORD : \"\" arm64 arm_container : image : golang:latest additional_containers : - name : mysql image : mysql:latest port : 3306 env : MYSQL_ROOT_PASSWORD : \"\" With the configuration above MySQL will be available on localhost:3306 . Use empty password to login as root user. Node \u00b6 Official NodeJS Docker images can be used for building and testing Node.JS applications. npm \u00b6 Here is an example of a .cirrus.yml that caches node_modules based on contents of package-lock.json file and runs tests: amd64 container : image : node:latest test_task : node_modules_cache : folder : node_modules fingerprint_script : cat package-lock.json populate_script : npm ci test_script : npm test arm64 arm_container : image : node:latest test_task : node_modules_cache : folder : node_modules fingerprint_script : cat package-lock.json populate_script : npm ci test_script : npm test Yarn \u00b6 Here is an example of a .cirrus.yml that caches node_modules based on the contents of a yarn.lock file and runs tests: amd64 container : image : node:latest test_task : node_modules_cache : folder : node_modules fingerprint_script : cat yarn.lock populate_script : yarn install test_script : yarn run test arm64 arm_container : image : node:latest test_task : node_modules_cache : folder : node_modules fingerprint_script : cat yarn.lock populate_script : yarn install test_script : yarn run test Yarn 2 \u00b6 Yarn 2 (also known as Yarn Berry), has a different package cache location ( .yarn/cache ). To run tests, it would look like this: amd64 container : image : node:latest test_task : yarn_cache : folder : .yarn/cache fingerprint_script : cat yarn.lock install_script : - yarn set version berry - yarn install test_script : yarn run test arm64 arm_container : image : node:latest test_task : yarn_cache : folder : .yarn/cache fingerprint_script : cat yarn.lock install_script : - yarn set version berry - yarn install test_script : yarn run test Python \u00b6 Official Python Docker images can be used for builds. Here is an example of a .cirrus.yml that caches installed packages based on contents of requirements.txt and runs pytest : amd64 container : image : python:slim test_task : pip_cache : folder : ~/.cache/pip fingerprint_script : echo $PYTHON_VERSION && cat requirements.txt populate_script : pip install -r requirements.txt test_script : pytest arm64 arm_container : image : python:slim test_task : pip_cache : folder : ~/.cache/pip fingerprint_script : echo $PYTHON_VERSION && cat requirements.txt populate_script : pip install -r requirements.txt test_script : pytest Building PyPI Packages \u00b6 Also using the Python Docker images, you can run tests if you are making packages for PyPI . Here is an example .cirrus.yml for doing so: amd64 container : image : python:slim build_package_test_task : pip_cache : folder : ~/.cache/pip fingerprint_script : echo $PYTHON_VERSION populate_script : python3 -m pip install --upgrade setuptools wheel build_package_test_script : python3 setup.py sdist bdist_wheel arm64 arm_container : image : python:slim build_package_test_task : pip_cache : folder : ~/.cache/pip fingerprint_script : echo $PYTHON_VERSION populate_script : python3 -m pip install --upgrade setuptools wheel build_package_test_script : python3 setup.py sdist bdist_wheel Linting \u00b6 You can easily set up linting with Cirrus CI and flake8, here is an example .cirrus.yml : amd64 lint_task : container : image : alpine/flake8:latest script : flake8 *.py arm64 lint_task : arm_container : image : alpine/flake8:latest script : flake8 *.py Unittest Annotations \u00b6 Python Unittest reports are supported by Cirrus CI Annotations . This way you can see what tests are failing without leaving the pull request you are reviewing! Here is an example of a .cirrus.yml that produces and stores Unittest reports: amd64 unittest_task : container : image : python:slim install_dependencies_script : | pip3 install unittest_xml_reporting run_tests_script : python3 -m xmlrunner tests # replace 'tests' with the module, # unittest.TestCase, or unittest.TestSuite # that the tests are in always : upload_results_artifacts : path : ./*.xml format : junit type : text/xml arm64 unittest_task : arm_container : image : python:slim install_dependencies_script : | pip3 install unittest_xml_reporting run_tests_script : python3 -m xmlrunner tests # replace 'tests' with the module, # unittest.TestCase, or unittest.TestSuite # that the tests are in always : upload_results_artifacts : path : ./*.xml format : junit type : text/xml Now you should get annotations for your test results. Qodana \u00b6 Qodana by JetBrains is a code quality monitoring tool that identifies and suggests fixes for bugs, security vulnerabilities, duplications, and imperfections. It brings all the smart features you love in the JetBrains IDEs. Here is an example of .cirrus.yml configuration file which will save Qodana's report as an artifact, will parse it and report as annotations : task : name : Qodana container : image : jetbrains/qodana:latest env : CIRRUS_WORKING_DIR : /data/project generate_report_script : - /opt/idea/bin/entrypoint --save-report --report-dir=report always : results_artifacts : path : \"report/results/result-allProblems.json\" format : qodana Release Assets \u00b6 Cirrus CI doesn't provide a built-in functionality to upload artifacts on a GitHub release but this functionality can be added via a script. For a release, Cirrus CI will provide CIRRUS_RELEASE environment variable along with CIRRUS_TAG environment variable. CIRRUS_RELEASE indicates release id which can be used to upload assets. Cirrus CI only requires write access to Check API and doesn't require write access to repository contents because of security reasons. That's why you need to create a personal access token with full access to repo scope. Once an access token is created, please create an encrypted variable from it and save it to .cirrus.yml : env : GITHUB_TOKEN : ENCRYPTED[qwerty] Now you can use a script to upload your assets: #!/usr/bin/env bash if [[ \" $CIRRUS_RELEASE \" == \"\" ]] ; then echo \"Not a release. No need to deploy!\" exit 0 fi if [[ \" $GITHUB_TOKEN \" == \"\" ]] ; then echo \"Please provide GitHub access token via GITHUB_TOKEN environment variable!\" exit 1 fi file_content_type = \"application/octet-stream\" files_to_upload =( # relative paths of assets to upload ) for fpath in $files_to_upload do echo \"Uploading $fpath ...\" name = $( basename \" $fpath \" ) url_to_upload = \"https://uploads.github.com/repos/ $CIRRUS_REPO_FULL_NAME /releases/ $CIRRUS_RELEASE /assets?name= $name \" curl -X POST \\ --data-binary @ $fpath \\ --header \"Authorization: token $GITHUB_TOKEN \" \\ --header \"Content-Type: $file_content_type \" \\ $url_to_upload done Ruby \u00b6 Official Ruby Docker images can be used for builds. Here is an example of a .cirrus.yml that caches installed gems based on Ruby version, contents of Gemfile.lock , and runs rspec : amd64 container : image : ruby:latest rspec_task : bundle_cache : folder : /usr/local/bundle fingerprint_script : - echo $RUBY_VERSION - cat Gemfile.lock populate_script : bundle install rspec_script : bundle exec rspec --format json --out rspec.json always : rspec_report_artifacts : path : rspec.json type : text/json format : rspec arm64 arm_container : image : ruby:latest rspec_task : bundle_cache : folder : /usr/local/bundle fingerprint_script : - echo $RUBY_VERSION - cat Gemfile.lock populate_script : bundle install rspec_script : bundle exec rspec --format json --out rspec.json always : rspec_report_artifacts : path : rspec.json type : text/json format : rspec Repositories without Gemfile.lock When you are not committing Gemfile.lock (in Ruby gems repositories, for example) you can run bundle install (or bundle update ) in install_script instead of populate_script in bundle_cache . Cirrus Agent is clever enough to re-upload cache entry only if cached folder has been changed during task execution. Here is an example of a .cirrus.yml that always runs bundle install : amd64 container : image : ruby:latest rspec_task : bundle_cache : folder : /usr/local/bundle fingerprint_script : - echo $RUBY_VERSION - cat Gemfile - cat *.gemspec install_script : bundle install # or `update` for the freshest bundle rspec_script : bundle exec rspec arm64 arm_container : image : ruby:latest rspec_task : bundle_cache : folder : /usr/local/bundle fingerprint_script : - echo $RUBY_VERSION - cat Gemfile - cat *.gemspec install_script : bundle install # or `update` for the freshest bundle rspec_script : bundle exec rspec Test Parallelization It's super easy to add intelligent test splitting by using Knapsack Pro and matrix modification . After setting up Knapsack Pro gem , you can add sharding like this: task : matrix : name : rspec (shard 1) name : rspec (shard 2) name : rspec (shard 3) name : rspec (shard 4) bundle_cache : folder : /usr/local/bundle fingerprint_script : cat Gemfile.lock populate_script : bundle install rspec_script : bundle exec rake knapsack_pro:rspec Which will create four shards that will theoretically run tests 4x faster by equally splitting all tests between these four shards. RSpec and RuboCop Annotations \u00b6 Cirrus CI natively supports RSpec and RuboCop machine-parsable JSON reports. To get behavior-driven test annotations, generate and upload a rspec artifact from your lint task: amd64 container : image : ruby:latest task : name : RSpec bundle_cache : folder : /usr/local/bundle fingerprint_script : - echo $RUBY_VERSION - cat Gemfile.lock populate_script : bundle install script : bundle exec rspec --format json --out rspec.json always : rspec_artifacts : path : rspec.json type : text/json format : rspec arm64 arm_container : image : ruby:latest task : name : RSpec bundle_cache : folder : /usr/local/bundle fingerprint_script : - echo $RUBY_VERSION - cat Gemfile.lock populate_script : bundle install script : bundle exec rspec --format json --out rspec.json always : rspec_artifacts : path : rspec.json type : text/json format : rspec Generate a rubocop artifact to quickly gain context for linter/formatter annotations: amd64 container : image : ruby:latest task : name : RuboCop bundle_cache : folder : /usr/local/bundle fingerprint_script : - echo $RUBY_VERSION - cat Gemfile.lock populate_script : bundle install script : bundle exec rubocop --format json --out rubocop.json always : rubocop_artifacts : path : rubocop.json type : text/json format : rubocop arm64 arm_container : image : ruby:latest task : name : RuboCop bundle_cache : folder : /usr/local/bundle fingerprint_script : - echo $RUBY_VERSION - cat Gemfile.lock populate_script : bundle install script : bundle exec rubocop --format json --out rubocop.json always : rubocop_artifacts : path : rubocop.json type : text/json format : rubocop Rust \u00b6 Official Rust Docker images can be used for builds. Here is a basic example of .cirrus.yml that caches crates in $CARGO_HOME based on contents of Cargo.lock : amd64 container : image : rust:latest test_task : registry_cache : folder : $CARGO_HOME/registry fingerprint_script : cat Cargo.lock target_cache : folder : target fingerprint_script : - rustc --version - cat Cargo.lock build_script : cargo build test_script : cargo test before_cache_script : rm -rf $CARGO_HOME/registry/index arm64 arm_container : image : rust:latest test_task : registry_cache : folder : $CARGO_HOME/registry fingerprint_script : cat Cargo.lock target_cache : folder : target fingerprint_script : - rustc --version - cat Cargo.lock build_script : cargo build test_script : cargo test before_cache_script : rm -rf $CARGO_HOME/registry/index Caching Cleanup Please note before_cache_script that removes registry index from the cache before uploading it in the end of a successful task. Registry index is changing very rapidly making the cache invalid. before_cache_script deletes the index and leaves only the required crates for caching. Rust Nightly \u00b6 It is possible to use nightly builds of Rust via an official rustlang/rust:nightly container . Here is an example of a .cirrus.yml to run tests against the latest stable and nightly versions of Rust: amd64 test_task : matrix : - container : image : rust:latest - allow_failures : true container : image : rustlang/rust:nightly registry_cache : folder : $CARGO_HOME/registry fingerprint_script : cat Cargo.lock target_cache : folder : target fingerprint_script : - rustc --version - cat Cargo.lock build_script : cargo build test_script : cargo test before_cache_script : rm -rf $CARGO_HOME/registry/index arm64 test_task : matrix : - arm_container : image : rust:latest - allow_failures : true arm_container : image : rustlang/rust:nightly registry_cache : folder : $CARGO_HOME/registry fingerprint_script : cat Cargo.lock target_cache : folder : target fingerprint_script : - rustc --version - cat Cargo.lock build_script : cargo build test_script : cargo test before_cache_script : rm -rf $CARGO_HOME/registry/index FreeBSD Caveats Vanila FreeBSD VMs don't set some environment variables required by Cargo for effective caching. Specifying HOME environment variable to some arbitrarily location should fix caching: freebsd_instance : image-family : freebsd-12-0 task : name : cargo test (stable) env : HOME : /tmp # cargo needs it install_script : pkg install -y rust cargo_cache : folder : $HOME/.cargo/registry fingerprint_script : cat Cargo.lock build_script : cargo build --all test_script : cargo test --all --all-targets before_cache_script : rm -rf $HOME/.cargo/registry/index XCLogParser \u00b6 XCLogParser is a CLI tool that parses Xcode and xcodebuild 's logs ( xcactivitylog files) and produces reports in different formats. Here is an example of .cirrus.yml configuration file which will save XCLogParser's flat JSON report as an artifact, will parse it and report as annotations : macos_instance : image : big-sur-xcode task : name : XCLogParser build_script : - xcodebuild -scheme noapp -derivedDataPath ~/dd always : xclogparser_parse_script : - brew install xclogparser - xclogparser parse --project noapp --reporter flatJson --output xclogparser.json --derived_data ~/dd xclogparser_upload_artifacts : path : \"xclogparser.json\" type : text/json format : xclogparser","title":"Examples"},{"location":"examples/#examples","text":"Here you can find example configurations per different programming languages/frameworks.","title":"Examples"},{"location":"examples/#android","text":"Cirrus CI has a set of Docker images ready for Android development . If these images are not the right fit for your project you can always use any custom Docker image with Cirrus CI. For those images .cirrus.yml configuration file can look like: container : image : cirrusci/android-sdk:29 check_android_task : check_script : ./gradlew check connectedCheck Or like this if a running emulator is needed for the tests: container : image : cirrusci/android-sdk:29 cpu : 4 memory : 10G check_android_task : create_device_script : echo no | avdmanager create avd --force -n test -k \"system-images;android-29;default;armeabi-v7a\" start_emulator_background_script : $ANDROID_HOME/emulator/emulator -avd test -no-audio -no-window wait_for_emulator_script : - adb wait-for-device - adb shell input keyevent 82 check_script : ./gradlew check connectedCheck Info Please don't forget to setup Remote Build Cache for your Gradle project. Or at least basic folder caching .","title":"Android"},{"location":"examples/#android-lint","text":"The Cirrus CI annotator supports providing inline reports on PRs and can parse Android Lint reports. Here is an example of an Android Lint task that you can add to your .cirrus.yml : task : name : Android Lint lint_script : ./gradlew lintDebug always : android-lint_artifacts : path : \"**/reports/lint-results-debug.xml\" type : text/xml format : android-lint","title":"Android Lint"},{"location":"examples/#bazel","text":"Bazel Team provides a set of official Docker images with Bazel pre-installed . Here is an example of how .cirrus.yml can look like for Bazel: amd64 container : image : l.gcr.io/google/bazel:latest task : build_script : bazel build //... arm64 arm_container : image : l.gcr.io/google/bazel:latest task : build_script : bazel build //... If these images are not the right fit for your project you can always use any custom Docker image with Cirrus CI.","title":"Bazel"},{"location":"examples/#remote-cache","text":"Cirrus CI has built-in HTTP Cache which is compatible with Bazel's remote cache . Here is an example of how Cirrus CI HTTP Cache can be used with Bazel: amd64 container : image : l.gcr.io/google/bazel:latest task : build_script : bazel build --spawn_strategy=sandboxed --strategy=Javac=sandboxed --genrule_strategy=sandboxed --remote_http_cache=http://$CIRRUS_HTTP_CACHE_HOST //... arm64 arm_container : image : l.gcr.io/google/bazel:latest task : build_script : bazel build --spawn_strategy=sandboxed --strategy=Javac=sandboxed --genrule_strategy=sandboxed --remote_http_cache=http://$CIRRUS_HTTP_CACHE_HOST //...","title":"Remote Cache"},{"location":"examples/#c","text":"Official GCC Docker images can be used for builds. Here is an example of a .cirrus.yml that runs tests: amd64 container : image : gcc:latest task : tests_script : make tests arm64 arm_container : image : gcc:latest task : tests_script : make tests","title":"C++"},{"location":"examples/#crystal","text":"Official Crystal Docker images can be used for builds. Here is an example of a .cirrus.yml that caches dependencies and runs tests: container : image : crystallang/crystal:latest spec_task : shard_cache : fingerprint_script : cat shard.lock populate_script : shards install folder : lib spec_script : crystal spec","title":"Crystal"},{"location":"examples/#elixir","text":"Official Elixir Docker images can be used for builds. Here is an example of a .cirrus.yml that runs tests: amd64 test_task : container : image : elixir:latest mix_cache : folder : deps fingerprint_script : cat mix.lock populate_script : mix deps.get compile_script : mix compile test_script : mix test arm64 test_task : arm_container : image : elixir:latest mix_cache : folder : deps fingerprint_script : cat mix.lock populate_script : mix deps.get compile_script : mix compile test_script : mix test","title":"Elixir"},{"location":"examples/#erlang","text":"Official Erlang Docker images can be used for builds. Here is an example of a .cirrus.yml that runs tests: amd64 test_task : container : image : erlang:latest rebar3_cache : folder : _build fingerprint_script : cat rebar.lock populate_script : rebar3 compile --deps_only compile_script : rebar3 compile test_script : rebar3 ct arm64 test_task : arm_container : image : erlang:latest rebar3_cache : folder : _build fingerprint_script : cat rebar.lock populate_script : rebar3 compile --deps_only compile_script : rebar3 compile test_script : rebar3 ct","title":"Erlang"},{"location":"examples/#flutter","text":"Cirrus CI provides a set of Docker images with Flutter and Dart SDK pre-installed . Here is an example of how .cirrus.yml can be written for Flutter: container : image : cirrusci/flutter:latest test_task : pub_cache : folder : ~/.pub-cache test_script : flutter test -machine > report.json always : report_artifacts : path : report.json format : flutter If these images are not the right fit for your project you can always use any custom Docker image with Cirrus CI.","title":"Flutter"},{"location":"examples/#flutter-web","text":"Our Docker images with Flutter and Dart SDK pre-installed have special *-web tags with Chromium pre-installed. You can use these tags to run Flutter Web First define a new chromium platform in your dart_test.yaml : define_platforms : chromium : name : Chromium extends : chrome settings : arguments : --no-sandbox executable : linux : chromium Now you'll be able to run tests targeting web via pub run test test -p chromium","title":"Flutter Web"},{"location":"examples/#go","text":"The best way to test Go projects is by using official Go Docker images . Here is an example of how .cirrus.yml can look like for a project using Go Modules: amd64 container : image : golang:latest test_task : modules_cache : fingerprint_script : cat go.sum folder : $GOPATH/pkg/mod get_script : go get ./... build_script : go build ./... test_script : go test ./... arm64 arm_container : image : golang:latest test_task : modules_cache : fingerprint_script : cat go.sum folder : $GOPATH/pkg/mod get_script : go get ./... build_script : go build ./... test_script : go test ./...","title":"Go"},{"location":"examples/#golangci-lint","text":"We highly recommend to configure some sort of linting for your Go project. One of the options is GolangCI Lint . The Cirrus CI annotator supports providing inline reports on PRs and can parse GolangCI Lint reports. Here is an example of a GolangCI Lint task that you can add to your .cirrus.yml : amd64 task : name : GolangCI Lint container : image : golangci/golangci-lint:latest run_script : golangci-lint run -v --out-format json > lint-report.json always : golangci_artifacts : path : lint-report.json type : text/json format : golangci arm64 task : name : GolangCI Lint arm_container : image : golangci/golangci-lint:latest run_script : golangci-lint run -v --out-format json > lint-report.json always : golangci_artifacts : path : lint-report.json type : text/json format : golangci","title":"GolangCI Lint"},{"location":"examples/#gradle","text":"We recommend use of the official Gradle Docker containers since they have Gradle specific configurations already set up. For example, standard Java containers don't have a pre-configured user and as a result don't have HOME environment variable presented which makes Gradle complain.","title":"Gradle"},{"location":"examples/#caching","text":"To preserve caches between Gradle runs, add a cache instruction as shown below. The trick here is to clean up ~/.gradle/caches folder in the very end of a build. Gradle creates some unique nondeterministic files in ~/.gradle/caches folder on every run which makes Cirrus CI re-upload the cache every time . This way, you get faster builds! amd64 container : image : gradle:jdk11 check_task : gradle_cache : folder : ~/.gradle/caches check_script : gradle check cleanup_before_cache_script : - rm -rf ~/.gradle/caches/$GRADLE_VERSION/ - rm -rf ~/.gradle/caches/transforms-1 - rm -rf ~/.gradle/caches/journal-1 - rm -rf ~/.gradle/caches/jars-3/*/buildSrc.jar - find ~/.gradle/caches/ -name \"*.lock\" -type f -delete arm64 arm_container : image : gradle:jdk11 check_task : gradle_cache : folder : ~/.gradle/caches check_script : gradle check cleanup_before_cache_script : - rm -rf ~/.gradle/caches/$GRADLE_VERSION/ - rm -rf ~/.gradle/caches/transforms-1 - rm -rf ~/.gradle/caches/journal-1 - rm -rf ~/.gradle/caches/jars-3/*/buildSrc.jar - find ~/.gradle/caches/ -name \"*.lock\" -type f -delete","title":"Caching"},{"location":"examples/#build-cache","text":"Here is how HTTP Cache can be used with Gradle by adding the following code to settings.gradle : ext . isCiServer = System . getenv (). containsKey ( \"CIRRUS_CI\" ) ext . isMasterBranch = System . getenv ()[ \"CIRRUS_BRANCH\" ] == \"master\" ext . buildCacheHost = System . getenv (). getOrDefault ( \"CIRRUS_HTTP_CACHE_HOST\" , \"localhost:12321\" ) buildCache { local { enabled = ! isCiServer } remote ( HttpBuildCache ) { url = \"http://${buildCacheHost}/\" enabled = isCiServer push = isMasterBranch } } If your project uses a buildSrc directory, the build cache configuration should also be applied to buildSrc/settings.gradle . To do this, put the build cache configuration above into a separate gradle/buildCacheSettings.gradle file, then apply it to both your settings.gradle and buildSrc/settings.gradle . In settings.gradle : apply from: new File ( settingsDir , 'gradle/buildCacheSettings.gradle' ) In buildSrc/settings.gradle : apply from: new File ( settingsDir , '../gradle/buildCacheSettings.gradle' ) Please make sure you are running Gradle commands with --build-cache flag or have org.gradle.caching enabled in gradle.properties file. Here is an example of a gradle.properties file that we use internally for all Gradle projects: org.gradle.daemon = true org.gradle.caching = true org.gradle.parallel = true org.gradle.configureondemand = true org.gradle.jvmargs = -Dfile.encoding=UTF-8","title":"Build Cache"},{"location":"examples/#junit","text":"Here is a .cirrus.yml that, parses and uploads JUnit reports at the end of the build: junit_test_task : junit_script : <replace this comment with instructions to run the test suites> always : junit_result_artifacts : path : \"**/test-results/**.xml\" format : junit type : text/xml If it is running on a pull request, annotations will also be displayed in-line.","title":"JUnit"},{"location":"examples/#maven","text":"Official Maven Docker images can be used for building and testing Maven projects: amd64 container : image : maven:latest task : name : Cirrus CI maven_cache : folder : ~/.m2 test_script : mvn test -B arm64 arm_container : image : maven:latest task : name : Cirrus CI maven_cache : folder : ~/.m2 test_script : mvn test -B","title":"Maven"},{"location":"examples/#mysql","text":"The Additional Containers feature makes it super simple to run the same Docker MySQL image as you might be running in production for your application. Getting a running instance of the latest GA version of MySQL can used with the following six lines in your .cirrus.yml : amd64 container : image : golang:latest additional_containers : - name : mysql image : mysql:latest port : 3306 env : MYSQL_ROOT_PASSWORD : \"\" arm64 arm_container : image : golang:latest additional_containers : - name : mysql image : mysql:latest port : 3306 env : MYSQL_ROOT_PASSWORD : \"\" With the configuration above MySQL will be available on localhost:3306 . Use empty password to login as root user.","title":"MySQL"},{"location":"examples/#node","text":"Official NodeJS Docker images can be used for building and testing Node.JS applications.","title":"Node"},{"location":"examples/#npm","text":"Here is an example of a .cirrus.yml that caches node_modules based on contents of package-lock.json file and runs tests: amd64 container : image : node:latest test_task : node_modules_cache : folder : node_modules fingerprint_script : cat package-lock.json populate_script : npm ci test_script : npm test arm64 arm_container : image : node:latest test_task : node_modules_cache : folder : node_modules fingerprint_script : cat package-lock.json populate_script : npm ci test_script : npm test","title":"npm"},{"location":"examples/#yarn","text":"Here is an example of a .cirrus.yml that caches node_modules based on the contents of a yarn.lock file and runs tests: amd64 container : image : node:latest test_task : node_modules_cache : folder : node_modules fingerprint_script : cat yarn.lock populate_script : yarn install test_script : yarn run test arm64 arm_container : image : node:latest test_task : node_modules_cache : folder : node_modules fingerprint_script : cat yarn.lock populate_script : yarn install test_script : yarn run test","title":"Yarn"},{"location":"examples/#yarn-2","text":"Yarn 2 (also known as Yarn Berry), has a different package cache location ( .yarn/cache ). To run tests, it would look like this: amd64 container : image : node:latest test_task : yarn_cache : folder : .yarn/cache fingerprint_script : cat yarn.lock install_script : - yarn set version berry - yarn install test_script : yarn run test arm64 arm_container : image : node:latest test_task : yarn_cache : folder : .yarn/cache fingerprint_script : cat yarn.lock install_script : - yarn set version berry - yarn install test_script : yarn run test","title":"Yarn 2"},{"location":"examples/#python","text":"Official Python Docker images can be used for builds. Here is an example of a .cirrus.yml that caches installed packages based on contents of requirements.txt and runs pytest : amd64 container : image : python:slim test_task : pip_cache : folder : ~/.cache/pip fingerprint_script : echo $PYTHON_VERSION && cat requirements.txt populate_script : pip install -r requirements.txt test_script : pytest arm64 arm_container : image : python:slim test_task : pip_cache : folder : ~/.cache/pip fingerprint_script : echo $PYTHON_VERSION && cat requirements.txt populate_script : pip install -r requirements.txt test_script : pytest","title":"Python"},{"location":"examples/#building-pypi-packages","text":"Also using the Python Docker images, you can run tests if you are making packages for PyPI . Here is an example .cirrus.yml for doing so: amd64 container : image : python:slim build_package_test_task : pip_cache : folder : ~/.cache/pip fingerprint_script : echo $PYTHON_VERSION populate_script : python3 -m pip install --upgrade setuptools wheel build_package_test_script : python3 setup.py sdist bdist_wheel arm64 arm_container : image : python:slim build_package_test_task : pip_cache : folder : ~/.cache/pip fingerprint_script : echo $PYTHON_VERSION populate_script : python3 -m pip install --upgrade setuptools wheel build_package_test_script : python3 setup.py sdist bdist_wheel","title":"Building PyPI Packages"},{"location":"examples/#linting","text":"You can easily set up linting with Cirrus CI and flake8, here is an example .cirrus.yml : amd64 lint_task : container : image : alpine/flake8:latest script : flake8 *.py arm64 lint_task : arm_container : image : alpine/flake8:latest script : flake8 *.py","title":"Linting"},{"location":"examples/#unittest-annotations","text":"Python Unittest reports are supported by Cirrus CI Annotations . This way you can see what tests are failing without leaving the pull request you are reviewing! Here is an example of a .cirrus.yml that produces and stores Unittest reports: amd64 unittest_task : container : image : python:slim install_dependencies_script : | pip3 install unittest_xml_reporting run_tests_script : python3 -m xmlrunner tests # replace 'tests' with the module, # unittest.TestCase, or unittest.TestSuite # that the tests are in always : upload_results_artifacts : path : ./*.xml format : junit type : text/xml arm64 unittest_task : arm_container : image : python:slim install_dependencies_script : | pip3 install unittest_xml_reporting run_tests_script : python3 -m xmlrunner tests # replace 'tests' with the module, # unittest.TestCase, or unittest.TestSuite # that the tests are in always : upload_results_artifacts : path : ./*.xml format : junit type : text/xml Now you should get annotations for your test results.","title":"Unittest Annotations"},{"location":"examples/#qodana","text":"Qodana by JetBrains is a code quality monitoring tool that identifies and suggests fixes for bugs, security vulnerabilities, duplications, and imperfections. It brings all the smart features you love in the JetBrains IDEs. Here is an example of .cirrus.yml configuration file which will save Qodana's report as an artifact, will parse it and report as annotations : task : name : Qodana container : image : jetbrains/qodana:latest env : CIRRUS_WORKING_DIR : /data/project generate_report_script : - /opt/idea/bin/entrypoint --save-report --report-dir=report always : results_artifacts : path : \"report/results/result-allProblems.json\" format : qodana","title":"Qodana"},{"location":"examples/#release-assets","text":"Cirrus CI doesn't provide a built-in functionality to upload artifacts on a GitHub release but this functionality can be added via a script. For a release, Cirrus CI will provide CIRRUS_RELEASE environment variable along with CIRRUS_TAG environment variable. CIRRUS_RELEASE indicates release id which can be used to upload assets. Cirrus CI only requires write access to Check API and doesn't require write access to repository contents because of security reasons. That's why you need to create a personal access token with full access to repo scope. Once an access token is created, please create an encrypted variable from it and save it to .cirrus.yml : env : GITHUB_TOKEN : ENCRYPTED[qwerty] Now you can use a script to upload your assets: #!/usr/bin/env bash if [[ \" $CIRRUS_RELEASE \" == \"\" ]] ; then echo \"Not a release. No need to deploy!\" exit 0 fi if [[ \" $GITHUB_TOKEN \" == \"\" ]] ; then echo \"Please provide GitHub access token via GITHUB_TOKEN environment variable!\" exit 1 fi file_content_type = \"application/octet-stream\" files_to_upload =( # relative paths of assets to upload ) for fpath in $files_to_upload do echo \"Uploading $fpath ...\" name = $( basename \" $fpath \" ) url_to_upload = \"https://uploads.github.com/repos/ $CIRRUS_REPO_FULL_NAME /releases/ $CIRRUS_RELEASE /assets?name= $name \" curl -X POST \\ --data-binary @ $fpath \\ --header \"Authorization: token $GITHUB_TOKEN \" \\ --header \"Content-Type: $file_content_type \" \\ $url_to_upload done","title":"Release Assets"},{"location":"examples/#ruby","text":"Official Ruby Docker images can be used for builds. Here is an example of a .cirrus.yml that caches installed gems based on Ruby version, contents of Gemfile.lock , and runs rspec : amd64 container : image : ruby:latest rspec_task : bundle_cache : folder : /usr/local/bundle fingerprint_script : - echo $RUBY_VERSION - cat Gemfile.lock populate_script : bundle install rspec_script : bundle exec rspec --format json --out rspec.json always : rspec_report_artifacts : path : rspec.json type : text/json format : rspec arm64 arm_container : image : ruby:latest rspec_task : bundle_cache : folder : /usr/local/bundle fingerprint_script : - echo $RUBY_VERSION - cat Gemfile.lock populate_script : bundle install rspec_script : bundle exec rspec --format json --out rspec.json always : rspec_report_artifacts : path : rspec.json type : text/json format : rspec Repositories without Gemfile.lock When you are not committing Gemfile.lock (in Ruby gems repositories, for example) you can run bundle install (or bundle update ) in install_script instead of populate_script in bundle_cache . Cirrus Agent is clever enough to re-upload cache entry only if cached folder has been changed during task execution. Here is an example of a .cirrus.yml that always runs bundle install : amd64 container : image : ruby:latest rspec_task : bundle_cache : folder : /usr/local/bundle fingerprint_script : - echo $RUBY_VERSION - cat Gemfile - cat *.gemspec install_script : bundle install # or `update` for the freshest bundle rspec_script : bundle exec rspec arm64 arm_container : image : ruby:latest rspec_task : bundle_cache : folder : /usr/local/bundle fingerprint_script : - echo $RUBY_VERSION - cat Gemfile - cat *.gemspec install_script : bundle install # or `update` for the freshest bundle rspec_script : bundle exec rspec Test Parallelization It's super easy to add intelligent test splitting by using Knapsack Pro and matrix modification . After setting up Knapsack Pro gem , you can add sharding like this: task : matrix : name : rspec (shard 1) name : rspec (shard 2) name : rspec (shard 3) name : rspec (shard 4) bundle_cache : folder : /usr/local/bundle fingerprint_script : cat Gemfile.lock populate_script : bundle install rspec_script : bundle exec rake knapsack_pro:rspec Which will create four shards that will theoretically run tests 4x faster by equally splitting all tests between these four shards.","title":"Ruby"},{"location":"examples/#rspec-and-rubocop-annotations","text":"Cirrus CI natively supports RSpec and RuboCop machine-parsable JSON reports. To get behavior-driven test annotations, generate and upload a rspec artifact from your lint task: amd64 container : image : ruby:latest task : name : RSpec bundle_cache : folder : /usr/local/bundle fingerprint_script : - echo $RUBY_VERSION - cat Gemfile.lock populate_script : bundle install script : bundle exec rspec --format json --out rspec.json always : rspec_artifacts : path : rspec.json type : text/json format : rspec arm64 arm_container : image : ruby:latest task : name : RSpec bundle_cache : folder : /usr/local/bundle fingerprint_script : - echo $RUBY_VERSION - cat Gemfile.lock populate_script : bundle install script : bundle exec rspec --format json --out rspec.json always : rspec_artifacts : path : rspec.json type : text/json format : rspec Generate a rubocop artifact to quickly gain context for linter/formatter annotations: amd64 container : image : ruby:latest task : name : RuboCop bundle_cache : folder : /usr/local/bundle fingerprint_script : - echo $RUBY_VERSION - cat Gemfile.lock populate_script : bundle install script : bundle exec rubocop --format json --out rubocop.json always : rubocop_artifacts : path : rubocop.json type : text/json format : rubocop arm64 arm_container : image : ruby:latest task : name : RuboCop bundle_cache : folder : /usr/local/bundle fingerprint_script : - echo $RUBY_VERSION - cat Gemfile.lock populate_script : bundle install script : bundle exec rubocop --format json --out rubocop.json always : rubocop_artifacts : path : rubocop.json type : text/json format : rubocop","title":"RSpec and RuboCop Annotations"},{"location":"examples/#rust","text":"Official Rust Docker images can be used for builds. Here is a basic example of .cirrus.yml that caches crates in $CARGO_HOME based on contents of Cargo.lock : amd64 container : image : rust:latest test_task : registry_cache : folder : $CARGO_HOME/registry fingerprint_script : cat Cargo.lock target_cache : folder : target fingerprint_script : - rustc --version - cat Cargo.lock build_script : cargo build test_script : cargo test before_cache_script : rm -rf $CARGO_HOME/registry/index arm64 arm_container : image : rust:latest test_task : registry_cache : folder : $CARGO_HOME/registry fingerprint_script : cat Cargo.lock target_cache : folder : target fingerprint_script : - rustc --version - cat Cargo.lock build_script : cargo build test_script : cargo test before_cache_script : rm -rf $CARGO_HOME/registry/index Caching Cleanup Please note before_cache_script that removes registry index from the cache before uploading it in the end of a successful task. Registry index is changing very rapidly making the cache invalid. before_cache_script deletes the index and leaves only the required crates for caching.","title":"Rust"},{"location":"examples/#rust-nightly","text":"It is possible to use nightly builds of Rust via an official rustlang/rust:nightly container . Here is an example of a .cirrus.yml to run tests against the latest stable and nightly versions of Rust: amd64 test_task : matrix : - container : image : rust:latest - allow_failures : true container : image : rustlang/rust:nightly registry_cache : folder : $CARGO_HOME/registry fingerprint_script : cat Cargo.lock target_cache : folder : target fingerprint_script : - rustc --version - cat Cargo.lock build_script : cargo build test_script : cargo test before_cache_script : rm -rf $CARGO_HOME/registry/index arm64 test_task : matrix : - arm_container : image : rust:latest - allow_failures : true arm_container : image : rustlang/rust:nightly registry_cache : folder : $CARGO_HOME/registry fingerprint_script : cat Cargo.lock target_cache : folder : target fingerprint_script : - rustc --version - cat Cargo.lock build_script : cargo build test_script : cargo test before_cache_script : rm -rf $CARGO_HOME/registry/index FreeBSD Caveats Vanila FreeBSD VMs don't set some environment variables required by Cargo for effective caching. Specifying HOME environment variable to some arbitrarily location should fix caching: freebsd_instance : image-family : freebsd-12-0 task : name : cargo test (stable) env : HOME : /tmp # cargo needs it install_script : pkg install -y rust cargo_cache : folder : $HOME/.cargo/registry fingerprint_script : cat Cargo.lock build_script : cargo build --all test_script : cargo test --all --all-targets before_cache_script : rm -rf $HOME/.cargo/registry/index","title":"Rust Nightly"},{"location":"examples/#xclogparser","text":"XCLogParser is a CLI tool that parses Xcode and xcodebuild 's logs ( xcactivitylog files) and produces reports in different formats. Here is an example of .cirrus.yml configuration file which will save XCLogParser's flat JSON report as an artifact, will parse it and report as annotations : macos_instance : image : big-sur-xcode task : name : XCLogParser build_script : - xcodebuild -scheme noapp -derivedDataPath ~/dd always : xclogparser_parse_script : - brew install xclogparser - xclogparser parse --project noapp --reporter flatJson --output xclogparser.json --derived_data ~/dd xclogparser_upload_artifacts : path : \"xclogparser.json\" type : text/json format : xclogparser","title":"XCLogParser"},{"location":"faq/","text":"Frequently Asked Questions \u00b6 Is Cirrus CI a delivery platform? \u00b6 Cirrus CI is not positioned as a delivery platform but can be used as one for many general use cases by having Dependencies between tasks and using Conditional Task Execution or Manual Tasks : lint_task : script : yarn run lint test_task : script : yarn run test publish_task : only_if : $BRANCH == 'master' trigger_type : manual depends_on : - test - lint script : yarn run publish Are there any limits? \u00b6 Cirrus CI has the following limitations on how many CPUs for different platforms a single user can run on community clusters for public repositories for free: 16.0 CPUs for Linux platform (Containers or VMs). 16.0 CPUs for Arm Linux platform (Containers). 8.0 CPUs for Windows platform (Containers or VMs) 8.0 CPUs for FreeBSD VMs. 12.0 CPUs macOS VM (1 VM). Note that a single task can't request more than 8 CPUs (except macOS VMs which are not configurable). No Monthly Minute Limit There are no limits on how many minutes a month you can use! Please keep in mind that mining cryptocurrency is against our Terms of Service, and will most likely be blocked by firewall rules and other anti-fraud mechanisms. Be a good citizen in the OSS community! If you are using Cirrus CI with your private personal repositories under the $10/month plan you'll have twice the limits : 32.0 CPUs for Linux platform (Containers or VMs). 16.0 CPUs for Windows platform (Containers or VMs) 16.0 CPUs for FreeBSD VMs. 24.0 CPUs macOS VM (2 VMs). There are no limits on how many VMs or Containers you can run in parallel if you bring your own infrastructure or use Compute Credits for either private or public repositories. No per repository limits Cirrus CI doesn't enforce any limits on repository or organization levels. All the limits are on a per-user basis. Cache and Logs Redundancy By default Cirrus CI persists caches and logs for 90 days. If you bring your own compute services this period can be configured directly in your cloud provider's console. Repository is blocked \u00b6 Free tier of Cirrus CI is intended for public OSS projects to run tests and other validations continuously. If your repository is configured to use Cirrus CI in a questionable way to just exploit Cirrus CI infrastructure, your repository might be blocked. Here are a few examples of such questionable activities we've seen so far: Use Cirrus CI as a powerhouse for arbitrary CPU-intensive calculations (including crypto mining). Use Cirrus CI to download a pirated movie, re-encode it, upload as a Cirrus artifact and distribute it. Use Cirrus CI distributed infrastructure to emulate user activity on a variety of websites to trick advertisers. IP Addresses of Community Clusters \u00b6 Instances running on Community Clusters are using dynamic IPs by default. It's possible to request a static 35.222.255.190 IP for all the community instance types except macOS VMs via use_static_ip field. Here is an example of a Linux Docker container with a static IP: task : name : Test IP container : image : cirrusci/wget:latest use_static_ip : true script : wget -qO- ifconfig.co CI agent stopped responding! \u00b6 It means that Cirrus CI haven't heard from the agent for quite some time. In 99.999% of the cases it happens because of two reasons: Your task was executing on Community Cluster . Community Cluster is backed by Google Cloud's Preemptible VMs for cost efficiency reasons and Google Cloud preempted back a VM your task was executing on. Cirrus CI is trying to minimize possibility of such cases by constantly rotating VMs before Google Cloud preempts them, but there is still chance of such inconvenience. Your CI task used too much memory which led to a crash of a VM or a container. Agent process on a persistent worker exited unexpectedly! \u00b6 This means that either an agent process or a VM with an agent process exited before reporting the last instruction of a task. If it's happening for a mancos_instance then please contact support . Instance failed to start! \u00b6 It means that Cirrus CI has made a successful API call to a computing service to allocate resources. But a requested resource wasn't created. If it happened for an OSS project, please contact support immediately. Otherwise check your cloud console first and then contact support if it's still not clear what happened. Instance got rescheduled! \u00b6 Cirrus CI is trying to be as efficient as possible and heavily uses preemptible VMs to run majority of workloads. It allows to drastically lower Cirrus CI's infrastructure bill and allows to provide the best pricing model with per-second billing and very generous limits for OSS projects , but it comes with a rare edge case... Preemptible VMs can be preempted which will require rescheduling and automatically restart tasks that were executing on these VMs. This is a rare event since autoscaler is constantly rotating instances but preemption still happens occasionally. All automatic re-runs and stateful tasks using compute credits are always executed on regular VMs. Instance timed out! \u00b6 By default, Cirrus CI has an execution limit of 60 minutes for each task. However, this default timeout duration can be changed by using timeout_in field in .cirrus.yml configuration file: task : timeout_in : 90m ... Maximum timeout There is a hard limit of 2 hours for community tasks. Use compute credits or compute service integration to avoid the limit. Container errored \u00b6 It means that Cirrus CI has made a successful API call to a computing service to start a container but unfortunately container runtime or the corresponding computing service had an internal error. Only GitHub Support? \u00b6 At the moment Cirrus CI only supports GitHub via a GitHub Application . We are planning to support BitBucket next. Any discounts? \u00b6 Cirrus CI itself doesn't provide any discounts except Community Cluster which is free for open source projects. But since Cirrus CI delegates execution of builds to different computing services, it means that discounts from your cloud provider will be applied to Cirrus CI builds.","title":"FAQ"},{"location":"faq/#frequently-asked-questions","text":"","title":"Frequently Asked Questions"},{"location":"faq/#is-cirrus-ci-a-delivery-platform","text":"Cirrus CI is not positioned as a delivery platform but can be used as one for many general use cases by having Dependencies between tasks and using Conditional Task Execution or Manual Tasks : lint_task : script : yarn run lint test_task : script : yarn run test publish_task : only_if : $BRANCH == 'master' trigger_type : manual depends_on : - test - lint script : yarn run publish","title":"Is Cirrus CI a delivery platform?"},{"location":"faq/#are-there-any-limits","text":"Cirrus CI has the following limitations on how many CPUs for different platforms a single user can run on community clusters for public repositories for free: 16.0 CPUs for Linux platform (Containers or VMs). 16.0 CPUs for Arm Linux platform (Containers). 8.0 CPUs for Windows platform (Containers or VMs) 8.0 CPUs for FreeBSD VMs. 12.0 CPUs macOS VM (1 VM). Note that a single task can't request more than 8 CPUs (except macOS VMs which are not configurable). No Monthly Minute Limit There are no limits on how many minutes a month you can use! Please keep in mind that mining cryptocurrency is against our Terms of Service, and will most likely be blocked by firewall rules and other anti-fraud mechanisms. Be a good citizen in the OSS community! If you are using Cirrus CI with your private personal repositories under the $10/month plan you'll have twice the limits : 32.0 CPUs for Linux platform (Containers or VMs). 16.0 CPUs for Windows platform (Containers or VMs) 16.0 CPUs for FreeBSD VMs. 24.0 CPUs macOS VM (2 VMs). There are no limits on how many VMs or Containers you can run in parallel if you bring your own infrastructure or use Compute Credits for either private or public repositories. No per repository limits Cirrus CI doesn't enforce any limits on repository or organization levels. All the limits are on a per-user basis. Cache and Logs Redundancy By default Cirrus CI persists caches and logs for 90 days. If you bring your own compute services this period can be configured directly in your cloud provider's console.","title":"Are there any limits?"},{"location":"faq/#repository-is-blocked","text":"Free tier of Cirrus CI is intended for public OSS projects to run tests and other validations continuously. If your repository is configured to use Cirrus CI in a questionable way to just exploit Cirrus CI infrastructure, your repository might be blocked. Here are a few examples of such questionable activities we've seen so far: Use Cirrus CI as a powerhouse for arbitrary CPU-intensive calculations (including crypto mining). Use Cirrus CI to download a pirated movie, re-encode it, upload as a Cirrus artifact and distribute it. Use Cirrus CI distributed infrastructure to emulate user activity on a variety of websites to trick advertisers.","title":"Repository is blocked"},{"location":"faq/#ip-addresses-of-community-clusters","text":"Instances running on Community Clusters are using dynamic IPs by default. It's possible to request a static 35.222.255.190 IP for all the community instance types except macOS VMs via use_static_ip field. Here is an example of a Linux Docker container with a static IP: task : name : Test IP container : image : cirrusci/wget:latest use_static_ip : true script : wget -qO- ifconfig.co","title":"IP Addresses of Community Clusters"},{"location":"faq/#ci-agent-stopped-responding","text":"It means that Cirrus CI haven't heard from the agent for quite some time. In 99.999% of the cases it happens because of two reasons: Your task was executing on Community Cluster . Community Cluster is backed by Google Cloud's Preemptible VMs for cost efficiency reasons and Google Cloud preempted back a VM your task was executing on. Cirrus CI is trying to minimize possibility of such cases by constantly rotating VMs before Google Cloud preempts them, but there is still chance of such inconvenience. Your CI task used too much memory which led to a crash of a VM or a container.","title":"CI agent stopped responding!"},{"location":"faq/#agent-process-on-a-persistent-worker-exited-unexpectedly","text":"This means that either an agent process or a VM with an agent process exited before reporting the last instruction of a task. If it's happening for a mancos_instance then please contact support .","title":"Agent process on a persistent worker exited unexpectedly!"},{"location":"faq/#instance-failed-to-start","text":"It means that Cirrus CI has made a successful API call to a computing service to allocate resources. But a requested resource wasn't created. If it happened for an OSS project, please contact support immediately. Otherwise check your cloud console first and then contact support if it's still not clear what happened.","title":"Instance failed to start!"},{"location":"faq/#instance-got-rescheduled","text":"Cirrus CI is trying to be as efficient as possible and heavily uses preemptible VMs to run majority of workloads. It allows to drastically lower Cirrus CI's infrastructure bill and allows to provide the best pricing model with per-second billing and very generous limits for OSS projects , but it comes with a rare edge case... Preemptible VMs can be preempted which will require rescheduling and automatically restart tasks that were executing on these VMs. This is a rare event since autoscaler is constantly rotating instances but preemption still happens occasionally. All automatic re-runs and stateful tasks using compute credits are always executed on regular VMs.","title":"Instance got rescheduled!"},{"location":"faq/#instance-timed-out","text":"By default, Cirrus CI has an execution limit of 60 minutes for each task. However, this default timeout duration can be changed by using timeout_in field in .cirrus.yml configuration file: task : timeout_in : 90m ... Maximum timeout There is a hard limit of 2 hours for community tasks. Use compute credits or compute service integration to avoid the limit.","title":"Instance timed out!"},{"location":"faq/#container-errored","text":"It means that Cirrus CI has made a successful API call to a computing service to start a container but unfortunately container runtime or the corresponding computing service had an internal error.","title":"Container errored"},{"location":"faq/#only-github-support","text":"At the moment Cirrus CI only supports GitHub via a GitHub Application . We are planning to support BitBucket next.","title":"Only GitHub Support?"},{"location":"faq/#any-discounts","text":"Cirrus CI itself doesn't provide any discounts except Community Cluster which is free for open source projects. But since Cirrus CI delegates execution of builds to different computing services, it means that discounts from your cloud provider will be applied to Cirrus CI builds.","title":"Any discounts?"},{"location":"features/","text":"Free for Open Source \u00b6 To support the Open Source community, Cirrus CI provides Linux , Windows , macOS and FreeBSD services free of charge with some limits but without a cap on how many minutes a month OSS projects can consume. Here is a list of all instance types available for free for Open Source Projects: Instance Type Managed by Description container us Linux Docker Container arm_container us Linux Arm Docker Container windows_container us Windows Docker Container docker_builder us Full-fledged VM pre-configured for running Docker macos_instance us macOS Virtual Machines freebsd_instance us FreeBSD Virtual Machines compute_engine_instance us Full-fledged custom VM persistent_worker you Use any host on any platform and architecture Per-second billing \u00b6 Use compute credits to run as many parallel tasks as you want and pay only for CPU time used by these tasks. Another approach is to bring your own infrastructure and pay directly to your cloud provider within your current billing. No concurrency limit. No queues \u00b6 Cirrus CI leverages elasticity of the modern clouds to always have available resources to process your builds. Engineers should never wait for builds to start . Bring Your Own Infrastructure \u00b6 Cirrus CI supports bringing your own infrastructure (BYO) for full control over security and for easy integration with your current workflow. Flexible runtime environment \u00b6 Cirrus CI allows you to use any Unix or Windows VMs, any Docker containers, any amount of CPUs, optional SSDs and GPUs. Basic but very powerful configuration format \u00b6 Learn more about how to configure tasks here . Configure things like: Matrix Builds Dependencies between tasks Conditional Task Execution Local HTTP Cache Dockerfile as a CI environment Monorepo Support Check the Quick Start guide for more features. Comparison with popular CIaaS \u00b6 Here is a high level comparison with popular continuous-integration-as-a-service solutions: Name Linux Windows macOS FreeBSD Customizable CPU/Memory For Open Source For Personal Private Repositories For Organizational Private Repositories Cirrus CI (any value) 34 concurrent CPUs with no monthly limit on minutes $10/month with the same OSS limits \ud83d\udc48 Per-second usage with no parallel limit Connect your cloud for $10/month/seat GitHub Actions 20 concurrent jobs with no monthly limit on minutes 2,000 minutes/month for free Per-minute usage with no parallel limit Host and manage additional runners at no additional cost Travis CI 1000 minutes per account per month $69/month for 1 concurrent job $49/month per additional concurrency job CircleCI (4 types) 40,000 minutes per organization per month 1,000 minutes/month for free $69/month for 2 concurrent job $15/month/user + per-minute usage with up to 80 parallel jobs AppVeyor 1 concurrent job with no monthly limit on minutes $59/month for 1 concurrent job $50/month per additional concurrency job Feel free to contact support if you have questions for your particular case.","title":"Features"},{"location":"features/#free-for-open-source","text":"To support the Open Source community, Cirrus CI provides Linux , Windows , macOS and FreeBSD services free of charge with some limits but without a cap on how many minutes a month OSS projects can consume. Here is a list of all instance types available for free for Open Source Projects: Instance Type Managed by Description container us Linux Docker Container arm_container us Linux Arm Docker Container windows_container us Windows Docker Container docker_builder us Full-fledged VM pre-configured for running Docker macos_instance us macOS Virtual Machines freebsd_instance us FreeBSD Virtual Machines compute_engine_instance us Full-fledged custom VM persistent_worker you Use any host on any platform and architecture","title":"Free for Open Source"},{"location":"features/#per-second-billing","text":"Use compute credits to run as many parallel tasks as you want and pay only for CPU time used by these tasks. Another approach is to bring your own infrastructure and pay directly to your cloud provider within your current billing.","title":"Per-second billing"},{"location":"features/#no-concurrency-limit-no-queues","text":"Cirrus CI leverages elasticity of the modern clouds to always have available resources to process your builds. Engineers should never wait for builds to start .","title":"No concurrency limit. No queues"},{"location":"features/#bring-your-own-infrastructure","text":"Cirrus CI supports bringing your own infrastructure (BYO) for full control over security and for easy integration with your current workflow.","title":"Bring Your Own Infrastructure"},{"location":"features/#flexible-runtime-environment","text":"Cirrus CI allows you to use any Unix or Windows VMs, any Docker containers, any amount of CPUs, optional SSDs and GPUs.","title":"Flexible runtime environment"},{"location":"features/#basic-but-very-powerful-configuration-format","text":"Learn more about how to configure tasks here . Configure things like: Matrix Builds Dependencies between tasks Conditional Task Execution Local HTTP Cache Dockerfile as a CI environment Monorepo Support Check the Quick Start guide for more features.","title":"Basic but very powerful configuration format"},{"location":"features/#comparison-with-popular-ciaas","text":"Here is a high level comparison with popular continuous-integration-as-a-service solutions: Name Linux Windows macOS FreeBSD Customizable CPU/Memory For Open Source For Personal Private Repositories For Organizational Private Repositories Cirrus CI (any value) 34 concurrent CPUs with no monthly limit on minutes $10/month with the same OSS limits \ud83d\udc48 Per-second usage with no parallel limit Connect your cloud for $10/month/seat GitHub Actions 20 concurrent jobs with no monthly limit on minutes 2,000 minutes/month for free Per-minute usage with no parallel limit Host and manage additional runners at no additional cost Travis CI 1000 minutes per account per month $69/month for 1 concurrent job $49/month per additional concurrency job CircleCI (4 types) 40,000 minutes per organization per month 1,000 minutes/month for free $69/month for 2 concurrent job $15/month/user + per-minute usage with up to 80 parallel jobs AppVeyor 1 concurrent job with no monthly limit on minutes $59/month for 1 concurrent job $50/month per additional concurrency job Feel free to contact support if you have questions for your particular case.","title":"Comparison with popular CIaaS"},{"location":"pricing/","text":"Pricing \u00b6 Cirrus CI is free for Open Source projects with some limitations . For private projects, Cirrus CI has couple of options depending on your needs: For private personal repositories there is a very affordable $10 a month plan with access to community clusters for Linux , Windows and macOS workloads. Buy compute credits to access managed and pre-configured community clusters for Linux , FreeBSD , Windows , and macOS workloads. Configure access to your own infrastructure and pay $10/seat/month . Here is a comparison table of available Cirrus CI plans : User Free Public Repositories Private Personal Repository Private Organization Repositories Person Free access to community clusters for public repositories Bring your own infrastructure for public repositories Configure persistent workers for public repositories Access to community clusters for public and private repositories Bring your own infrastructure for public and private repositories Configure persistent workers for public and private repositories Not Applicable Organization Free access to community clusters for public repositories Use compute credits to access community clusters for private repositories and/or to avoid the limits on public repositories Bring your own infrastructure for public repositories Configure persistent workers for public repositories Not Applicable Free access to community clusters for public repositories Use compute credits to access community clusters for private repositories and/or to avoid the limits on public repositories Bring your own infrastructure for public and private repositories Configure persistent workers for public and private repositories Compute Credits \u00b6 Sometimes configuring your own compute services isn't worth it. It takes time and effort to maintain them. For such cases there is a way to use the same community clusters that the Open Source community is enjoying. Use compute credits with your private or public repositories of any scale. 1 compute credit can be bought for 1 US dollar. Here is how much 1000 minutes of CPU time will cost for different platforms: 1000 minutes of 1 virtual CPU for Linux for 5 compute credits 1000 minutes of 1 virtual CPU for FreeBSD for 5 compute credits 1000 minutes of 1 virtual CPU for Windows for 10 compute credits 1000 minutes of 1 virtual CPU for macOS for 10 compute credits All tasks using compute credits are charged on per-second basis. 2 CPU Linux task takes 2 minutes? Pay 2 cents . Note: orchestration costs are included in compute credits and there is no need to purchase additional seats on your plan. Priority Scheduling Tasks that are using compute credits will be prioritized and will be scheduled as fast as possible. Works for OSS projects Compute credits can be used for commercial OSS projects to avoid concurrency limits . Note that only collaborators for the project will be able to use organization's compute credits. Benefits of this approach: Use the same pre-configured infrastructure as the Open Source community is enjoying. No need to configure anything. Let Cirrus CI's team manage and upgrade infrastructure for you. Per-second billing with no additional minimum or monthly fees. Cost efficient for small to medium teams. Cons of this approach: No support for exotic use cases like GPUs, SSDs and 100+ cores machines. Not that cost efficient for big teams. Buying Compute Credits \u00b6 To see your current balance, recent transactions and to buy more compute credits, go to your organization's settings page: https://cirrus-ci.com/settings/github/MY-ORGANIZATION Configuring Compute Credits \u00b6 Compute credits can be used with any of the following instance types: container , windows_container and macos_instance . No additional configuration needed. amd64 task : container : image : node:latest ... arm64 task : arm_container : image : node:latest ... Using compute credits for public or personal private repositories If you willing to boost Cirrus CI for public or your personal private repositories you need to explicitly mark a task to use compute credits with use_compute_credits field. Here is an example of how to enable compute credits for internal and external collaborators of a public repository: task : use_compute_credits : $CIRRUS_USER_COLLABORATOR == 'true' Here is another example of how to enable compute credits for master branch of a personal private project to make sure all of the master builds are executed as fast as possible by skipping community clusters usage limits : task : use_compute_credits : $CIRRUS_BRANCH == 'master' Compute Services \u00b6 Configure and connect one or more compute services and/or persistent workers to Cirrus CI for orchestrating CI workloads on them. It's free for your public repositories and costs $10/seat/month to use with private repositories. Benefits of this approach: Full control of underlying infrastructure. Use any type of VMs and containers with any amount of CPUs and memory. More secure. Setup any firewall and access rules. Pay for CI within your existing cloud and GitHub bills. Cons of this approach: Need to configure and connect one or several compute services . Might not be worth the effort for a small team. Need to pay $10/seat/month plan. What is a seat? A seat is a GitHub user that initiates CI builds by pushing commits and/or creating pull requests in a private repository. It can be a real person or a bot. If you are using Cron Builds or creating builds through Cirrus's API it will be counted as an additional seat (like a bot). For example, if there are 10 people in your GitHub Organization and only 5 of them are working on private repositories where Cirrus CI is configured, the remaining 5 people are not counted as seats, given that they aren't pushing to the private repository. Let's say Dependabot is also configured for these private repositories. In that case there are 5 + 1 = 6 seats you need to purchase Cirrus CI plan for.","title":"Pricing"},{"location":"pricing/#pricing","text":"Cirrus CI is free for Open Source projects with some limitations . For private projects, Cirrus CI has couple of options depending on your needs: For private personal repositories there is a very affordable $10 a month plan with access to community clusters for Linux , Windows and macOS workloads. Buy compute credits to access managed and pre-configured community clusters for Linux , FreeBSD , Windows , and macOS workloads. Configure access to your own infrastructure and pay $10/seat/month . Here is a comparison table of available Cirrus CI plans : User Free Public Repositories Private Personal Repository Private Organization Repositories Person Free access to community clusters for public repositories Bring your own infrastructure for public repositories Configure persistent workers for public repositories Access to community clusters for public and private repositories Bring your own infrastructure for public and private repositories Configure persistent workers for public and private repositories Not Applicable Organization Free access to community clusters for public repositories Use compute credits to access community clusters for private repositories and/or to avoid the limits on public repositories Bring your own infrastructure for public repositories Configure persistent workers for public repositories Not Applicable Free access to community clusters for public repositories Use compute credits to access community clusters for private repositories and/or to avoid the limits on public repositories Bring your own infrastructure for public and private repositories Configure persistent workers for public and private repositories","title":"Pricing"},{"location":"pricing/#compute-credits","text":"Sometimes configuring your own compute services isn't worth it. It takes time and effort to maintain them. For such cases there is a way to use the same community clusters that the Open Source community is enjoying. Use compute credits with your private or public repositories of any scale. 1 compute credit can be bought for 1 US dollar. Here is how much 1000 minutes of CPU time will cost for different platforms: 1000 minutes of 1 virtual CPU for Linux for 5 compute credits 1000 minutes of 1 virtual CPU for FreeBSD for 5 compute credits 1000 minutes of 1 virtual CPU for Windows for 10 compute credits 1000 minutes of 1 virtual CPU for macOS for 10 compute credits All tasks using compute credits are charged on per-second basis. 2 CPU Linux task takes 2 minutes? Pay 2 cents . Note: orchestration costs are included in compute credits and there is no need to purchase additional seats on your plan. Priority Scheduling Tasks that are using compute credits will be prioritized and will be scheduled as fast as possible. Works for OSS projects Compute credits can be used for commercial OSS projects to avoid concurrency limits . Note that only collaborators for the project will be able to use organization's compute credits. Benefits of this approach: Use the same pre-configured infrastructure as the Open Source community is enjoying. No need to configure anything. Let Cirrus CI's team manage and upgrade infrastructure for you. Per-second billing with no additional minimum or monthly fees. Cost efficient for small to medium teams. Cons of this approach: No support for exotic use cases like GPUs, SSDs and 100+ cores machines. Not that cost efficient for big teams.","title":"Compute Credits"},{"location":"pricing/#buying-compute-credits","text":"To see your current balance, recent transactions and to buy more compute credits, go to your organization's settings page: https://cirrus-ci.com/settings/github/MY-ORGANIZATION","title":"Buying Compute Credits"},{"location":"pricing/#configuring-compute-credits","text":"Compute credits can be used with any of the following instance types: container , windows_container and macos_instance . No additional configuration needed. amd64 task : container : image : node:latest ... arm64 task : arm_container : image : node:latest ... Using compute credits for public or personal private repositories If you willing to boost Cirrus CI for public or your personal private repositories you need to explicitly mark a task to use compute credits with use_compute_credits field. Here is an example of how to enable compute credits for internal and external collaborators of a public repository: task : use_compute_credits : $CIRRUS_USER_COLLABORATOR == 'true' Here is another example of how to enable compute credits for master branch of a personal private project to make sure all of the master builds are executed as fast as possible by skipping community clusters usage limits : task : use_compute_credits : $CIRRUS_BRANCH == 'master'","title":"Configuring Compute Credits"},{"location":"pricing/#compute-services","text":"Configure and connect one or more compute services and/or persistent workers to Cirrus CI for orchestrating CI workloads on them. It's free for your public repositories and costs $10/seat/month to use with private repositories. Benefits of this approach: Full control of underlying infrastructure. Use any type of VMs and containers with any amount of CPUs and memory. More secure. Setup any firewall and access rules. Pay for CI within your existing cloud and GitHub bills. Cons of this approach: Need to configure and connect one or several compute services . Might not be worth the effort for a small team. Need to pay $10/seat/month plan. What is a seat? A seat is a GitHub user that initiates CI builds by pushing commits and/or creating pull requests in a private repository. It can be a real person or a bot. If you are using Cron Builds or creating builds through Cirrus's API it will be counted as an additional seat (like a bot). For example, if there are 10 people in your GitHub Organization and only 5 of them are working on private repositories where Cirrus CI is configured, the remaining 5 people are not counted as seats, given that they aren't pushing to the private repository. Let's say Dependabot is also configured for these private repositories. In that case there are 5 + 1 = 6 seats you need to purchase Cirrus CI plan for.","title":"Compute Services"},{"location":"security/","text":"Security Policy \u00b6 Reporting a Vulnerability \u00b6 If you find a security vulnerability in the Cirrus CI platform (the backend, web interface, etc.), please follow the steps below . Do NOT comment about the vulnerability publicly. Please email hello@cirruslabs.org with the following format: Subject: Platform Security Risk HOW TO EXPLOIT Give exact details so our team can replicate it. OTHER INFORMATION If anything else needs to be said, put it here. Please be patient. You will get an email back soon. Thank you!","title":"Security"},{"location":"security/#security-policy","text":"","title":"Security Policy"},{"location":"security/#reporting-a-vulnerability","text":"If you find a security vulnerability in the Cirrus CI platform (the backend, web interface, etc.), please follow the steps below . Do NOT comment about the vulnerability publicly. Please email hello@cirruslabs.org with the following format: Subject: Platform Security Risk HOW TO EXPLOIT Give exact details so our team can replicate it. OTHER INFORMATION If anything else needs to be said, put it here. Please be patient. You will get an email back soon. Thank you!","title":"Reporting a Vulnerability"},{"location":"support/","text":"Support \u00b6 The best way to ask general questions about a particular use cases is to email us at support+ci@cirruslabs.org . If you have a feature request or noticed lack of some documentation please feel free to create a GitHub issue . Our support team will answer it by replying or updating documentation. Migration Assistance \u00b6 Cirrus Labs can help your team with migration to Cirrus CI. Our team will analyze your current needs and workflow in order to not only perform the migration, but also perform optimizations along the way to make sure your team's workflow is as optimal as it can possibly be. Our team has experience of optimizing developer experiences at companies like Airbnb and Twitter. Contact us at support+migration@cirruslabs.org .","title":"Support"},{"location":"support/#support","text":"The best way to ask general questions about a particular use cases is to email us at support+ci@cirruslabs.org . If you have a feature request or noticed lack of some documentation please feel free to create a GitHub issue . Our support team will answer it by replying or updating documentation.","title":"Support"},{"location":"support/#migration-assistance","text":"Cirrus Labs can help your team with migration to Cirrus CI. Our team will analyze your current needs and workflow in order to not only perform the migration, but also perform optimizations along the way to make sure your team's workflow is as optimal as it can possibly be. Our team has experience of optimizing developer experiences at companies like Airbnb and Twitter. Contact us at support+migration@cirruslabs.org .","title":"Migration Assistance"},{"location":"guide/FreeBSD/","text":"FreeBSD Virtual Machines \u00b6 It is possible to run FreeBSD Virtual Machines the same way one can run Linux containers on the FreeBSD Community Cluster. To accomplish this, use freebsd_instance in your .cirrus.yml : freebsd_instance : image_family : freebsd-13-0 task : install_script : pkg install -y ... script : ... Under the Hood Under the hood, a basic integration with Google Compute Engine is used and freebsd_instance is a syntactic sugar for the following compute_engine_instance configuration: compute_engine_instance : image_project : freebsd-org-cloud-dev image : family/freebsd-13-0 platform : freebsd List of available image families \u00b6 Any of the official FreeBSD VMs on Google Cloud Platform are supported. Here are a few of them which are self explanatory: freebsd-14-0-snap (14.0-SNAP) freebsd-13-0 (13.0-RELEASE) freebsd-12-2-snap (12.2-SNAP) freebsd-12-2 (12.2-RELEASE) freebsd-12-0 (12.0-RELEASE) freebsd-11-4 (11.4-RELEASE) freebsd-11-3-snap (11.3-STABLE) freebsd-11-3 (11.3-RELEASE, doesn't boot properly at the moment) It's also possible to specify a concrete version of an image by name via image_name field. To get a full list of available images please run the following gcloud command: gcloud compute images list --project freebsd-org-cloud-dev --no-standard-images","title":"FreeBSD VMs"},{"location":"guide/FreeBSD/#freebsd-virtual-machines","text":"It is possible to run FreeBSD Virtual Machines the same way one can run Linux containers on the FreeBSD Community Cluster. To accomplish this, use freebsd_instance in your .cirrus.yml : freebsd_instance : image_family : freebsd-13-0 task : install_script : pkg install -y ... script : ... Under the Hood Under the hood, a basic integration with Google Compute Engine is used and freebsd_instance is a syntactic sugar for the following compute_engine_instance configuration: compute_engine_instance : image_project : freebsd-org-cloud-dev image : family/freebsd-13-0 platform : freebsd","title":"FreeBSD Virtual Machines"},{"location":"guide/FreeBSD/#list-of-available-image-families","text":"Any of the official FreeBSD VMs on Google Cloud Platform are supported. Here are a few of them which are self explanatory: freebsd-14-0-snap (14.0-SNAP) freebsd-13-0 (13.0-RELEASE) freebsd-12-2-snap (12.2-SNAP) freebsd-12-2 (12.2-RELEASE) freebsd-12-0 (12.0-RELEASE) freebsd-11-4 (11.4-RELEASE) freebsd-11-3-snap (11.3-STABLE) freebsd-11-3 (11.3-RELEASE, doesn't boot properly at the moment) It's also possible to specify a concrete version of an image by name via image_name field. To get a full list of available images please run the following gcloud command: gcloud compute images list --project freebsd-org-cloud-dev --no-standard-images","title":"List of available image families"},{"location":"guide/build-life/","text":"Any build starts with a change pushed to GitHub. Since Cirrus CI is a GitHub Application, a webhook event will be triggered by GitHub. From the webhook event, Cirrus CI will parse a Git branch and the SHA for the change. Based on said information, a new build will be created. After build creation Cirrus CI will use GitHub's APIs to download a content of .cirrus.yml file for the SHA. Cirrus CI will evaluate it and create corresponding tasks. These tasks (defined in the .cirrus.yml file) will be dispatched within Cirrus CI to different services responsible for scheduling on a supported computing service . Cirrus CI's scheduling service will use appropriate APIs to create and manage a VM instance or a Docker container on the particular computing service. The scheduling service will also configure start-up script that downloads the Cirrus CI agent, configures it to send logs back and starts it. Cirrus CI agent is a self-contained executable written in Go which means it can be executed anywhere. Cirrus CI's agent will request commands to execute for a particular task and will stream back logs, caches, artifacts and exit codes of the commands upon execution. Once the task finishes, the scheduling service will clean up the used VM or container. This is a diagram of how Cirrus CI schedules a task on Google Cloud Platform (the community cluster's engine). The blue arrows represent API calls and the green arrows represent unidirectional communication between an agent inside a VM or a container and Cirrus CI. Other chores such as health checking of the agent and GitHub status reporting happen in real time as a task is running. Straight forward and nothing magical. For any questions, feel free to contact us .","title":"Life of a Build"},{"location":"guide/custom-vms/","text":"Custom Compute Engine VMs \u00b6 Cirrus CI supports many different compute services when you bring your own infrastructure, but internally at Cirrus Labs we use Google Cloud Platform for running all managed by us instances except macos_instance . Already things like Docker Builder and freebsd_instance are basically a syntactic sugar for launching Compute Engine instances from a particular limited set of images. With compute_engine_instance it is possible to use any publicly available image for running your Cirrus tasks in. Such instances are particularly useful when you can't use Docker containers, for example, when you need to test things against newer versions of Linux kernel then the Docker host has. Here is an example of using a compute_engine_instance to run a VM with KVM available: compute_engine_instance : image_project : cirrus-images # GCP project image : family/docker-kvm # family or a full image name. platform : linux cpu : 4 # optional. Defaults to 2 CPUs. memory : 16G # optional. Defaults to 4G. disk : 100 # optional. By default, uses the smallest disk size required by the image. nested_virtualization : true # optional. Whether to enable Intel VT-x. Defaults to false. Nested Virtualization License Make sure that your source image already has a necessary license . Otherwise, nested virtualization won't work. Building custom image for Compute Engine \u00b6 We recommend to use Packer for building your custom images. As an example, please take a look at our Packer templates used for building Docker Builder VM image. After building your image, please make sure the image publicly available : gcloud compute images add-iam-policy-binding $IMAGE_NAME \\ --member = 'allAuthenticatedUsers' \\ --role = 'roles/compute.imageUser'","title":"Custom VMs"},{"location":"guide/custom-vms/#custom-compute-engine-vms","text":"Cirrus CI supports many different compute services when you bring your own infrastructure, but internally at Cirrus Labs we use Google Cloud Platform for running all managed by us instances except macos_instance . Already things like Docker Builder and freebsd_instance are basically a syntactic sugar for launching Compute Engine instances from a particular limited set of images. With compute_engine_instance it is possible to use any publicly available image for running your Cirrus tasks in. Such instances are particularly useful when you can't use Docker containers, for example, when you need to test things against newer versions of Linux kernel then the Docker host has. Here is an example of using a compute_engine_instance to run a VM with KVM available: compute_engine_instance : image_project : cirrus-images # GCP project image : family/docker-kvm # family or a full image name. platform : linux cpu : 4 # optional. Defaults to 2 CPUs. memory : 16G # optional. Defaults to 4G. disk : 100 # optional. By default, uses the smallest disk size required by the image. nested_virtualization : true # optional. Whether to enable Intel VT-x. Defaults to false. Nested Virtualization License Make sure that your source image already has a necessary license . Otherwise, nested virtualization won't work.","title":"Custom Compute Engine VMs"},{"location":"guide/custom-vms/#building-custom-image-for-compute-engine","text":"We recommend to use Packer for building your custom images. As an example, please take a look at our Packer templates used for building Docker Builder VM image. After building your image, please make sure the image publicly available : gcloud compute images add-iam-policy-binding $IMAGE_NAME \\ --member = 'allAuthenticatedUsers' \\ --role = 'roles/compute.imageUser'","title":"Building custom image for Compute Engine"},{"location":"guide/docker-builder-vm/","text":"Docker Builder VM \u00b6 \"Docker Builder\" tasks are a way to build and publish Docker Images to Docker Registries of your choice using a VM as build environment. In essence, a docker_builder is basically a task that is executed in a VM with pre-installed Docker. A docker_builder can be defined the same way as a task : docker_builder : build_script : docker build --tag myrepo/foo:latest . Leveraging features such as Task Dependencies , Conditional Execution and Encrypted Variables with a Docker Builder can help building relatively complex pipelines. It can also be used to execute builds which need special privileges. In the example below, a docker_builder will be only executed on a tag creation, once both test and lint tasks have finished successfully: test_task : ... lint_task : ... docker_builder : only_if : $CIRRUS_TAG != '' depends_on : - test - lint env : DOCKER_USERNAME : ENCRYPTED[...] DOCKER_PASSWORD : ENCRYPTED[...] build_script : docker build --tag myrepo/foo:$CIRRUS_TAG . login_script : docker login --username $DOCKER_USERNAME --password $DOCKER_PASSWORD push_script : docker push myrepo/foo:$CIRRUS_TAG Example For more examples please check how we use Docker Builder to build and publish Cirrus CI's Docker Images for Android . Multi-arch builds \u00b6 Docker Builder VM has QEMU pre-installed and is able to execute multi-arch builds via buildx . Add the following setup_script to enable buildx and then use docker buildx build instead of the regular docker build : docker_builder : setup_script : - docker buildx create --name multibuilder - docker buildx use multibuilder - docker buildx inspect --bootstrap build_script : docker buildx build --platform linux/amd64,linux/arm64 --tag myrepo/foo:$CIRRUS_TAG . Pre-installed Packages \u00b6 For your convenience, a Docker Builder VM has some common packages pre-installed: AWS CLI Docker Compose Heroku CLI OpenJDK 11 Python Ruby with Bundler Under the hood \u00b6 Under the hood a simple integration with Google Compute Engine is used and basically docker_builder is a syntactic sugar for the following compute_engine_instance configuration: task : compute_engine_instance : image_project : cirrus-images image : family/docker-builder platform : linux cpu : 4 memory : 16G You can check Packer templates of the VM image in cirruslabs/vm-images repository . Layer Caching \u00b6 Docker has the --cache-from flag which allows using a previously built image as a cache source. This way only changed layers will be rebuilt which can drastically improve performance of the build_script . Here is a snippet that uses the --cache-from flag: # pull an image if available docker pull myrepo/foo:latest || true docker build --cache-from myrepo/foo:latest \\ --tag myrepo/foo: $CIRRUS_TAG \\ --tag myrepo/foo:latest . Dockerfile as a CI environment \u00b6 With Docker Builder there is no need to build and push custom containers so they can be used as an environment to run CI tasks in. Cirrus CI can do it for you! Just declare a path to a Dockerfile with the dockerfile field for your container ( arm_container s are not supported yet) declaration in your .cirrus.yml like this: efficient_task : container : dockerfile : ci/Dockerfile docker_arguments : foo : bar test_script : ... inefficient_task : container : image : node:latest setup_script : - apt-get update - apt-get install build-essential test_script : ... Cirrus CI will build a container and cache the resulting image based on Dockerfile \u2019s content. On the next build, Cirrus CI will check if a container was already built, and if so, Cirrus CI will instantly start a CI task using the cached image. Under the hood, for every Dockerfile that is needed to be built, Cirrus CI will create a Docker Builder task as a dependency. You will see such build_docker_image_HASH tasks in the UI. Danger of using COPY and ADD instructions Cirrus doesn't include files added or copied into a container image in the cache key. This means that for a public repository a potential bad actor can create a PR with malicious scripts included into a container, wait for it to be cached and then reset the PR so it looks harmless. Using with private GKE clusters To use dockerfile with gke_container you first need to create a VM with Docker installed within your GCP project. This image will be used to perform building of Docker images for caching. Once this image is available, for example, by MY_DOCKER_VM name, you can use it like this: gke_container : dockerfile : .ci/Dockerfile builder_image_name : MY_DOCKER_VM cluster_name : cirrus-ci-cluster zone : us-central1-a namespace : default If your builder image is stored in another project you can also specify it by using builder_image_project field. By default, Cirrus CI assumes builder image is stored within the same project as the GKE cluster. Windows Support \u00b6 Docker builders also support building Windows Docker containers - use the platform and os_version fields: docker_builder : platform : windows os_version : 2019 ... Supported OS Versions See Windows Containers documentation for a list of supported OS versions.","title":"Docker Builder on VM"},{"location":"guide/docker-builder-vm/#docker-builder-vm","text":"\"Docker Builder\" tasks are a way to build and publish Docker Images to Docker Registries of your choice using a VM as build environment. In essence, a docker_builder is basically a task that is executed in a VM with pre-installed Docker. A docker_builder can be defined the same way as a task : docker_builder : build_script : docker build --tag myrepo/foo:latest . Leveraging features such as Task Dependencies , Conditional Execution and Encrypted Variables with a Docker Builder can help building relatively complex pipelines. It can also be used to execute builds which need special privileges. In the example below, a docker_builder will be only executed on a tag creation, once both test and lint tasks have finished successfully: test_task : ... lint_task : ... docker_builder : only_if : $CIRRUS_TAG != '' depends_on : - test - lint env : DOCKER_USERNAME : ENCRYPTED[...] DOCKER_PASSWORD : ENCRYPTED[...] build_script : docker build --tag myrepo/foo:$CIRRUS_TAG . login_script : docker login --username $DOCKER_USERNAME --password $DOCKER_PASSWORD push_script : docker push myrepo/foo:$CIRRUS_TAG Example For more examples please check how we use Docker Builder to build and publish Cirrus CI's Docker Images for Android .","title":"Docker Builder VM"},{"location":"guide/docker-builder-vm/#multi-arch-builds","text":"Docker Builder VM has QEMU pre-installed and is able to execute multi-arch builds via buildx . Add the following setup_script to enable buildx and then use docker buildx build instead of the regular docker build : docker_builder : setup_script : - docker buildx create --name multibuilder - docker buildx use multibuilder - docker buildx inspect --bootstrap build_script : docker buildx build --platform linux/amd64,linux/arm64 --tag myrepo/foo:$CIRRUS_TAG .","title":"Multi-arch builds"},{"location":"guide/docker-builder-vm/#pre-installed-packages","text":"For your convenience, a Docker Builder VM has some common packages pre-installed: AWS CLI Docker Compose Heroku CLI OpenJDK 11 Python Ruby with Bundler","title":"Pre-installed Packages"},{"location":"guide/docker-builder-vm/#under-the-hood","text":"Under the hood a simple integration with Google Compute Engine is used and basically docker_builder is a syntactic sugar for the following compute_engine_instance configuration: task : compute_engine_instance : image_project : cirrus-images image : family/docker-builder platform : linux cpu : 4 memory : 16G You can check Packer templates of the VM image in cirruslabs/vm-images repository .","title":"Under the hood"},{"location":"guide/docker-builder-vm/#layer-caching","text":"Docker has the --cache-from flag which allows using a previously built image as a cache source. This way only changed layers will be rebuilt which can drastically improve performance of the build_script . Here is a snippet that uses the --cache-from flag: # pull an image if available docker pull myrepo/foo:latest || true docker build --cache-from myrepo/foo:latest \\ --tag myrepo/foo: $CIRRUS_TAG \\ --tag myrepo/foo:latest .","title":"Layer Caching"},{"location":"guide/docker-builder-vm/#dockerfile-as-a-ci-environment","text":"With Docker Builder there is no need to build and push custom containers so they can be used as an environment to run CI tasks in. Cirrus CI can do it for you! Just declare a path to a Dockerfile with the dockerfile field for your container ( arm_container s are not supported yet) declaration in your .cirrus.yml like this: efficient_task : container : dockerfile : ci/Dockerfile docker_arguments : foo : bar test_script : ... inefficient_task : container : image : node:latest setup_script : - apt-get update - apt-get install build-essential test_script : ... Cirrus CI will build a container and cache the resulting image based on Dockerfile \u2019s content. On the next build, Cirrus CI will check if a container was already built, and if so, Cirrus CI will instantly start a CI task using the cached image. Under the hood, for every Dockerfile that is needed to be built, Cirrus CI will create a Docker Builder task as a dependency. You will see such build_docker_image_HASH tasks in the UI. Danger of using COPY and ADD instructions Cirrus doesn't include files added or copied into a container image in the cache key. This means that for a public repository a potential bad actor can create a PR with malicious scripts included into a container, wait for it to be cached and then reset the PR so it looks harmless. Using with private GKE clusters To use dockerfile with gke_container you first need to create a VM with Docker installed within your GCP project. This image will be used to perform building of Docker images for caching. Once this image is available, for example, by MY_DOCKER_VM name, you can use it like this: gke_container : dockerfile : .ci/Dockerfile builder_image_name : MY_DOCKER_VM cluster_name : cirrus-ci-cluster zone : us-central1-a namespace : default If your builder image is stored in another project you can also specify it by using builder_image_project field. By default, Cirrus CI assumes builder image is stored within the same project as the GKE cluster.","title":"Dockerfile as a CI environment"},{"location":"guide/docker-builder-vm/#windows-support","text":"Docker builders also support building Windows Docker containers - use the platform and os_version fields: docker_builder : platform : windows os_version : 2019 ... Supported OS Versions See Windows Containers documentation for a list of supported OS versions.","title":"Windows Support"},{"location":"guide/docker-builds-on-kubernetes/","text":"Docker Builds on Kubernetes \u00b6 Besides the ability to build docker images using a dedicated docker_builder task which runs on VMs, it is also possible to run docker builds on Kubernetes. To do so we are leveraging the additional_containers and docker-in-docker functionality. Currently Cirrus CI supports running builds on these Kubernetes distributions: Google Kubernetes Engine (GKE) AWS Elastic Kubernetes Service (EKS) For Generic Kubernetes Support follow this issue . Comparison of docker builds on VMs vs Kubernetes \u00b6 VMs complex builds are potentially faster than docker-in-docker safer due to better isolation between builds Kubernetes much faster start - creating a new container usually takes few seconds vs creating a VM which takes usually about a minute on GCP and even longer on AWS. ability to use an image with your custom tools image (e.g. containing Skaffold) to invoke docker instead of using a fixed VM image. How to \u00b6 This a full example of how to build a docker image on GKE using docker and pushing it to GCR. While not required, the script section in this example also has some best practice cache optimizations and pushes the image to GCR. AWS EKS support While the steps below are specifically written for and tested with GKE (Google Kubernetes Engine), it should work equally on AWS EKS. docker_build_task : gke_container : # for AWS, replace this with `aks_container` image : docker:latest # This image can be any custom image. The only hard requirement is that it needs to have `docker-cli` installed. cluster_name : cirrus-ci-cluster # your gke cluster name zone : us-central1-b # zone of the cluster namespace : cirrus-ci # namespace to use cpu : 1 memory : 1500Mb additional_containers : - name : dockerdaemon privileged : true # docker-in-docker needs to run in privileged mode cpu : 4 memory : 3500Mb image : docker:dind port : 2375 env : DOCKER_DRIVER : overlay2 # this speeds up the build env : DOCKER_HOST : tcp://localhost:2375 # this is required so that docker cli commands connect to the \"additional container\" instead of `docker.sock`. GOOGLE_CREDENTIALS : ENCRYPTED[qwerty239abc] # this should contain the json key for a gcp service account with the `roles/storage.admin` role on the `artifacts.<your_gcp_project>.appspot.com` bucket as described here https://cloud.google.com/container-registry/docs/access-control. This is only required if you want to pull / push to gcr. If we use dockerhub you need to use different credentials. login_script : echo $GOOGLE_CREDENTIALS | docker login -u _json_key --password-stdin https://gcr.io build_script : - docker pull gcr.io/my-project/my-app:$CIRRUS_LAST_GREEN_CHANGE || true - docker build --cache-from=gcr.io/my-project/my-app:$CIRRUS_LAST_GREEN_CHANGE -t gcr.io/my-project/my-app:$CIRRUS_CHANGE_IN_REPO . push_script : - docker push gcr.io/my-project/my-app:$CIRRUS_CHANGE_IN_REPO Caveats \u00b6 Since the additional_container needs to run in privileged mode, the isolation between the Docker build and the host are somewhat limited, you should create a separate cluster for Cirrus CI builds ideally. If this a concern you can also try out Kaniko or Makisu to run builds in unprivileged containers.","title":"Docker Builds on GKE"},{"location":"guide/docker-builds-on-kubernetes/#docker-builds-on-kubernetes","text":"Besides the ability to build docker images using a dedicated docker_builder task which runs on VMs, it is also possible to run docker builds on Kubernetes. To do so we are leveraging the additional_containers and docker-in-docker functionality. Currently Cirrus CI supports running builds on these Kubernetes distributions: Google Kubernetes Engine (GKE) AWS Elastic Kubernetes Service (EKS) For Generic Kubernetes Support follow this issue .","title":"Docker Builds on Kubernetes"},{"location":"guide/docker-builds-on-kubernetes/#comparison-of-docker-builds-on-vms-vs-kubernetes","text":"VMs complex builds are potentially faster than docker-in-docker safer due to better isolation between builds Kubernetes much faster start - creating a new container usually takes few seconds vs creating a VM which takes usually about a minute on GCP and even longer on AWS. ability to use an image with your custom tools image (e.g. containing Skaffold) to invoke docker instead of using a fixed VM image.","title":"Comparison of docker builds on VMs vs Kubernetes"},{"location":"guide/docker-builds-on-kubernetes/#how-to","text":"This a full example of how to build a docker image on GKE using docker and pushing it to GCR. While not required, the script section in this example also has some best practice cache optimizations and pushes the image to GCR. AWS EKS support While the steps below are specifically written for and tested with GKE (Google Kubernetes Engine), it should work equally on AWS EKS. docker_build_task : gke_container : # for AWS, replace this with `aks_container` image : docker:latest # This image can be any custom image. The only hard requirement is that it needs to have `docker-cli` installed. cluster_name : cirrus-ci-cluster # your gke cluster name zone : us-central1-b # zone of the cluster namespace : cirrus-ci # namespace to use cpu : 1 memory : 1500Mb additional_containers : - name : dockerdaemon privileged : true # docker-in-docker needs to run in privileged mode cpu : 4 memory : 3500Mb image : docker:dind port : 2375 env : DOCKER_DRIVER : overlay2 # this speeds up the build env : DOCKER_HOST : tcp://localhost:2375 # this is required so that docker cli commands connect to the \"additional container\" instead of `docker.sock`. GOOGLE_CREDENTIALS : ENCRYPTED[qwerty239abc] # this should contain the json key for a gcp service account with the `roles/storage.admin` role on the `artifacts.<your_gcp_project>.appspot.com` bucket as described here https://cloud.google.com/container-registry/docs/access-control. This is only required if you want to pull / push to gcr. If we use dockerhub you need to use different credentials. login_script : echo $GOOGLE_CREDENTIALS | docker login -u _json_key --password-stdin https://gcr.io build_script : - docker pull gcr.io/my-project/my-app:$CIRRUS_LAST_GREEN_CHANGE || true - docker build --cache-from=gcr.io/my-project/my-app:$CIRRUS_LAST_GREEN_CHANGE -t gcr.io/my-project/my-app:$CIRRUS_CHANGE_IN_REPO . push_script : - docker push gcr.io/my-project/my-app:$CIRRUS_CHANGE_IN_REPO","title":"How to"},{"location":"guide/docker-builds-on-kubernetes/#caveats","text":"Since the additional_container needs to run in privileged mode, the isolation between the Docker build and the host are somewhat limited, you should create a separate cluster for Cirrus CI builds ideally. If this a concern you can also try out Kaniko or Makisu to run builds in unprivileged containers.","title":"Caveats"},{"location":"guide/docker-pipe/","text":"Docker Pipe is a way to execute each instruction in its own Docker container while persisting working directory between each of the containers. For example, you can build your application in one container, run some lint tools in another containers and finally deploy your app via CLI from another container. No need to create huge containers with every single tool pre-installed! A pipe can be defined the same way as a task with the only difference that instructions should be grouped under the steps field defining a Docker image for each step to be executed in. Here is an example of how we build and validate links for the Cirrus CI documentation that you are reading right now: pipe : name : Build Site and Validate Links steps : - image : squidfunk/mkdocs-material:latest build_script : mkdocs build - image : raviqqe/liche:latest # links validation tool in a separate container validate_script : /liche --document-root=site --recursive site/ Amount of CPU and memory that a pipe has access to can be configured with resources field: pipe : resources : cpu : 2.5 memory : 5G # ...","title":"Docker Pipe"},{"location":"guide/linux/","text":"Linux Containers \u00b6 Cirrus CI supports container and arm_container instances in order to run your CI workloads on amd64 and arm64 platforms respectively. Cirrus CI uses Kubernetes clusters running in different clouds that are the most suitable for running each platform: For container instances Cirrus CI uses a GKE cluster of compute-optimized instances running in Google Cloud. For arm_container instances Cirrus CI uses a EKS cluster of Graviton2 instances running in AWS. Community Clusters are configured the same way as anyone can configure a private Kubernetes cluster for their own repository. Cirrus CI supports connecting managed Kubernetes clusters from most of the cloud providers. Please check out all the supported computing services Cirrus CI can integrate with. By default, a container is given 2 CPUs and 4 GB of memory, but it can be configured in .cirrus.yml : amd64 container : image : openjdk:latest cpu : 4 memory : 12G task : script : ... arm64 arm_container : image : openjdk:latest cpu : 4 memory : 12G task : script : ... Containers on Community Cluster can use maximum 8.0 CPUs and up to 32 GB of memory. Memory limit is tied to the amount of CPUs requested. For each CPU you can't get more than 4G of memory. Tasks using Compute Credits has higher limits and can use up to 28.0 CPUs and 112G of memory respectively. Scheduling Times on Community Cluster Since Community Cluster is shared, scheduling times for containers can vary from time to time. Also, the smaller a container require resources the faster it will be scheduled. If you have a popular project and experiencing long scheduling times, don't hesitate to reach out to support and we can whitelist your repository for use of extra resources. Using in-memory disks Some I/O intensive tasks may benefit from using a tmpfs disk mounted as a working directory. Set use_in_memory_disk flag to enable in-memory disk for a container: amd64 task : name : Much I/O container : image : alpine:latest use_in_memory_disk : true arm64 task : name : Much I/O arm_container : image : alpine:latest use_in_memory_disk : true Note : any files you write including cloned repository will count against your task's memory limit. Privileged Access If you need to run privileged docker containers, take a look at the docker builder . Greedy instances Greedy instances can potentially use more CPU resources if available. Please check this blog post for more details. KVM-enabled Privileged Containers \u00b6 It is possible to run containers with KVM enabled. Some types of CI tasks can tremendously benefit from native virtualization. For example, Android related tasks can benefit from running hardware accelerated emulators instead of software emulated ARM emulators. In order to enable KVM module for your container s, add kvm: true to your container declaration. Here is an example of a task that runs hardware accelerated Android emulators: task : name : Integration Tests (x86) container : image : cirrusci/android-sdk:29 kvm : true accel_check_script : emulator -accel-check Limitations of KVM-enabled Containers Because of the additional virtualization layer, it takes about a minute to acquire the necessary resources to start such tasks. KVM-enabled containers are backed by dedicated VMs which restrict the amount of CPU resources that can be used. The value of cpu must be 1 or an even integer. Values like 0.5 or 3 are not supported for KVM-enabled containers Working with Private Registries \u00b6 It is possible to use private Docker registries with Cirrus CI to pull containers. To provide an access to a private registry of your choice you'll need to obtain a JSON Docker config file for your registry and create an encrypted variable for Cirrus CI to use. Let's check an example of setting up Oracle Container Registry in order to use Oracle Database in tests. First, you'll need to login with the registry by running the following command: docker login container-registry.oracle.com After a successful login, Docker config file located in ~/.docker/config.json will look something like this: { \"auths\" : { \"container-registry.oracle.com\" : { \"auth\" : \"....\" } } } If you don't see auth for your registry, it means your Docker installation is using a credentials store. In this case you can manually auth using a Base64 encoded string of your username and your PAT ( Personal Access Token ). Here's how to generate that: echo $USERNAME : $PAT | base64 Create an encrypted variable from the Docker config and put in .cirrus.yml : registry_config : ENCRYPTED[...] Now Cirrus CI will be able to pull images from Oracle Container Registry: registry_config : ENCRYPTED[...] test_task : container : image : bigtruedata/sbt:latest additional_containers : - name : oracle image : container-registry.oracle.com/database/standard:latest port : 1521 cpu : 1 memory : 8G build_script : ./build/build.sh","title":"Linux Containers"},{"location":"guide/linux/#linux-containers","text":"Cirrus CI supports container and arm_container instances in order to run your CI workloads on amd64 and arm64 platforms respectively. Cirrus CI uses Kubernetes clusters running in different clouds that are the most suitable for running each platform: For container instances Cirrus CI uses a GKE cluster of compute-optimized instances running in Google Cloud. For arm_container instances Cirrus CI uses a EKS cluster of Graviton2 instances running in AWS. Community Clusters are configured the same way as anyone can configure a private Kubernetes cluster for their own repository. Cirrus CI supports connecting managed Kubernetes clusters from most of the cloud providers. Please check out all the supported computing services Cirrus CI can integrate with. By default, a container is given 2 CPUs and 4 GB of memory, but it can be configured in .cirrus.yml : amd64 container : image : openjdk:latest cpu : 4 memory : 12G task : script : ... arm64 arm_container : image : openjdk:latest cpu : 4 memory : 12G task : script : ... Containers on Community Cluster can use maximum 8.0 CPUs and up to 32 GB of memory. Memory limit is tied to the amount of CPUs requested. For each CPU you can't get more than 4G of memory. Tasks using Compute Credits has higher limits and can use up to 28.0 CPUs and 112G of memory respectively. Scheduling Times on Community Cluster Since Community Cluster is shared, scheduling times for containers can vary from time to time. Also, the smaller a container require resources the faster it will be scheduled. If you have a popular project and experiencing long scheduling times, don't hesitate to reach out to support and we can whitelist your repository for use of extra resources. Using in-memory disks Some I/O intensive tasks may benefit from using a tmpfs disk mounted as a working directory. Set use_in_memory_disk flag to enable in-memory disk for a container: amd64 task : name : Much I/O container : image : alpine:latest use_in_memory_disk : true arm64 task : name : Much I/O arm_container : image : alpine:latest use_in_memory_disk : true Note : any files you write including cloned repository will count against your task's memory limit. Privileged Access If you need to run privileged docker containers, take a look at the docker builder . Greedy instances Greedy instances can potentially use more CPU resources if available. Please check this blog post for more details.","title":"Linux Containers"},{"location":"guide/linux/#kvm-enabled-privileged-containers","text":"It is possible to run containers with KVM enabled. Some types of CI tasks can tremendously benefit from native virtualization. For example, Android related tasks can benefit from running hardware accelerated emulators instead of software emulated ARM emulators. In order to enable KVM module for your container s, add kvm: true to your container declaration. Here is an example of a task that runs hardware accelerated Android emulators: task : name : Integration Tests (x86) container : image : cirrusci/android-sdk:29 kvm : true accel_check_script : emulator -accel-check Limitations of KVM-enabled Containers Because of the additional virtualization layer, it takes about a minute to acquire the necessary resources to start such tasks. KVM-enabled containers are backed by dedicated VMs which restrict the amount of CPU resources that can be used. The value of cpu must be 1 or an even integer. Values like 0.5 or 3 are not supported for KVM-enabled containers","title":"KVM-enabled Privileged Containers"},{"location":"guide/linux/#working-with-private-registries","text":"It is possible to use private Docker registries with Cirrus CI to pull containers. To provide an access to a private registry of your choice you'll need to obtain a JSON Docker config file for your registry and create an encrypted variable for Cirrus CI to use. Let's check an example of setting up Oracle Container Registry in order to use Oracle Database in tests. First, you'll need to login with the registry by running the following command: docker login container-registry.oracle.com After a successful login, Docker config file located in ~/.docker/config.json will look something like this: { \"auths\" : { \"container-registry.oracle.com\" : { \"auth\" : \"....\" } } } If you don't see auth for your registry, it means your Docker installation is using a credentials store. In this case you can manually auth using a Base64 encoded string of your username and your PAT ( Personal Access Token ). Here's how to generate that: echo $USERNAME : $PAT | base64 Create an encrypted variable from the Docker config and put in .cirrus.yml : registry_config : ENCRYPTED[...] Now Cirrus CI will be able to pull images from Oracle Container Registry: registry_config : ENCRYPTED[...] test_task : container : image : bigtruedata/sbt:latest additional_containers : - name : oracle image : container-registry.oracle.com/database/standard:latest port : 1521 cpu : 1 memory : 8G build_script : ./build/build.sh","title":"Working with Private Registries"},{"location":"guide/macOS/","text":"macOS Virtual Machines \u00b6 It is possible to run macOS Virtual Machines (like how one can run Linux containers ) on the macOS Community Cluster. Use macos_instance in your .cirrus.yml files: macos_instance : image : big-sur-base task : script : echo \"Hello World from macOS!\" List of available images \u00b6 macOS Big Sur \u00b6 big-sur-base - vanilla macOS with Brew and Command Line Tools pre-installed. big-sur-xcode-NN - based of catalina-base with Xcode NN and couple other packages pre-installed: cocoapods , fastlane , rake and xctool . Flutter and Android SDK/NDK are also pre-installed.** List of available Xcode versions: big-sur-xcode-12.3 big-sur-xcode-12.4 big-sur-xcode-12.5 big-sur-xcode-13 Note that there is a big-sur-xcode alias available to always reference to the latest stable big-sur-xcode-NN image. macOS Catalina \u00b6 catalina-base - vanilla macOS with Brew and Command Line Tools pre-installed. catalina-xcode-NN - based of catalina-base with Xcode NN and couple other packages pre-installed: cocoapods , fastlane , rake and xctool . Starting from Xcode 12.1 Flutter and Android SDK/NDK are also pre-installed. catalina-xcode-NN-flutter ( deprecated since Xcode 12.1) - based of catalina-xcode-NN with pre-installed Flutter and Android SDK/NDK. List of available Xcode versions: catalina-xcode-11.3.1 catalina-xcode-11.4.1 catalina-xcode-11.5 catalina-xcode-11.6 catalina-xcode-12.0 catalina-xcode-12.1 catalina-xcode-12.2 Note that there are a couple of aliases available for images: catalina-xcode - point to the latest stable catalina-xcode-NN image. catalina-flutter - point to the latest image with. How images are built \u00b6 Please refer to the osx-images repository on how the images were built and don't hesitate to create issues if current images are missing something. Underlying Technology Under the hood Cirrus CI is using Cirrus CI's own Persistent Workers . See more details in out blog post .","title":"macOS VMs"},{"location":"guide/macOS/#macos-virtual-machines","text":"It is possible to run macOS Virtual Machines (like how one can run Linux containers ) on the macOS Community Cluster. Use macos_instance in your .cirrus.yml files: macos_instance : image : big-sur-base task : script : echo \"Hello World from macOS!\"","title":"macOS Virtual Machines"},{"location":"guide/macOS/#list-of-available-images","text":"","title":"List of available images"},{"location":"guide/macOS/#macos-big-sur","text":"big-sur-base - vanilla macOS with Brew and Command Line Tools pre-installed. big-sur-xcode-NN - based of catalina-base with Xcode NN and couple other packages pre-installed: cocoapods , fastlane , rake and xctool . Flutter and Android SDK/NDK are also pre-installed.** List of available Xcode versions: big-sur-xcode-12.3 big-sur-xcode-12.4 big-sur-xcode-12.5 big-sur-xcode-13 Note that there is a big-sur-xcode alias available to always reference to the latest stable big-sur-xcode-NN image.","title":"macOS Big Sur"},{"location":"guide/macOS/#macos-catalina","text":"catalina-base - vanilla macOS with Brew and Command Line Tools pre-installed. catalina-xcode-NN - based of catalina-base with Xcode NN and couple other packages pre-installed: cocoapods , fastlane , rake and xctool . Starting from Xcode 12.1 Flutter and Android SDK/NDK are also pre-installed. catalina-xcode-NN-flutter ( deprecated since Xcode 12.1) - based of catalina-xcode-NN with pre-installed Flutter and Android SDK/NDK. List of available Xcode versions: catalina-xcode-11.3.1 catalina-xcode-11.4.1 catalina-xcode-11.5 catalina-xcode-11.6 catalina-xcode-12.0 catalina-xcode-12.1 catalina-xcode-12.2 Note that there are a couple of aliases available for images: catalina-xcode - point to the latest stable catalina-xcode-NN image. catalina-flutter - point to the latest image with.","title":"macOS Catalina"},{"location":"guide/macOS/#how-images-are-built","text":"Please refer to the osx-images repository on how the images were built and don't hesitate to create issues if current images are missing something. Underlying Technology Under the hood Cirrus CI is using Cirrus CI's own Persistent Workers . See more details in out blog post .","title":"How images are built"},{"location":"guide/notifications/","text":"Cirrus CI itself doesn't have built-in mechanism to send notifications but, since Cirrus CI is following best practices of integrating with GitHub, it's possible to configure a GitHub action that will send any kind of notifications. Here is a full list of curated Cirrus Actions for GitHub including ones to send notifications: cirrus-actions . Email Action \u00b6 It's possible to facilitate GitHub Action's own email notification mechanism to send emails about Cirrus CI failures. To enable it, add the following .github/workflows/email.yml workflow file: on : check_suite : type : [ 'completed' ] name : Email about Cirrus CI failures jobs : continue : name : After Cirrus CI Failure if : github.event.check_suite.app.name == 'Cirrus CI' && github.event.check_suite.conclusion != 'success' runs-on : ubuntu-latest steps : - uses : octokit/request-action@v2.x id : get_failed_check_run with : route : GET /repos/${{ github.repository }}/check-suites/${{ github.event.check_suite.id }}/check-runs?status=completed mediaType : '{\"previews\": [\"antiope\"]}' env : GITHUB_TOKEN : ${{ secrets.GITHUB_TOKEN }} - run : | echo \"Cirrus CI ${{ github.event.check_suite.conclusion }} on ${{ github.event.check_suite.head_branch }} branch!\" echo \"SHA ${{ github.event.check_suite.head_sha }}\" echo $MESSAGE echo \"##[error]See $CHECK_RUN_URL for details\" && false env : CHECK_RUN_URL : ${{ fromJson(steps.get_failed_check_run.outputs.data).check_runs[0].html_url }}","title":"Notifications"},{"location":"guide/notifications/#email-action","text":"It's possible to facilitate GitHub Action's own email notification mechanism to send emails about Cirrus CI failures. To enable it, add the following .github/workflows/email.yml workflow file: on : check_suite : type : [ 'completed' ] name : Email about Cirrus CI failures jobs : continue : name : After Cirrus CI Failure if : github.event.check_suite.app.name == 'Cirrus CI' && github.event.check_suite.conclusion != 'success' runs-on : ubuntu-latest steps : - uses : octokit/request-action@v2.x id : get_failed_check_run with : route : GET /repos/${{ github.repository }}/check-suites/${{ github.event.check_suite.id }}/check-runs?status=completed mediaType : '{\"previews\": [\"antiope\"]}' env : GITHUB_TOKEN : ${{ secrets.GITHUB_TOKEN }} - run : | echo \"Cirrus CI ${{ github.event.check_suite.conclusion }} on ${{ github.event.check_suite.head_branch }} branch!\" echo \"SHA ${{ github.event.check_suite.head_sha }}\" echo $MESSAGE echo \"##[error]See $CHECK_RUN_URL for details\" && false env : CHECK_RUN_URL : ${{ fromJson(steps.get_failed_check_run.outputs.data).check_runs[0].html_url }}","title":"Email Action"},{"location":"guide/persistent-workers/","text":"Persistent Workers \u00b6 Introduction \u00b6 Cirrus CI pioneered an idea of directly using compute services instead of requiring users to manage their own infrastructure, configuring servers for running CI jobs, performing upgrades, etc. Instead, Cirrus CI just uses APIs of cloud providers to create virtual machines or containers on demand. This fundamental design difference has multiple benefits comparing to more traditional CIs: Ephemeral environment. Each Cirrus CI task starts in a fresh VM or a container without any state left by previous tasks. Infrastructure as code. All VM versions and container tags are specified in .cirrus.yml configuration file in your Git repository. For any revision in the past Cirrus tasks can be identically reproduced at any point in time in the future using the exact versions of VMs or container tags specified in .cirrus.yml at the particular revision. Just imagine how difficult it is to do a security release for a 6 months old version if your CI environment independently changes. Predictability and cost efficiency. Cirrus CI uses elasticity of modern clouds and creates VMs and containers on demand only when they are needed for executing Cirrus tasks and deletes them right after. Immediately scale from 0 to hundreds or thousands of parallel Cirrus tasks without a need to over provision infrastructure or constantly monitor if your team has reached maximum parallelism of your current CI plan. What is a Persistent Worker \u00b6 For some use cases the traditional CI setup is still useful. However, not everything is available in the cloud. For example, Apple releases new ARM-based products and there is no virtualization yet available for the new hardware. Another use case is to test the hardware itself, since not everyone is working on websites and mobile apps after all! For such use cases it makes sense to go with a traditional CI setup: install some binary on the hardware which will constantly pull for new tasks and will execute them one after another. This is precisely what Persistent Workers for Cirrus CI are: a simple way to run Cirrus tasks beyond cloud! Configuration \u00b6 First, create a persistent workers pool for your personal account or a GitHub organization ( https://cirrus-ci.com/settings/github/<ORGANIZATION> ): Once a persistent worker is created, copy registration token of the pool and follow Cirrus CLI guide to configure a host that will be a persistent worker. Once configured, target task execution on a worker by using persistent_worker instance and matching by workers' labels: task : persistent_worker : labels : os : darwin arch : arm64 script : echo \"running on-premise\" Or remove labels filed if you want to target any worker: task : persistent_worker : {} script : echo \"running on-premise\" Isolation \u00b6 By default, a persistent worker spawns all the tasks on the same host machine it's being run. However, using the isolation field, a persistent worker can utilize a VM or a container engine to increase the separation between tasks and to unlock the ability to use different operating systems. Parallels \u00b6 To use this isolation type, install the Parallels Desktop on the persistent worker's host machine and create a base VM that will be later cloned for each task. This base VM needs to: be either in a stopped or suspended state provide SSH access on port 22 Here's an example of a configuration that will run the task inside of a fresh macOS virtual machine created from the big-sur-base base VM: persistent_worker : isolation : parallels : image : big-sur-base user : admin password : secret platform : darwin task : script : system_profiler Once the VM spins up, persistent worker will connect to the VM's IP-address over SSH using user and password credentials and run the latest agent version targeted for the platform . Container \u00b6 To use this isolation type, install and configure a container engine like Docker or Podman (essentially the ones supported by the Cirrus CLI ). Here's an example that runs a task in a separate container with a couple directories from the host machine being accessible: persistent_worker : isolation : container : image : debian:latest cpu : 24 memory : 128G volumes : - /path/on/host:/path/in/container - /tmp/persistent-cache:/tmp/cache:ro task : script : uname -a","title":"Persistent Workers"},{"location":"guide/persistent-workers/#persistent-workers","text":"","title":"Persistent Workers"},{"location":"guide/persistent-workers/#introduction","text":"Cirrus CI pioneered an idea of directly using compute services instead of requiring users to manage their own infrastructure, configuring servers for running CI jobs, performing upgrades, etc. Instead, Cirrus CI just uses APIs of cloud providers to create virtual machines or containers on demand. This fundamental design difference has multiple benefits comparing to more traditional CIs: Ephemeral environment. Each Cirrus CI task starts in a fresh VM or a container without any state left by previous tasks. Infrastructure as code. All VM versions and container tags are specified in .cirrus.yml configuration file in your Git repository. For any revision in the past Cirrus tasks can be identically reproduced at any point in time in the future using the exact versions of VMs or container tags specified in .cirrus.yml at the particular revision. Just imagine how difficult it is to do a security release for a 6 months old version if your CI environment independently changes. Predictability and cost efficiency. Cirrus CI uses elasticity of modern clouds and creates VMs and containers on demand only when they are needed for executing Cirrus tasks and deletes them right after. Immediately scale from 0 to hundreds or thousands of parallel Cirrus tasks without a need to over provision infrastructure or constantly monitor if your team has reached maximum parallelism of your current CI plan.","title":"Introduction"},{"location":"guide/persistent-workers/#what-is-a-persistent-worker","text":"For some use cases the traditional CI setup is still useful. However, not everything is available in the cloud. For example, Apple releases new ARM-based products and there is no virtualization yet available for the new hardware. Another use case is to test the hardware itself, since not everyone is working on websites and mobile apps after all! For such use cases it makes sense to go with a traditional CI setup: install some binary on the hardware which will constantly pull for new tasks and will execute them one after another. This is precisely what Persistent Workers for Cirrus CI are: a simple way to run Cirrus tasks beyond cloud!","title":"What is a Persistent Worker"},{"location":"guide/persistent-workers/#configuration","text":"First, create a persistent workers pool for your personal account or a GitHub organization ( https://cirrus-ci.com/settings/github/<ORGANIZATION> ): Once a persistent worker is created, copy registration token of the pool and follow Cirrus CLI guide to configure a host that will be a persistent worker. Once configured, target task execution on a worker by using persistent_worker instance and matching by workers' labels: task : persistent_worker : labels : os : darwin arch : arm64 script : echo \"running on-premise\" Or remove labels filed if you want to target any worker: task : persistent_worker : {} script : echo \"running on-premise\"","title":"Configuration"},{"location":"guide/persistent-workers/#isolation","text":"By default, a persistent worker spawns all the tasks on the same host machine it's being run. However, using the isolation field, a persistent worker can utilize a VM or a container engine to increase the separation between tasks and to unlock the ability to use different operating systems.","title":"Isolation"},{"location":"guide/persistent-workers/#parallels","text":"To use this isolation type, install the Parallels Desktop on the persistent worker's host machine and create a base VM that will be later cloned for each task. This base VM needs to: be either in a stopped or suspended state provide SSH access on port 22 Here's an example of a configuration that will run the task inside of a fresh macOS virtual machine created from the big-sur-base base VM: persistent_worker : isolation : parallels : image : big-sur-base user : admin password : secret platform : darwin task : script : system_profiler Once the VM spins up, persistent worker will connect to the VM's IP-address over SSH using user and password credentials and run the latest agent version targeted for the platform .","title":"Parallels"},{"location":"guide/persistent-workers/#container","text":"To use this isolation type, install and configure a container engine like Docker or Podman (essentially the ones supported by the Cirrus CLI ). Here's an example that runs a task in a separate container with a couple directories from the host machine being accessible: persistent_worker : isolation : container : image : debian:latest cpu : 24 memory : 128G volumes : - /path/on/host:/path/in/container - /tmp/persistent-cache:/tmp/cache:ro task : script : uname -a","title":"Container"},{"location":"guide/programming-tasks/","text":"Introduction into Starlark \u00b6 Most commonly, Cirrus tasks are declared in .cirrus.yml file in YAML format as documented in Writing Tasks guide. YAML, as a language, is great for declaring simple to moderate configurations, but sometimes just using a declarative language is not enough. One might need some conditional execution or have an easy way to generate multiple similar tasks. Most of the CIs solve this problem by introducing special DSL into the existing YAML. In case of Cirrus CI, we have only_if keyword for conditional execution and matrix modification for generating similar tasks. These options are mostly hacks to workaround declarative nature of YAML language where in reality an imperative language looks like a better fit. This is why Cirrus CI allows in additional to YAML configure tasks via Starlark. Starlark language is a procedural programming language originated from Bazel build tool , but ideal for embedding within any other system that want to safely allow user-defined logic. There are a few key differences which made us choose Starlark instead of common alternatives like JavaScript/TypeScript or WebAssembly: Starlark doesn't require compilation. No need to introduce full-blown compile and deploy process for a few dozen lines of logic. Starlark script can be executed instantly on any platform. There is Starlark interpreter written in Go which integrates nicely with Cirrus CLI and Cirrus CI infrastructure. Starlark has built-in functionality for loading external modules which is ideal for config sharing. See module loading for details. Writing Starlark scripts \u00b6 Let's start with a trivial .cirrus.star example like this: def main (): return [ { \"container\" : { \"image\" : \"debian:latest\" , }, \"script\" : \"make\" , }, ] With the module loading , you can re-use other people's code to avoid wasting time on things written from scratch. For example, with the official task helpers the example above can be refactored in: load ( \"github.com/cirrus-modules/helpers\" , \"task\" , \"container\" , \"script\" ) def main ( ctx ): return [ task ( instance = container ( \"debian:latest\" ), instructions = [ script ( \"make\" )] ), ] main() needs to return a list of task objects which will be serialized into YAML, like this: task : container : image : debian:latest script : make Then the generated YAML is appended to .cirrus.yml (if any) before passing the combined config into the final YAML parser. With Starlark, it's possible to generate parts of the configuration dynamically based on some external conditions: Parsing files inside the repository to pick up some common settings (for example, parse package.json to see if it contains lint script and generate a linting task). Making an HTTP request to check the previous build status. See a video tutorial on how to create a custom Cirrus module: Entrypoints \u00b6 Different events will trigger execution of different top-level functions in the .cirrus.star . These functions reserve certain names and will be called with different arguments depending on the event which triggered the execution. main() \u00b6 main() is called once a Cirrus CI build is triggered in order to generate a list of tasks to execute within that particular build: def main (): return [ { \"container\" : { \"image\" : \"debian:latest\" }, \"script\" : \"make test\" }, { \"container\" : { \"image\" : \"debian:latest\" }, \"script\" : \"make build\" } ] If you want to return multiple tasks with the same name or a top-level override like env , use the tuple syntax below: def main (): return [ ( \"env\" , { \"PARALLEL\" : \"yes\" }), ( \"container\" , { \"image\" : \"debian:latest\" }), ( \"task\" , { \"script\" : \"make build\" }), ( \"task\" , { \"script\" : \"make test\" }) ] In regard to top-level overrides, note that when using both YAML and Starlark configuration formats they get merged and the YAML configuration always comes first. Hooks \u00b6 It's also possible to execute Starlark scripts on updates to the current build or any of the tasks within the build. Think of it as WebHooks running within Cirrus that doesn't require any infrastructure on your end. Expected names of Starlark Hook functions in .cirrus.star are on_build_<STATUS> or on_task_<STATUS> respectively. Please refer to Cirrus CI GraphQL Schema for a full list of existing statuses, but most commonly on_build_failed / on_build_completed and on_task_failed / on_task_completed are used. These functions should expect a single context argument passed by Cirrus Cloud. At the moment hook's context only contains a single field payload containing the same payload as a webhook . One caveat of Starlark Hooks execution is CIRRUS_TOKEN environment variable that contains a token to access Cirrus API . Scope of CIRRUS_TOKEN is restricted to the build associated with that particular hook invocation and allows, for example, to automatically re-run tasks. Here is an example of a Starlark Hook that automatically re-runs a failed task in case a particular transient issue found in logs: # load some helpers from an external module load ( \"github.com/cirrus-modules/graphql\" , \"rerun_task_if_issue_in_logs\" ) def on_task_failed ( ctx ): if \"Test\" not in ctx . payload . data . task . name : return if ctx . payload . data . task . automaticReRun : print ( \"Task is already an automatic re-run! Won't even try to re-run it...\" ) return rerun_task_if_issue_in_logs ( ctx . payload . data . task . id , \"Time out\" ) Module loading \u00b6 Module loading is done through the Starlark's load() statement. Besides the ability to load builtins with it, Cirrus can load other .star files from local and remote locations to facilitate code re-use. Local \u00b6 Local loads are relative to the project's root (where .cirrus.star is located): load ( \".ci/notify-slack.star\" , \"notify_slack\" ) Remote from Git \u00b6 To load the default branch of the module from GitHub: load ( \"github.com/cirrus-modules/golang\" , \"task\" , \"container\" ) In the example above, the name of the .star file was not provided, because lib.star is assumed by default. This is equivalent to: load ( \"github.com/cirrus-modules/golang/lib.star@main\" , \"task\" , \"container\" ) You can also specify an exact commit hash instead of the main() branch name to prevent accidental changes. To load .star files from repositories other than GitHub, add a .git suffix at the end of the repository name, for example: load ( \"gitlab.com/fictional/repository.git/validator.star\" , \"validate\" ) ^^^^ note the suffix Builtins \u00b6 Cirrus CLI provides builtins all nested in the cirrus module that greatly extend what can be done with the Starlark alone. fs \u00b6 These builtins allow for read-only filesystem access. All paths are relative to the project's directory. fs.exists(path) \u00b6 Returns True if path exists and False otherwise. fs.read(path) \u00b6 Returns a string with the file contents or None if the file doesn't exist. Note that this is an error to read a directory with fs.read() . fs.readdir(dirpath) \u00b6 Returns a list of string 's with names of the entries in the directory. Note that this is an error to read a file with fs.readdir() . Example: load ( \"cirrus\" , \"fs\" ) def main ( ctx ): tasks = base_tasks () if fs . exists ( \"go.mod\" ): tasks += go_tasks () return tasks is_test \u00b6 While not technically a builtin, is_test is a bool that allows Starlark code to determine whether it's running in test environment via Cirrus CLI. This can be useful for limiting the test complexity, e.g. by not making a real HTTP request and mocking/skipping it instead. Read more about module testing in a separate guide in Cirrus CLI repository . env \u00b6 While not technically a builtin, env is dict that contains environment variables . Example: load ( \"cirrus\" , \"env\" ) def main ( ctx ): tasks = base_tasks () if env . get ( \"CIRRUS_TAG\" ) != None : tasks += release_tasks () return tasks changes_include \u00b6 changes_include() is a Starlark alternative to the changesInclude() function commonly found in the YAML configuration files. It takes at least one string with a pattern and returns a bool that represents whether any of the specified patterns matched any of the affected files in the running context. Currently supported contexts: main() entrypoint Example: load ( \"cirrus\" , \"changes_include\" ) def main ( ctx ): tasks = base_tasks () if changes_include ( \"Dockerfile\" ): tasks += docker_task () return tasks changes_include_only \u00b6 changes_include_only() is a Starlark alternative to the changesIncludeOnly() function commonly found in the YAML configuration files. It takes at least one string with a pattern and returns a bool that represents whether any of the specified patterns matched all the affected files in the running context. Currently supported contexts: main() entrypoint Example: load ( \"cirrus\" , \"changes_include_only\" ) def main ( ctx ): if changes_include_only ( \"doc/*\" ): return [] return base_tasks () http \u00b6 Provides HTTP client implementation with http.get() , http.post() and other HTTP method functions. Refer to the starlib's documentation for more details. hash \u00b6 Provides cryptographic hashing functions, such as hash.md5() , hash.sha1() and hash.sha256() . Refer to the starlib's documentation for more details. base64 \u00b6 Provides Base64 encoding and decoding functions using base64.encode() and base64.decode() . Refer to the starlib's documentation for more details. json \u00b6 Provides JSON document marshalling and unmarshalling using json.dumps() and json.loads() functions. Refer to the starlib's documentation for more details. yaml \u00b6 Provides YAML document marshalling and unmarshalling using yaml.dumps() and yaml.loads() functions. Refer to the starlib's documentation for more details. re \u00b6 Provides regular expression functions, such as findall() , split() and sub() . Refer to the starlib's documentation for more details. zipfile \u00b6 cirrus.zipfile module provides methods to read Zip archives. You instantiate a ZipFile object using zipfile.ZipFile(data) function call and then call namelist() and open(filename) methods to retrieve information about archive contents. Refer to the starlib's documentation for more details. Example: load ( \"cirrus\" , \"fs\" , \"zipfile\" ) def is_java_archive ( path ): # Read Zip archive contents from the filesystem archive_contents = fs . read ( path ) if archive_contents == None : return False # Open Zip archive and a file inside of it zf = zipfile . ZipFile ( archive_contents ) manifest = zf . open ( \"META-INF/MANIFEST.MF\" ) # Does the manifest contain the expected version? if \"Manifest-Version: 1.0\" in manifest . read (): return True return False","title":"Programming Tasks in Starlark"},{"location":"guide/programming-tasks/#introduction-into-starlark","text":"Most commonly, Cirrus tasks are declared in .cirrus.yml file in YAML format as documented in Writing Tasks guide. YAML, as a language, is great for declaring simple to moderate configurations, but sometimes just using a declarative language is not enough. One might need some conditional execution or have an easy way to generate multiple similar tasks. Most of the CIs solve this problem by introducing special DSL into the existing YAML. In case of Cirrus CI, we have only_if keyword for conditional execution and matrix modification for generating similar tasks. These options are mostly hacks to workaround declarative nature of YAML language where in reality an imperative language looks like a better fit. This is why Cirrus CI allows in additional to YAML configure tasks via Starlark. Starlark language is a procedural programming language originated from Bazel build tool , but ideal for embedding within any other system that want to safely allow user-defined logic. There are a few key differences which made us choose Starlark instead of common alternatives like JavaScript/TypeScript or WebAssembly: Starlark doesn't require compilation. No need to introduce full-blown compile and deploy process for a few dozen lines of logic. Starlark script can be executed instantly on any platform. There is Starlark interpreter written in Go which integrates nicely with Cirrus CLI and Cirrus CI infrastructure. Starlark has built-in functionality for loading external modules which is ideal for config sharing. See module loading for details.","title":"Introduction into Starlark"},{"location":"guide/programming-tasks/#writing-starlark-scripts","text":"Let's start with a trivial .cirrus.star example like this: def main (): return [ { \"container\" : { \"image\" : \"debian:latest\" , }, \"script\" : \"make\" , }, ] With the module loading , you can re-use other people's code to avoid wasting time on things written from scratch. For example, with the official task helpers the example above can be refactored in: load ( \"github.com/cirrus-modules/helpers\" , \"task\" , \"container\" , \"script\" ) def main ( ctx ): return [ task ( instance = container ( \"debian:latest\" ), instructions = [ script ( \"make\" )] ), ] main() needs to return a list of task objects which will be serialized into YAML, like this: task : container : image : debian:latest script : make Then the generated YAML is appended to .cirrus.yml (if any) before passing the combined config into the final YAML parser. With Starlark, it's possible to generate parts of the configuration dynamically based on some external conditions: Parsing files inside the repository to pick up some common settings (for example, parse package.json to see if it contains lint script and generate a linting task). Making an HTTP request to check the previous build status. See a video tutorial on how to create a custom Cirrus module:","title":"Writing Starlark scripts"},{"location":"guide/programming-tasks/#entrypoints","text":"Different events will trigger execution of different top-level functions in the .cirrus.star . These functions reserve certain names and will be called with different arguments depending on the event which triggered the execution.","title":"Entrypoints"},{"location":"guide/programming-tasks/#main","text":"main() is called once a Cirrus CI build is triggered in order to generate a list of tasks to execute within that particular build: def main (): return [ { \"container\" : { \"image\" : \"debian:latest\" }, \"script\" : \"make test\" }, { \"container\" : { \"image\" : \"debian:latest\" }, \"script\" : \"make build\" } ] If you want to return multiple tasks with the same name or a top-level override like env , use the tuple syntax below: def main (): return [ ( \"env\" , { \"PARALLEL\" : \"yes\" }), ( \"container\" , { \"image\" : \"debian:latest\" }), ( \"task\" , { \"script\" : \"make build\" }), ( \"task\" , { \"script\" : \"make test\" }) ] In regard to top-level overrides, note that when using both YAML and Starlark configuration formats they get merged and the YAML configuration always comes first.","title":"main()"},{"location":"guide/programming-tasks/#hooks","text":"It's also possible to execute Starlark scripts on updates to the current build or any of the tasks within the build. Think of it as WebHooks running within Cirrus that doesn't require any infrastructure on your end. Expected names of Starlark Hook functions in .cirrus.star are on_build_<STATUS> or on_task_<STATUS> respectively. Please refer to Cirrus CI GraphQL Schema for a full list of existing statuses, but most commonly on_build_failed / on_build_completed and on_task_failed / on_task_completed are used. These functions should expect a single context argument passed by Cirrus Cloud. At the moment hook's context only contains a single field payload containing the same payload as a webhook . One caveat of Starlark Hooks execution is CIRRUS_TOKEN environment variable that contains a token to access Cirrus API . Scope of CIRRUS_TOKEN is restricted to the build associated with that particular hook invocation and allows, for example, to automatically re-run tasks. Here is an example of a Starlark Hook that automatically re-runs a failed task in case a particular transient issue found in logs: # load some helpers from an external module load ( \"github.com/cirrus-modules/graphql\" , \"rerun_task_if_issue_in_logs\" ) def on_task_failed ( ctx ): if \"Test\" not in ctx . payload . data . task . name : return if ctx . payload . data . task . automaticReRun : print ( \"Task is already an automatic re-run! Won't even try to re-run it...\" ) return rerun_task_if_issue_in_logs ( ctx . payload . data . task . id , \"Time out\" )","title":"Hooks"},{"location":"guide/programming-tasks/#module-loading","text":"Module loading is done through the Starlark's load() statement. Besides the ability to load builtins with it, Cirrus can load other .star files from local and remote locations to facilitate code re-use.","title":"Module loading"},{"location":"guide/programming-tasks/#local","text":"Local loads are relative to the project's root (where .cirrus.star is located): load ( \".ci/notify-slack.star\" , \"notify_slack\" )","title":"Local"},{"location":"guide/programming-tasks/#remote-from-git","text":"To load the default branch of the module from GitHub: load ( \"github.com/cirrus-modules/golang\" , \"task\" , \"container\" ) In the example above, the name of the .star file was not provided, because lib.star is assumed by default. This is equivalent to: load ( \"github.com/cirrus-modules/golang/lib.star@main\" , \"task\" , \"container\" ) You can also specify an exact commit hash instead of the main() branch name to prevent accidental changes. To load .star files from repositories other than GitHub, add a .git suffix at the end of the repository name, for example: load ( \"gitlab.com/fictional/repository.git/validator.star\" , \"validate\" ) ^^^^ note the suffix","title":"Remote from Git"},{"location":"guide/programming-tasks/#builtins","text":"Cirrus CLI provides builtins all nested in the cirrus module that greatly extend what can be done with the Starlark alone.","title":"Builtins"},{"location":"guide/programming-tasks/#fs","text":"These builtins allow for read-only filesystem access. All paths are relative to the project's directory.","title":"fs"},{"location":"guide/programming-tasks/#fsexistspath","text":"Returns True if path exists and False otherwise.","title":"fs.exists(path)"},{"location":"guide/programming-tasks/#fsreadpath","text":"Returns a string with the file contents or None if the file doesn't exist. Note that this is an error to read a directory with fs.read() .","title":"fs.read(path)"},{"location":"guide/programming-tasks/#fsreaddirdirpath","text":"Returns a list of string 's with names of the entries in the directory. Note that this is an error to read a file with fs.readdir() . Example: load ( \"cirrus\" , \"fs\" ) def main ( ctx ): tasks = base_tasks () if fs . exists ( \"go.mod\" ): tasks += go_tasks () return tasks","title":"fs.readdir(dirpath)"},{"location":"guide/programming-tasks/#is_test","text":"While not technically a builtin, is_test is a bool that allows Starlark code to determine whether it's running in test environment via Cirrus CLI. This can be useful for limiting the test complexity, e.g. by not making a real HTTP request and mocking/skipping it instead. Read more about module testing in a separate guide in Cirrus CLI repository .","title":"is_test"},{"location":"guide/programming-tasks/#env","text":"While not technically a builtin, env is dict that contains environment variables . Example: load ( \"cirrus\" , \"env\" ) def main ( ctx ): tasks = base_tasks () if env . get ( \"CIRRUS_TAG\" ) != None : tasks += release_tasks () return tasks","title":"env"},{"location":"guide/programming-tasks/#changes_include","text":"changes_include() is a Starlark alternative to the changesInclude() function commonly found in the YAML configuration files. It takes at least one string with a pattern and returns a bool that represents whether any of the specified patterns matched any of the affected files in the running context. Currently supported contexts: main() entrypoint Example: load ( \"cirrus\" , \"changes_include\" ) def main ( ctx ): tasks = base_tasks () if changes_include ( \"Dockerfile\" ): tasks += docker_task () return tasks","title":"changes_include"},{"location":"guide/programming-tasks/#changes_include_only","text":"changes_include_only() is a Starlark alternative to the changesIncludeOnly() function commonly found in the YAML configuration files. It takes at least one string with a pattern and returns a bool that represents whether any of the specified patterns matched all the affected files in the running context. Currently supported contexts: main() entrypoint Example: load ( \"cirrus\" , \"changes_include_only\" ) def main ( ctx ): if changes_include_only ( \"doc/*\" ): return [] return base_tasks ()","title":"changes_include_only"},{"location":"guide/programming-tasks/#http","text":"Provides HTTP client implementation with http.get() , http.post() and other HTTP method functions. Refer to the starlib's documentation for more details.","title":"http"},{"location":"guide/programming-tasks/#hash","text":"Provides cryptographic hashing functions, such as hash.md5() , hash.sha1() and hash.sha256() . Refer to the starlib's documentation for more details.","title":"hash"},{"location":"guide/programming-tasks/#base64","text":"Provides Base64 encoding and decoding functions using base64.encode() and base64.decode() . Refer to the starlib's documentation for more details.","title":"base64"},{"location":"guide/programming-tasks/#json","text":"Provides JSON document marshalling and unmarshalling using json.dumps() and json.loads() functions. Refer to the starlib's documentation for more details.","title":"json"},{"location":"guide/programming-tasks/#yaml","text":"Provides YAML document marshalling and unmarshalling using yaml.dumps() and yaml.loads() functions. Refer to the starlib's documentation for more details.","title":"yaml"},{"location":"guide/programming-tasks/#re","text":"Provides regular expression functions, such as findall() , split() and sub() . Refer to the starlib's documentation for more details.","title":"re"},{"location":"guide/programming-tasks/#zipfile","text":"cirrus.zipfile module provides methods to read Zip archives. You instantiate a ZipFile object using zipfile.ZipFile(data) function call and then call namelist() and open(filename) methods to retrieve information about archive contents. Refer to the starlib's documentation for more details. Example: load ( \"cirrus\" , \"fs\" , \"zipfile\" ) def is_java_archive ( path ): # Read Zip archive contents from the filesystem archive_contents = fs . read ( path ) if archive_contents == None : return False # Open Zip archive and a file inside of it zf = zipfile . ZipFile ( archive_contents ) manifest = zf . open ( \"META-INF/MANIFEST.MF\" ) # Does the manifest contain the expected version? if \"Manifest-Version: 1.0\" in manifest . read (): return True return False","title":"zipfile"},{"location":"guide/quick-start/","text":"At the moment Cirrus CI only supports repositories hosted on GitHub. This guide will walk you through the installation process. If you are interested in a support for other code hosting platforms please fill up this form to help us prioritize the support and notify you once the support is available. Start by configuring the Cirrus CI application from GitHub Marketplace. Choose a plan for your personal account or for an organization you have admin writes for. GitHub Apps can be installed on all repositories or on repository-by-repository basis for granular access control. For example, Cirrus CI can be installed only on public repositories and will only have access to these public repositories. In contrast, classic OAuth Apps don't have such restrictions . Change Repository Access You can always revisit Cirrus CI's repository access settings on your installation page . Post Installation \u00b6 Once Cirrus CI is installed for a particular repository, a .cirrus.yml configuration file should be added to the root of the repository. The .cirrus.yml defines tasks that will be executed for every build for the repository. For a Node.js project, your .cirrus.yml could look like: amd64 container : image : node:latest check_task : node_modules_cache : folder : node_modules fingerprint_script : cat yarn.lock populate_script : yarn install test_script : yarn test arm64 arm_container : image : node:latest check_task : node_modules_cache : folder : node_modules fingerprint_script : cat yarn.lock populate_script : yarn install test_script : yarn test That's all! After pushing a .cirrus.yml a build with all the tasks defined in the .cirrus.yml file will be created. Note: Please check the full guide on configuring Cirrus Tasks and/or check a list of available examples . Zero-config Docker Builds If your repository happened to have a Dockerfile in the root, Cirrus CI will attempt to build it even without a corresponding .cirrus.yml configuration file. You will see all your Cirrus CI builds on cirrus-ci.com once signed in. GitHub status checks for each task will appear on GitHub as well. Newly created PRs will also get Cirrus CI's status checks. Examples Don't forget to check examples page for ready-to-copy examples of some .cirrus.yml configuration files for different languages and build systems. Life of a build Please check a high level overview of what's happening under the hood when a changed is pushed and this guide to learn more about how to write tasks. Authorization on Cirrus CI Web App \u00b6 All builds created by your account can be viewed on Cirrus CI Web App after signing in with your GitHub Account: After clicking on Sign In you'll be redirected to GitHub in order to authorize access: Note about Act on your behalf Cirrus CI only asks for several kinds of permissions that you can see on your installation page . These permissions are read-only except for write access to checks and commit statuses in order for Cirrus CI to be able to report task statuses via checks or commit statuses. There is a long thread disscussing this weird \" Act on your behalf \" wording here on GitHub's own commuity forum. Enabling New Repositories after Installation \u00b6 If you choose initially to allow Cirrus CI to access all of your repositories, all you need to do is push a .cirrus.yml to start building your repository on Cirrus CI. If you only allowed Cirrus CI to access certain repositories, then add your new repository to the list of repositories Cirrus CI has access to via this page , then push a .cirrus.yml to start building on Cirrus CI.","title":"Quick Start"},{"location":"guide/quick-start/#post-installation","text":"Once Cirrus CI is installed for a particular repository, a .cirrus.yml configuration file should be added to the root of the repository. The .cirrus.yml defines tasks that will be executed for every build for the repository. For a Node.js project, your .cirrus.yml could look like: amd64 container : image : node:latest check_task : node_modules_cache : folder : node_modules fingerprint_script : cat yarn.lock populate_script : yarn install test_script : yarn test arm64 arm_container : image : node:latest check_task : node_modules_cache : folder : node_modules fingerprint_script : cat yarn.lock populate_script : yarn install test_script : yarn test That's all! After pushing a .cirrus.yml a build with all the tasks defined in the .cirrus.yml file will be created. Note: Please check the full guide on configuring Cirrus Tasks and/or check a list of available examples . Zero-config Docker Builds If your repository happened to have a Dockerfile in the root, Cirrus CI will attempt to build it even without a corresponding .cirrus.yml configuration file. You will see all your Cirrus CI builds on cirrus-ci.com once signed in. GitHub status checks for each task will appear on GitHub as well. Newly created PRs will also get Cirrus CI's status checks. Examples Don't forget to check examples page for ready-to-copy examples of some .cirrus.yml configuration files for different languages and build systems. Life of a build Please check a high level overview of what's happening under the hood when a changed is pushed and this guide to learn more about how to write tasks.","title":"Post Installation"},{"location":"guide/quick-start/#authorization-on-cirrus-ci-web-app","text":"All builds created by your account can be viewed on Cirrus CI Web App after signing in with your GitHub Account: After clicking on Sign In you'll be redirected to GitHub in order to authorize access: Note about Act on your behalf Cirrus CI only asks for several kinds of permissions that you can see on your installation page . These permissions are read-only except for write access to checks and commit statuses in order for Cirrus CI to be able to report task statuses via checks or commit statuses. There is a long thread disscussing this weird \" Act on your behalf \" wording here on GitHub's own commuity forum.","title":"Authorization on Cirrus CI Web App"},{"location":"guide/quick-start/#enabling-new-repositories-after-installation","text":"If you choose initially to allow Cirrus CI to access all of your repositories, all you need to do is push a .cirrus.yml to start building your repository on Cirrus CI. If you only allowed Cirrus CI to access certain repositories, then add your new repository to the list of repositories Cirrus CI has access to via this page , then push a .cirrus.yml to start building on Cirrus CI.","title":"Enabling New Repositories after Installation"},{"location":"guide/supported-computing-services/","text":"For every task Cirrus CI starts a new Virtual Machine or a new Docker Container on a given compute service. Using a new VM or a new Docker Container each time for running tasks has many benefits: Atomic changes to an environment where tasks are executed. Everything about a task is configured in .cirrus.yml file, including VM image version and Docker Container image version. After committing changes to .cirrus.yml not only new tasks will use the new environment, but also outdated branches will continue using the old configuration. Reproducibility. Fresh environment guarantees no corrupted artifacts or caches are presented from the previous tasks. Cost efficiency. Most compute services are offering per-second pricing which makes them ideal for using with Cirrus CI. Also each task for repository can define ideal amount of CPUs and Memory specific for a nature of the task. No need to manage pools of similar VMs or try to fit workloads within limits of a given Continuous Integration systems. To be fair there are of course some disadvantages of starting a new VM or a container for every task: Virtual Machine Startup Speed. Starting a VM can take from a few dozen seconds to a minute or two depending on a cloud provider and a particular VM image. Starting a container on the other hand just takes a few hundred milliseconds! But even a minute on average for starting up VMs is not a big inconvenience in favor of more stable, reliable and more reproducible CI. Cold local caches for every task execution. Many tools tend to store some caches like downloaded dependencies locally to avoid downloading them again in future. Since Cirrus CI always uses fresh VMs and containers such local caches will always be empty. Performance implication of empty local caches can be avoided by using Cirrus CI features like built-in caching mechanism . Some tools like Gradle can even take advantages of built-in HTTP cache ! Please check the list of currently supported cloud compute services below. In case you have your own hardware, please take a look at Persistent Workers , which allow connecting anything to Cirrus CI. Google Cloud \u00b6 Cirrus CI can schedule tasks on several Google Cloud Compute services. In order to interact with Google Cloud APIs Cirrus CI needs permissions. Creating a service account is a common way to safely give granular access to parts of Google Cloud Projects. Isolation We do recommend to create a separate Google Cloud project for running CI builds to make sure tests are isolated from production data. Having a separate project also will show how much money is spent on CI and how efficient Cirrus CI is Once you have a Google Cloud project for Cirrus CI please create a service account by running the following command: gcloud iam service-accounts create cirrus-ci \\ --project $PROJECT_ID Depending on a compute service Cirrus CI will need different roles assigned to the service account. But Cirrus CI will always need permissions to act as a service account and be able to view monitoring: gcloud projects add-iam-policy-binding $PROJECT_ID \\ --member serviceAccount:cirrus-ci@ $PROJECT_ID .iam.gserviceaccount.com \\ --role roles/iam.serviceAccountUser \\ --role roles/monitoring.viewer Cirrus CI uses Google Cloud Storage to store logs and caches. In order to give Google Cloud Storage permissions to the service account please run: gcloud projects add-iam-policy-binding $PROJECT_ID \\ --member serviceAccount:cirrus-ci@ $PROJECT_ID .iam.gserviceaccount.com \\ --role roles/storage.admin Default Logs Retentions Period By default Cirrus CI will store logs and caches for 90 days but it can be changed by manually configuring a lifecycle rule for a Google Cloud Storage bucket that Cirrus CI is using. Now we have a service account that Cirrus CI can use! It's time to let Cirrus CI know about that fact by securely providing a private key for the service account. A private key can be created by running the following command: gcloud iam service-accounts keys create service-account-credentials.json \\ --iam-account cirrus-ci@ $PROJECT_ID .iam.gserviceaccount.com At last create an encrypted variable from contents of service-account-credentials.json file and add it to the top of .cirrus.yml file: gcp_credentials : ENCRYPTED[qwerty239abc] Now Cirrus CI can store logs and caches in Google Cloud Storage for tasks scheduled on either GCE or GKE. Please check following sections with additional instructions about Compute Engine or Kubernetes Engine . Supported Regions Cirrus CI currently supports following GCP regions: us-central1 , us-east1 , us-east4 , us-west1 , us-west2 , europe-west1 , europe-west2 , europe-west3 and europe-west4 . Please contact support if you are interested in support for other regions. Compute Engine \u00b6 In order to schedule tasks on Google Compute Engine a service account that Cirrus CI operates via should have a necessary role assigned. It can be done by running a gcloud command: gcloud projects add-iam-policy-binding $PROJECT_ID \\ --member serviceAccount:cirrus-ci@ $PROJECT_ID .iam.gserviceaccount.com \\ --role roles/compute.admin Now tasks can be scheduled on Compute Engine within $PROJECT_ID project by configuring gce_instance something like this: gce_instance : image_project : ubuntu-os-cloud image_name : ubuntu-1904-disco-v20190417 zone : us-central1-a cpu : 8 memory : 40GB disk : 60 use_ssd : true # default to false task : script : ./run-ci.sh Specify Machine Type It is possible to specify a predefined machine type via type field: gce_instance : image_project : ubuntu-os-cloud image_name : ubuntu-1604-xenial-v20171121a zone : us-central1-a type : n1-standard-8 disk : 20 Specify Image Family It's also possible to specify image family instead of the concrete image name. Use the image_family field instead of image_name : gce_instance : image_project : ubuntu-os-cloud image_family : ubuntu-1904 Custom VM images \u00b6 Building an immutable VM image with all necessary software pre-configured is a known best practice with many benefits. It makes sure environment where a task is executed is always the same and that no time is spent on useless work like installing a package over and over again for every single task. There are many ways how one can create a custom image for Google Compute Engine. Please refer to the official documentation . At Cirrus Labs we are using Packer to automate building such images. An example of how we use it can be found in our public GitHub repository . Windows Support \u00b6 Google Compute Engine support Windows images and Cirrus CI can take full advantages of it by just explicitly specifying platform of an image like this: gce_instance : image_project : windows-cloud image_name : windows-server-2016-dc-core-v20170913 platform : windows zone : us-central1-a cpu : 8 memory : 40GB disk : 20 task : script : run-ci.bat FreeBSD Support \u00b6 Google Compute Engine support FreeBSD images and Cirrus CI can take full advantages of it by just explicitly specifying platform of an image like this: gce_instance : image_project : freebsd-org-cloud-dev image_family : freebsd-12-1 platform : FreeBSD zone : us-central1-a cpu : 8 memory : 40GB disk : 50 task : script : printenv Docker Containers on Dedicated VMs \u00b6 It is possible to run a container directly on a Compute Engine VM with pre-installed Docker. Use the gce_container field to specify a VM image and a Docker container to execute on the VM ( gce_container extends gce_instance definition with a few additional fields): gce_container : image_project : my-project image_name : my-custom-ubuntu-with-docker container : golang:latest additional_containers : - name : redis image : redis:3.2-alpine port : 6379 Note that gce_container always runs containers in privileged mode. If your VM image has Nested Virtualization Enabled it's possible to use KVM from the container by specifying enable_nested_virtualization flag. Here is an example of using KVM-enabled container to run a hardware accelerated Android emulator: gce_container : image_project : my-project image_name : my-custom-ubuntu-with-docker-and-KVM container : cirrusci/android-sdk:29 enable_nested_virtualization : true accel_check_script : - sudo chown cirrus:cirrus /dev/kvm - emulator -accel-check Instance Scopes \u00b6 By default Cirrus CI will create Google Compute instances without any scopes so an instance can't access Google Cloud Storage for example. But sometimes it can be useful to give some permissions to an instance by using scopes key of gce_instance . For example, if a particular task builds Docker images and then pushes them to Container Registry , its configuration file can look something like: gcp_credentials : ENCRYPTED[qwerty239abc] gce_instance : image_project : my-project image_name : my-custom-image-with-docker zone : us-central1-a cpu : 8 memory : 40GB disk : 20 test_task : test_script : ./scripts/test.sh push_docker_task : depends_on : test only_if : $CIRRUS_BRANCH == \"master\" gce_instance : scopes : cloud-platform push_script : ./scripts/push_docker.sh Preemptible Instances \u00b6 Cirrus CI can schedule preemptible instances with all price benefits and stability risks. But sometimes risks of an instance being preempted at any time can be tolerated. For example gce_instance can be configured to schedule preemptible instance for non master branches like this: gce_instance : image_project : my-project image_name : my-custom-image-with-docker zone : us-central1-a preemptible : $CIRRUS_BRANCH != \"master\" Kubernetes Engine \u00b6 Scheduling tasks on Compute Engine has one big disadvantage of waiting for an instance to start which usually takes around a minute. One minute is not that long but can't compete with hundreds of milliseconds that takes a container cluster on GKE to start a container. To start scheduling tasks on a container cluster we first need to create one using gcloud . Here is a recommended configuration of a cluster that is very similar to what is used for the managed contianer instances. We recommend creating a cluster with two node pools: default-pool with a single node and no autoscaling for system pods required by Kubernetes. workers-pool that will use Compute-Optimized instances and SSD storage for better performance. This pool also will be able to scale to 0 when there are no tasks to run. gcloud container clusters create cirrus-ci-cluster \\ --autoscaling-profile optimize-utilization \\ --zone us-central1-a \\ --num-nodes \"1\" \\ --machine-type \"e2-standard-2\" \\ --disk-type \"pd-standard\" --disk-size \"100\" gcloud container node-pools create \"workers-pool\" \\ --cluster cirrus-ci-cluster \\ --zone \"us-central1-a\" \\ --num-nodes \"0\" \\ --enable-autoscaling --min-nodes \"0\" --max-nodes \"8\" \\ --node-taints dedicated=system:PreferNoSchedule \\ --machine-type \"c2-standard-30\" \\ --disk-type \"pd-ssd\" --disk-size \"500\" A service account that Cirrus CI operates via should be assigned with container.admin role that allows to administrate GKE clusters: gcloud projects add-iam-policy-binding $PROJECT_ID \\ --member serviceAccount:cirrus-ci@ $PROJECT_ID .iam.gserviceaccount.com \\ --role roles/container.admin Done! Now after creating cirrus-ci-cluster cluster and having gcp_credentials configured tasks can be scheduled on the newly created cluster like this: gcp_credentials : ENCRYPTED[qwerty239abc] gke_container : image : gradle:jdk8 cluster_name : cirrus-ci-cluster location : us-central1-a # cluster zone or region for multi-zone clusters namespace : default # Kubernetes namespace to create pods in cpu : 6 memory : 24GB Using in-memory disk By default Cirrus CI mounts an emptyDir into /tmp path to protect the pod from unnecessary eviction by autoscaler. It is possible to switch emptyDir's medium to use in-memory tmpfs storage instead of a default one by setting use_in_memory_disk field of gke_container to true or any other expression that uses environment variables. Running privileged containers You can run privileged containers on your private GKE cluster by setting privileged field of gke_container to true or any other expression that uses environment variables. privileged field is also available for any additional container. Here is an example of how to run docker-in-docker gke_container : image : my-docker-client:latest cluster_name : my-gke-cluster location : us-west1-c namespace : cirrus-ci additional_containers : - name : docker image : docker:dind privileged : true cpu : 2 memory : 6G port : 2375 For a full example on leveraging this to do docker-in-docker builds on Kubernetes checkout Docker Builds on Kubernetes Greedy instances Greedy instances can potentially use more CPU resources if available. Please check this blog post for more details. AWS \u00b6 Cirrus CI can schedule tasks on several AWS services. In order to interact with AWS APIs Cirrus CI needs permissions. Creating an IAM user for programmatic access is a common way to safely give granular access to parts of your AWS. Once you created a user for Cirrus CI you'll need to provide key id and access key itself. In order to do so please create an encrypted variable with the following content: [default] aws_access_key_id = ... aws_secret_access_key = ... Then you'll be able to use the encrypted variable in your .cirrus.yml file like this: aws_credentials : ENCRYPTED[...] task : ec2_instance : ... task : eks_instance : ... Permissions A user that Cirrus CI will be using for orchestrating tasks on AWS should at least have access to S3 in order to store logs and cache artifacts. Here is a list of actions that Cirrus CI requires to store logs and artifacts: \"Action\" : [ \"s3:CreateBucket\" , \"s3:GetObject\" , \"s3:PutObject\" , \"s3:DeleteObject\" , \"s3:PutLifecycleConfiguration\" ] EC2 \u00b6 In order to schedule tasks on EC2 please make sure that IAM user that Cirrus CI is using has following permissions: \"Action\" : [ \"ec2:DescribeInstances\" , \"ec2:RunInstances\" , \"ec2:TerminateInstances\" ] Now tasks can be scheduled on EC2 by configuring ec2_instance something like this: task : ec2_instance : image : ami-03790f6959fc34ef3 type : t2.micro region : us-east-1 script : ./run-ci.sh EKS \u00b6 Please follow instructions on how to create a EKS cluster and add workers nodes to it. And don't forget to add necessary permissions for the IAM user that Cirrus CI is using: \"Action\" : [ \"iam:PassRole\" , \"eks:DescribeCluster\" , \"eks:CreateCluster\" , \"eks:DeleteCluster\" , \"eks:UpdateClusterVersion\" ] To verify that Cirrus CI will be able to communicate with your cluster please make sure that if you are locally logged in as the user that Cirrus CI acts as you can successfully run the following commands and see your worker nodes up and running: $: aws sts get-caller-identity { \"UserId\" : \"...\" , \"Account\" : \"...\" , \"Arn\" : \"USER_USED_BY_CIRRUS_CI\" } $: aws eks --region $REGION update-kubeconfig --name $CLUSTER_NAME $: kubectl get nodes EKS Access Denied If you have an issue with accessing your EKS cluster via kubectl , most likely you did not create the cluster with the user that Cirrus CI is using. The easiest way to do so is to create the cluster through AWS CLI with the following command: $: aws sts get-caller-identity { \"UserId\" : \"...\" , \"Account\" : \"...\" , \"Arn\" : \"USER_USED_BY_CIRRUS_CI\" } $: aws eks --region $REGION \\ create-cluster --name cirrus-ci \\ --role-arn ... \\ --resources-vpc-config subnetIds = ...,securityGroupIds = ... Now tasks can be scheduled on EKS by configuring eks_container something like this: task : eks_container : image : node:latest region : us-east-1 cluster_name : cirrus-ci script : ./run-ci.sh S3 Access for Caching Please add AmazonS3FullAccess policy to the role used for creation of EKS workers (same role you put in aws-auth-cm.yaml when enabled worker nodes to join the cluster ). Greedy instances Greedy instances can potentially use more CPU resources if available. Please check this blog post for more details. Azure \u00b6 Cirrus CI can schedule tasks on several Azure services. In order to interact with Azure APIs Cirrus CI needs permissions. First, please choose a subscription you want to use for scheduling CI tasks. Navigate to the Subscriptions blade within the Azure Portal and save $SUBSCRIPTION_ID that we'll use below for setting up a service principle. Creating a service principal is a common way to safely give granular access to parts of Azure: az ad sp create-for-rbac --name CirrusCI --sdk-auth \\ --scopes \"/subscriptions/ $SUBSCRIPTION_ID \" Command above will create a new service principal and will print something like: { \"clientId\" : \"...\" , \"clientSecret\" : \"...\" , \"subscriptionId\" : \"...\" , \"tenantId\" : \"...\" , ... } Please also remember clientId from the JSON as $CIRRUS_CLIENT_ID . It will be used later for configuring blob storage access. Please create an encrypted variable from this output and add it to the top of .cirrus.yml file: azure_credentials : ENCRYPTED[qwerty239abc] You also need to create a resource group that Cirrus CI will use for scheduling tasks: az group create --location eastus --name CirrusCI Please also allow the newly created CirrusCI principle to access blob storage in order to manage logs and caches. az role assignment create \\ --role \"Storage Blob Data Contributor\" \\ --assignee $CIRRUS_CLIENT_ID \\ --scope \"/subscriptions/$SUBSCRIPTION_ID/resourceGroups/CirrusCI\" Now Cirrus CI can interact with Azure APIs. Azure Container Instances \u00b6 Azure Container Instances (ACI) is an ideal candidate for running modern CI workloads. ACI allows just to run Linux and Windows containers without thinking about underlying infrastructure. Once azure_credentials is configured as described above, tasks can be scheduled on ACI by configuring aci_instance like this: azure_container_instance : image : cirrusci/windowsservercore:2016 resource_group : CirrusCI region : westus platform : windows cpu : 4 memory : 12G About Docker Images to use with ACI Linux-based images are usually pretty small and doesn't require much tweaking. For Windows containers ACI recommends to follow a few basic tips in order to reduce startup time. Oracle Cloud \u00b6 Cirrus CI can schedule tasks on several Oracle Cloud services. In order to interact with OCI APIs Cirrus CI needs permissions. Please create a user that Cirrus CI will behalf on: oci iam user create --name cirrus --description \"Cirrus CI Orchestrator\" Please configure the cirrus user to be able to access storage, launch instances and have access to Kubernetes clusters. The easiest way is to add cirrus user to Administrators group, but it's not as secure as a granular access configuration. By default, for every repository you'll start using Cirrus CI with, Cirrus will create a bucket with 90 days lifetime policy. In order to allow Cirrus to configure lifecycle policies please add the following policy as described in the documentation . Here is an example of the policy for us-ashburn-1 region: Allow service objectstorage-us-ashburn-1 to manage object-family in tenancy Once you created and configured cirrus user you'll need to provide its API key. Once you generate an API key you should get a *.pem file with the private key that will be used by Cirrus CI. Normally your config file for local use looks like this: [DEFAULT] user = ocid1.user.oc1..XXX fingerprint = 11:22:...:99 tenancy = ocid1.tenancy.oc1..YYY region = us-ashburn-1 key_file = <path to your *.pem private keyfile> For Cirrus to use, you'll need to use a different format: <user value> <fingerprint value> <tenancy value> <region value> <content of your *.pem private keyfile> This way you'll be able to create a single encrypted variable with the contents of the Cirrus specific credentials above. oracle_credentials : ENCRYPTED[qwerty239abc] Kubernetes Cluster \u00b6 Please create a Kubernetes cluster and make sure Kubernetes API Public Endpoint is enabled for the cluster so Cirrus can access it. Then copy cluster id which can be used in configuring oke_container : task : oke_container : cluster_id : ocid1.cluster.oc1.iad.xxxxxx image : golang:latest script : ./run-ci.sh Ampere A1 Support The cluster can utilize Oracle's Ampere A1 Arm instances in order to run arm64 CI workloads! Greedy instances Greedy instances can potentially use more CPU resources if available. Please check this blog post for more details.","title":"Computing Services"},{"location":"guide/supported-computing-services/#google-cloud","text":"Cirrus CI can schedule tasks on several Google Cloud Compute services. In order to interact with Google Cloud APIs Cirrus CI needs permissions. Creating a service account is a common way to safely give granular access to parts of Google Cloud Projects. Isolation We do recommend to create a separate Google Cloud project for running CI builds to make sure tests are isolated from production data. Having a separate project also will show how much money is spent on CI and how efficient Cirrus CI is Once you have a Google Cloud project for Cirrus CI please create a service account by running the following command: gcloud iam service-accounts create cirrus-ci \\ --project $PROJECT_ID Depending on a compute service Cirrus CI will need different roles assigned to the service account. But Cirrus CI will always need permissions to act as a service account and be able to view monitoring: gcloud projects add-iam-policy-binding $PROJECT_ID \\ --member serviceAccount:cirrus-ci@ $PROJECT_ID .iam.gserviceaccount.com \\ --role roles/iam.serviceAccountUser \\ --role roles/monitoring.viewer Cirrus CI uses Google Cloud Storage to store logs and caches. In order to give Google Cloud Storage permissions to the service account please run: gcloud projects add-iam-policy-binding $PROJECT_ID \\ --member serviceAccount:cirrus-ci@ $PROJECT_ID .iam.gserviceaccount.com \\ --role roles/storage.admin Default Logs Retentions Period By default Cirrus CI will store logs and caches for 90 days but it can be changed by manually configuring a lifecycle rule for a Google Cloud Storage bucket that Cirrus CI is using. Now we have a service account that Cirrus CI can use! It's time to let Cirrus CI know about that fact by securely providing a private key for the service account. A private key can be created by running the following command: gcloud iam service-accounts keys create service-account-credentials.json \\ --iam-account cirrus-ci@ $PROJECT_ID .iam.gserviceaccount.com At last create an encrypted variable from contents of service-account-credentials.json file and add it to the top of .cirrus.yml file: gcp_credentials : ENCRYPTED[qwerty239abc] Now Cirrus CI can store logs and caches in Google Cloud Storage for tasks scheduled on either GCE or GKE. Please check following sections with additional instructions about Compute Engine or Kubernetes Engine . Supported Regions Cirrus CI currently supports following GCP regions: us-central1 , us-east1 , us-east4 , us-west1 , us-west2 , europe-west1 , europe-west2 , europe-west3 and europe-west4 . Please contact support if you are interested in support for other regions.","title":"Google Cloud"},{"location":"guide/supported-computing-services/#compute-engine","text":"In order to schedule tasks on Google Compute Engine a service account that Cirrus CI operates via should have a necessary role assigned. It can be done by running a gcloud command: gcloud projects add-iam-policy-binding $PROJECT_ID \\ --member serviceAccount:cirrus-ci@ $PROJECT_ID .iam.gserviceaccount.com \\ --role roles/compute.admin Now tasks can be scheduled on Compute Engine within $PROJECT_ID project by configuring gce_instance something like this: gce_instance : image_project : ubuntu-os-cloud image_name : ubuntu-1904-disco-v20190417 zone : us-central1-a cpu : 8 memory : 40GB disk : 60 use_ssd : true # default to false task : script : ./run-ci.sh Specify Machine Type It is possible to specify a predefined machine type via type field: gce_instance : image_project : ubuntu-os-cloud image_name : ubuntu-1604-xenial-v20171121a zone : us-central1-a type : n1-standard-8 disk : 20 Specify Image Family It's also possible to specify image family instead of the concrete image name. Use the image_family field instead of image_name : gce_instance : image_project : ubuntu-os-cloud image_family : ubuntu-1904","title":"Compute Engine"},{"location":"guide/supported-computing-services/#custom-vm-images","text":"Building an immutable VM image with all necessary software pre-configured is a known best practice with many benefits. It makes sure environment where a task is executed is always the same and that no time is spent on useless work like installing a package over and over again for every single task. There are many ways how one can create a custom image for Google Compute Engine. Please refer to the official documentation . At Cirrus Labs we are using Packer to automate building such images. An example of how we use it can be found in our public GitHub repository .","title":"Custom VM images"},{"location":"guide/supported-computing-services/#windows-support","text":"Google Compute Engine support Windows images and Cirrus CI can take full advantages of it by just explicitly specifying platform of an image like this: gce_instance : image_project : windows-cloud image_name : windows-server-2016-dc-core-v20170913 platform : windows zone : us-central1-a cpu : 8 memory : 40GB disk : 20 task : script : run-ci.bat","title":"Windows Support"},{"location":"guide/supported-computing-services/#freebsd-support","text":"Google Compute Engine support FreeBSD images and Cirrus CI can take full advantages of it by just explicitly specifying platform of an image like this: gce_instance : image_project : freebsd-org-cloud-dev image_family : freebsd-12-1 platform : FreeBSD zone : us-central1-a cpu : 8 memory : 40GB disk : 50 task : script : printenv","title":"FreeBSD Support"},{"location":"guide/supported-computing-services/#docker-containers-on-dedicated-vms","text":"It is possible to run a container directly on a Compute Engine VM with pre-installed Docker. Use the gce_container field to specify a VM image and a Docker container to execute on the VM ( gce_container extends gce_instance definition with a few additional fields): gce_container : image_project : my-project image_name : my-custom-ubuntu-with-docker container : golang:latest additional_containers : - name : redis image : redis:3.2-alpine port : 6379 Note that gce_container always runs containers in privileged mode. If your VM image has Nested Virtualization Enabled it's possible to use KVM from the container by specifying enable_nested_virtualization flag. Here is an example of using KVM-enabled container to run a hardware accelerated Android emulator: gce_container : image_project : my-project image_name : my-custom-ubuntu-with-docker-and-KVM container : cirrusci/android-sdk:29 enable_nested_virtualization : true accel_check_script : - sudo chown cirrus:cirrus /dev/kvm - emulator -accel-check","title":"Docker Containers on Dedicated VMs"},{"location":"guide/supported-computing-services/#instance-scopes","text":"By default Cirrus CI will create Google Compute instances without any scopes so an instance can't access Google Cloud Storage for example. But sometimes it can be useful to give some permissions to an instance by using scopes key of gce_instance . For example, if a particular task builds Docker images and then pushes them to Container Registry , its configuration file can look something like: gcp_credentials : ENCRYPTED[qwerty239abc] gce_instance : image_project : my-project image_name : my-custom-image-with-docker zone : us-central1-a cpu : 8 memory : 40GB disk : 20 test_task : test_script : ./scripts/test.sh push_docker_task : depends_on : test only_if : $CIRRUS_BRANCH == \"master\" gce_instance : scopes : cloud-platform push_script : ./scripts/push_docker.sh","title":"Instance Scopes"},{"location":"guide/supported-computing-services/#preemptible-instances","text":"Cirrus CI can schedule preemptible instances with all price benefits and stability risks. But sometimes risks of an instance being preempted at any time can be tolerated. For example gce_instance can be configured to schedule preemptible instance for non master branches like this: gce_instance : image_project : my-project image_name : my-custom-image-with-docker zone : us-central1-a preemptible : $CIRRUS_BRANCH != \"master\"","title":"Preemptible Instances"},{"location":"guide/supported-computing-services/#kubernetes-engine","text":"Scheduling tasks on Compute Engine has one big disadvantage of waiting for an instance to start which usually takes around a minute. One minute is not that long but can't compete with hundreds of milliseconds that takes a container cluster on GKE to start a container. To start scheduling tasks on a container cluster we first need to create one using gcloud . Here is a recommended configuration of a cluster that is very similar to what is used for the managed contianer instances. We recommend creating a cluster with two node pools: default-pool with a single node and no autoscaling for system pods required by Kubernetes. workers-pool that will use Compute-Optimized instances and SSD storage for better performance. This pool also will be able to scale to 0 when there are no tasks to run. gcloud container clusters create cirrus-ci-cluster \\ --autoscaling-profile optimize-utilization \\ --zone us-central1-a \\ --num-nodes \"1\" \\ --machine-type \"e2-standard-2\" \\ --disk-type \"pd-standard\" --disk-size \"100\" gcloud container node-pools create \"workers-pool\" \\ --cluster cirrus-ci-cluster \\ --zone \"us-central1-a\" \\ --num-nodes \"0\" \\ --enable-autoscaling --min-nodes \"0\" --max-nodes \"8\" \\ --node-taints dedicated=system:PreferNoSchedule \\ --machine-type \"c2-standard-30\" \\ --disk-type \"pd-ssd\" --disk-size \"500\" A service account that Cirrus CI operates via should be assigned with container.admin role that allows to administrate GKE clusters: gcloud projects add-iam-policy-binding $PROJECT_ID \\ --member serviceAccount:cirrus-ci@ $PROJECT_ID .iam.gserviceaccount.com \\ --role roles/container.admin Done! Now after creating cirrus-ci-cluster cluster and having gcp_credentials configured tasks can be scheduled on the newly created cluster like this: gcp_credentials : ENCRYPTED[qwerty239abc] gke_container : image : gradle:jdk8 cluster_name : cirrus-ci-cluster location : us-central1-a # cluster zone or region for multi-zone clusters namespace : default # Kubernetes namespace to create pods in cpu : 6 memory : 24GB Using in-memory disk By default Cirrus CI mounts an emptyDir into /tmp path to protect the pod from unnecessary eviction by autoscaler. It is possible to switch emptyDir's medium to use in-memory tmpfs storage instead of a default one by setting use_in_memory_disk field of gke_container to true or any other expression that uses environment variables. Running privileged containers You can run privileged containers on your private GKE cluster by setting privileged field of gke_container to true or any other expression that uses environment variables. privileged field is also available for any additional container. Here is an example of how to run docker-in-docker gke_container : image : my-docker-client:latest cluster_name : my-gke-cluster location : us-west1-c namespace : cirrus-ci additional_containers : - name : docker image : docker:dind privileged : true cpu : 2 memory : 6G port : 2375 For a full example on leveraging this to do docker-in-docker builds on Kubernetes checkout Docker Builds on Kubernetes Greedy instances Greedy instances can potentially use more CPU resources if available. Please check this blog post for more details.","title":"Kubernetes Engine"},{"location":"guide/supported-computing-services/#aws","text":"Cirrus CI can schedule tasks on several AWS services. In order to interact with AWS APIs Cirrus CI needs permissions. Creating an IAM user for programmatic access is a common way to safely give granular access to parts of your AWS. Once you created a user for Cirrus CI you'll need to provide key id and access key itself. In order to do so please create an encrypted variable with the following content: [default] aws_access_key_id = ... aws_secret_access_key = ... Then you'll be able to use the encrypted variable in your .cirrus.yml file like this: aws_credentials : ENCRYPTED[...] task : ec2_instance : ... task : eks_instance : ... Permissions A user that Cirrus CI will be using for orchestrating tasks on AWS should at least have access to S3 in order to store logs and cache artifacts. Here is a list of actions that Cirrus CI requires to store logs and artifacts: \"Action\" : [ \"s3:CreateBucket\" , \"s3:GetObject\" , \"s3:PutObject\" , \"s3:DeleteObject\" , \"s3:PutLifecycleConfiguration\" ]","title":"AWS"},{"location":"guide/supported-computing-services/#ec2","text":"In order to schedule tasks on EC2 please make sure that IAM user that Cirrus CI is using has following permissions: \"Action\" : [ \"ec2:DescribeInstances\" , \"ec2:RunInstances\" , \"ec2:TerminateInstances\" ] Now tasks can be scheduled on EC2 by configuring ec2_instance something like this: task : ec2_instance : image : ami-03790f6959fc34ef3 type : t2.micro region : us-east-1 script : ./run-ci.sh","title":"EC2"},{"location":"guide/supported-computing-services/#eks","text":"Please follow instructions on how to create a EKS cluster and add workers nodes to it. And don't forget to add necessary permissions for the IAM user that Cirrus CI is using: \"Action\" : [ \"iam:PassRole\" , \"eks:DescribeCluster\" , \"eks:CreateCluster\" , \"eks:DeleteCluster\" , \"eks:UpdateClusterVersion\" ] To verify that Cirrus CI will be able to communicate with your cluster please make sure that if you are locally logged in as the user that Cirrus CI acts as you can successfully run the following commands and see your worker nodes up and running: $: aws sts get-caller-identity { \"UserId\" : \"...\" , \"Account\" : \"...\" , \"Arn\" : \"USER_USED_BY_CIRRUS_CI\" } $: aws eks --region $REGION update-kubeconfig --name $CLUSTER_NAME $: kubectl get nodes EKS Access Denied If you have an issue with accessing your EKS cluster via kubectl , most likely you did not create the cluster with the user that Cirrus CI is using. The easiest way to do so is to create the cluster through AWS CLI with the following command: $: aws sts get-caller-identity { \"UserId\" : \"...\" , \"Account\" : \"...\" , \"Arn\" : \"USER_USED_BY_CIRRUS_CI\" } $: aws eks --region $REGION \\ create-cluster --name cirrus-ci \\ --role-arn ... \\ --resources-vpc-config subnetIds = ...,securityGroupIds = ... Now tasks can be scheduled on EKS by configuring eks_container something like this: task : eks_container : image : node:latest region : us-east-1 cluster_name : cirrus-ci script : ./run-ci.sh S3 Access for Caching Please add AmazonS3FullAccess policy to the role used for creation of EKS workers (same role you put in aws-auth-cm.yaml when enabled worker nodes to join the cluster ). Greedy instances Greedy instances can potentially use more CPU resources if available. Please check this blog post for more details.","title":"EKS"},{"location":"guide/supported-computing-services/#azure","text":"Cirrus CI can schedule tasks on several Azure services. In order to interact with Azure APIs Cirrus CI needs permissions. First, please choose a subscription you want to use for scheduling CI tasks. Navigate to the Subscriptions blade within the Azure Portal and save $SUBSCRIPTION_ID that we'll use below for setting up a service principle. Creating a service principal is a common way to safely give granular access to parts of Azure: az ad sp create-for-rbac --name CirrusCI --sdk-auth \\ --scopes \"/subscriptions/ $SUBSCRIPTION_ID \" Command above will create a new service principal and will print something like: { \"clientId\" : \"...\" , \"clientSecret\" : \"...\" , \"subscriptionId\" : \"...\" , \"tenantId\" : \"...\" , ... } Please also remember clientId from the JSON as $CIRRUS_CLIENT_ID . It will be used later for configuring blob storage access. Please create an encrypted variable from this output and add it to the top of .cirrus.yml file: azure_credentials : ENCRYPTED[qwerty239abc] You also need to create a resource group that Cirrus CI will use for scheduling tasks: az group create --location eastus --name CirrusCI Please also allow the newly created CirrusCI principle to access blob storage in order to manage logs and caches. az role assignment create \\ --role \"Storage Blob Data Contributor\" \\ --assignee $CIRRUS_CLIENT_ID \\ --scope \"/subscriptions/$SUBSCRIPTION_ID/resourceGroups/CirrusCI\" Now Cirrus CI can interact with Azure APIs.","title":"Azure"},{"location":"guide/supported-computing-services/#azure-container-instances","text":"Azure Container Instances (ACI) is an ideal candidate for running modern CI workloads. ACI allows just to run Linux and Windows containers without thinking about underlying infrastructure. Once azure_credentials is configured as described above, tasks can be scheduled on ACI by configuring aci_instance like this: azure_container_instance : image : cirrusci/windowsservercore:2016 resource_group : CirrusCI region : westus platform : windows cpu : 4 memory : 12G About Docker Images to use with ACI Linux-based images are usually pretty small and doesn't require much tweaking. For Windows containers ACI recommends to follow a few basic tips in order to reduce startup time.","title":"Azure Container Instances"},{"location":"guide/supported-computing-services/#oracle-cloud","text":"Cirrus CI can schedule tasks on several Oracle Cloud services. In order to interact with OCI APIs Cirrus CI needs permissions. Please create a user that Cirrus CI will behalf on: oci iam user create --name cirrus --description \"Cirrus CI Orchestrator\" Please configure the cirrus user to be able to access storage, launch instances and have access to Kubernetes clusters. The easiest way is to add cirrus user to Administrators group, but it's not as secure as a granular access configuration. By default, for every repository you'll start using Cirrus CI with, Cirrus will create a bucket with 90 days lifetime policy. In order to allow Cirrus to configure lifecycle policies please add the following policy as described in the documentation . Here is an example of the policy for us-ashburn-1 region: Allow service objectstorage-us-ashburn-1 to manage object-family in tenancy Once you created and configured cirrus user you'll need to provide its API key. Once you generate an API key you should get a *.pem file with the private key that will be used by Cirrus CI. Normally your config file for local use looks like this: [DEFAULT] user = ocid1.user.oc1..XXX fingerprint = 11:22:...:99 tenancy = ocid1.tenancy.oc1..YYY region = us-ashburn-1 key_file = <path to your *.pem private keyfile> For Cirrus to use, you'll need to use a different format: <user value> <fingerprint value> <tenancy value> <region value> <content of your *.pem private keyfile> This way you'll be able to create a single encrypted variable with the contents of the Cirrus specific credentials above. oracle_credentials : ENCRYPTED[qwerty239abc]","title":"Oracle Cloud"},{"location":"guide/supported-computing-services/#kubernetes-cluster","text":"Please create a Kubernetes cluster and make sure Kubernetes API Public Endpoint is enabled for the cluster so Cirrus can access it. Then copy cluster id which can be used in configuring oke_container : task : oke_container : cluster_id : ocid1.cluster.oc1.iad.xxxxxx image : golang:latest script : ./run-ci.sh Ampere A1 Support The cluster can utilize Oracle's Ampere A1 Arm instances in order to run arm64 CI workloads! Greedy instances Greedy instances can potentially use more CPU resources if available. Please check this blog post for more details.","title":"Kubernetes Cluster"},{"location":"guide/tips-and-tricks/","text":"Custom Clone Command \u00b6 By default, Cirrus CI uses a Git client implemented purely in Go to perform a clone of a single branch with full Git history. It is possible to control clone depth via CIRRUS_CLONE_DEPTH environment variable . Customizing clone behavior is a simple as overriding clone_script . For example, here an override to use a pre-installed Git client (if your build environment has it) to do a shallow clone of a single branch: task : clone_script : | if [ -z \"$CIRRUS_PR\" ]; then git clone --recursive --branch=$CIRRUS_BRANCH https://x-access-token:${CIRRUS_REPO_CLONE_TOKEN}@github.com/${CIRRUS_REPO_FULL_NAME}.git $CIRRUS_WORKING_DIR git reset --hard $CIRRUS_CHANGE_IN_REPO else git clone --recursive https://x-access-token:${CIRRUS_REPO_CLONE_TOKEN}@github.com/${CIRRUS_REPO_FULL_NAME}.git $CIRRUS_WORKING_DIR git fetch origin pull/$CIRRUS_PR/head:pull/$CIRRUS_PR git reset --hard $CIRRUS_CHANGE_IN_REPO fi # ... go-git benefits Using go-git made it possible not to require a pre-installed Git from an execution environment. For example, most of alpine -based containers don't have Git pre-installed. Because of go-git you can even use distroless containers with Cirrus CI, which don't even have an Operating System. Sharing configuration between tasks \u00b6 You can use YAML aliases to share configuration options between multiple tasks. For example, here is a 2-task build which only runs for \"master\", PRs and tags, and installs some framework: # Define a node anywhere in YAML file to create an alias. Make sure the name doesn't clash with an existing keyword. regular_task_template : &REGULAR_TASK_TEMPLATE only_if : $CIRRUS_BRANCH == 'master' || $CIRRUS_TAG != '' || $CIRRUS_PR != '' env : FRAMEWORK_PATH : \"${HOME}/framework\" install_framework_script : curl https://example.com/framework.tar | tar -C \"${FRAMEWORK_PATH}\" -x task : # This operator will insert REGULAR_TASK_TEMPLATE at this point in the task node. << : *REGULAR_TASK_TEMPLATE name : linux container : image : alpine:latest test_script : ls \"${FRAMEWORK_PATH}\" task : << : *REGULAR_TASK_TEMPLATE name : osx macos_instance : image : catalina-xcode test_script : ls -w \"${FRAMEWORK_PATH}\" Long lines in configuration file \u00b6 If you like your YAML file to fit on your screen, and some commands are just too long, you can split them across multiple lines. YAML supports a variety of options to do that, for example here's how you can split ENCRYPTED values: env : GOOGLE_APPLICATION_CREDENTIALS_DATA : \"ENCRYPTED\\ [3287dbace8346dfbe98347d1954eca923487fd8ea7251983\\ cb6d5edabdf6fe5abd711238764cbd6efbde6236abd6f274]\" Setting environment variables from scripts \u00b6 Even through most of the time you can configure environment variables via env , there are cases when a variable value is obtained only when the task is already running. Normally you'd use export for that, but since each script instruction is executed in a separate shell, the exported variables won't propagate to the next instruction. However, there's a simple solution: just write your variables in a KEY=VALUE format to the file referenced by the CIRRUS_ENV environment variable. Here's a simple example: task : get_date_script : echo \"MEMOIZED_DATE=$(date)\" >> $CIRRUS_ENV show_date_script : echo $MEMOIZED_DATE","title":"Configuration Tips and Tricks"},{"location":"guide/tips-and-tricks/#custom-clone-command","text":"By default, Cirrus CI uses a Git client implemented purely in Go to perform a clone of a single branch with full Git history. It is possible to control clone depth via CIRRUS_CLONE_DEPTH environment variable . Customizing clone behavior is a simple as overriding clone_script . For example, here an override to use a pre-installed Git client (if your build environment has it) to do a shallow clone of a single branch: task : clone_script : | if [ -z \"$CIRRUS_PR\" ]; then git clone --recursive --branch=$CIRRUS_BRANCH https://x-access-token:${CIRRUS_REPO_CLONE_TOKEN}@github.com/${CIRRUS_REPO_FULL_NAME}.git $CIRRUS_WORKING_DIR git reset --hard $CIRRUS_CHANGE_IN_REPO else git clone --recursive https://x-access-token:${CIRRUS_REPO_CLONE_TOKEN}@github.com/${CIRRUS_REPO_FULL_NAME}.git $CIRRUS_WORKING_DIR git fetch origin pull/$CIRRUS_PR/head:pull/$CIRRUS_PR git reset --hard $CIRRUS_CHANGE_IN_REPO fi # ... go-git benefits Using go-git made it possible not to require a pre-installed Git from an execution environment. For example, most of alpine -based containers don't have Git pre-installed. Because of go-git you can even use distroless containers with Cirrus CI, which don't even have an Operating System.","title":"Custom Clone Command"},{"location":"guide/tips-and-tricks/#sharing-configuration-between-tasks","text":"You can use YAML aliases to share configuration options between multiple tasks. For example, here is a 2-task build which only runs for \"master\", PRs and tags, and installs some framework: # Define a node anywhere in YAML file to create an alias. Make sure the name doesn't clash with an existing keyword. regular_task_template : &REGULAR_TASK_TEMPLATE only_if : $CIRRUS_BRANCH == 'master' || $CIRRUS_TAG != '' || $CIRRUS_PR != '' env : FRAMEWORK_PATH : \"${HOME}/framework\" install_framework_script : curl https://example.com/framework.tar | tar -C \"${FRAMEWORK_PATH}\" -x task : # This operator will insert REGULAR_TASK_TEMPLATE at this point in the task node. << : *REGULAR_TASK_TEMPLATE name : linux container : image : alpine:latest test_script : ls \"${FRAMEWORK_PATH}\" task : << : *REGULAR_TASK_TEMPLATE name : osx macos_instance : image : catalina-xcode test_script : ls -w \"${FRAMEWORK_PATH}\"","title":"Sharing configuration between tasks"},{"location":"guide/tips-and-tricks/#long-lines-in-configuration-file","text":"If you like your YAML file to fit on your screen, and some commands are just too long, you can split them across multiple lines. YAML supports a variety of options to do that, for example here's how you can split ENCRYPTED values: env : GOOGLE_APPLICATION_CREDENTIALS_DATA : \"ENCRYPTED\\ [3287dbace8346dfbe98347d1954eca923487fd8ea7251983\\ cb6d5edabdf6fe5abd711238764cbd6efbde6236abd6f274]\"","title":"Long lines in configuration file"},{"location":"guide/tips-and-tricks/#setting-environment-variables-from-scripts","text":"Even through most of the time you can configure environment variables via env , there are cases when a variable value is obtained only when the task is already running. Normally you'd use export for that, but since each script instruction is executed in a separate shell, the exported variables won't propagate to the next instruction. However, there's a simple solution: just write your variables in a KEY=VALUE format to the file referenced by the CIRRUS_ENV environment variable. Here's a simple example: task : get_date_script : echo \"MEMOIZED_DATE=$(date)\" >> $CIRRUS_ENV show_date_script : echo $MEMOIZED_DATE","title":"Setting environment variables from scripts"},{"location":"guide/windows/","text":"Windows Containers \u00b6 It is possible to run Windows Containers like how one can run Linux containers on Windows Community Cluster. To use Windows, add windows_container instead of container in .cirrus.yml files: windows_container : image : cirrusci/windowsservercore:2019 task : script : ... Cirrus CI will execute scripts instructions like Batch scripts . OS Versions \u00b6 By default, Cirrus CI assumes that the container image's host OS is Windows Server 2019. You can specify os_version to override it. Cirrus CI supports most versions of Windows Containers, including: 1709 , 1803 and 2019 . windows_container : image : cirrusci/windowsservercore:2019 windows_task : install_script : choco install -y ... ... PowerShell support \u00b6 By default Cirrus CI agent executed scripts using cmd.exe . It is possible to override default shell executor by providing CIRRUS_SHELL environment variable : env : CIRRUS_SHELL : powershell It is also possible to use PowerShell scripts inline inside of a script instruction by prefixing it with ps : windows_task : script : - ps : Get-Location ps: COMMAND is just a syntactic sugar which transforms it to: powershell.exe -NoLogo -EncodedCommand base64 ( COMMAND ) Environment Variables \u00b6 Some software installed with Chocolatey would update PATH environment variable in system settings and suggest using refreshenv to pull those changes into the current environment. Unfortunately, using refreshenv will overwrite any environment variables set in Cirrus CI configuration with system-configured defaults. We advise to make necessary changes using env and environment instead of using refreshenv command in scripts. Chocolatey \u00b6 All cirrusci/* Windows containers like cirrusci/windowsservercore:2016 have Chocolatey pre-installed. Chocolatey is a package manager for Windows which supports unattended installs of software, useful on headless machines.","title":"Windows Containers"},{"location":"guide/windows/#windows-containers","text":"It is possible to run Windows Containers like how one can run Linux containers on Windows Community Cluster. To use Windows, add windows_container instead of container in .cirrus.yml files: windows_container : image : cirrusci/windowsservercore:2019 task : script : ... Cirrus CI will execute scripts instructions like Batch scripts .","title":"Windows Containers"},{"location":"guide/windows/#os-versions","text":"By default, Cirrus CI assumes that the container image's host OS is Windows Server 2019. You can specify os_version to override it. Cirrus CI supports most versions of Windows Containers, including: 1709 , 1803 and 2019 . windows_container : image : cirrusci/windowsservercore:2019 windows_task : install_script : choco install -y ... ...","title":"OS Versions"},{"location":"guide/windows/#powershell-support","text":"By default Cirrus CI agent executed scripts using cmd.exe . It is possible to override default shell executor by providing CIRRUS_SHELL environment variable : env : CIRRUS_SHELL : powershell It is also possible to use PowerShell scripts inline inside of a script instruction by prefixing it with ps : windows_task : script : - ps : Get-Location ps: COMMAND is just a syntactic sugar which transforms it to: powershell.exe -NoLogo -EncodedCommand base64 ( COMMAND )","title":"PowerShell support"},{"location":"guide/windows/#environment-variables","text":"Some software installed with Chocolatey would update PATH environment variable in system settings and suggest using refreshenv to pull those changes into the current environment. Unfortunately, using refreshenv will overwrite any environment variables set in Cirrus CI configuration with system-configured defaults. We advise to make necessary changes using env and environment instead of using refreshenv command in scripts.","title":"Environment Variables"},{"location":"guide/windows/#chocolatey","text":"All cirrusci/* Windows containers like cirrusci/windowsservercore:2016 have Chocolatey pre-installed. Chocolatey is a package manager for Windows which supports unattended installs of software, useful on headless machines.","title":"Chocolatey"},{"location":"guide/writing-tasks/","text":"A task defines a sequence of instructions to execute and an execution environment to execute these instructions in. Let's see a line-by-line example of a .cirrus.yml configuration file first: amd64 test_task : container : image : openjdk:latest test_script : ./gradlew test arm64 test_task : arm_container : image : openjdk:latest test_script : ./gradlew test The example above defines a single task that will be scheduled and executed on the Linux Community Cluster using the gradle:jdk11 Docker image. Only one user-defined script instruction to run gradle test will be executed. Not that complex, right? Please read the topics below if you want better understand what's doing on in a more complex .cirrus.yml configuration file, such as this: amd64 task : container : image : node:latest # (1) node_modules_cache : # (2) folder : node_modules fingerprint_script : cat yarn.lock populate_script : yarn install matrix : # (3) - name : Lint skip : !changesInclude('.cirrus.yml', '**.{js,ts}' ) # (4) lint_script : yarn run lint - name : Test container : matrix : # (5) - image : node:latest - image : node:lts test_script : yarn run test - name : Publish depends_on : - Lint - Test only_if : $BRANCH == \"master\" # (6) publish_script : yarn run publish Use any Docker image from public or private registries Use cache instruction to persist folders based on an arbitrary fingerprint_script . Use matrix modification to produce many similar tasks. See what kind of files were changes and skip tasks that are not applicable. See changesInclude and changesIncludeOnly documentation for details. Use nested matrix modification to produce even more tasks. Completely exclude tasks from execution graph by any custom condition . arm64 task : arm_container : image : node:latest # (1) node_modules_cache : # (2) folder : node_modules fingerprint_script : cat yarn.lock populate_script : yarn install matrix : # (3) - name : Lint skip : !changesInclude('.cirrus.yml', '**.{js,ts}' ) # (4) lint_script : yarn run lint - name : Test arm_container : matrix : # (5) - image : node:latest - image : node:lts test_script : yarn run test - name : Publish depends_on : - Lint - Test only_if : $BRANCH == \"master\" # (6) publish_script : yarn run publish Use any Docker image from public or private registries Use cache instruction to persist folders based on an arbitrary fingerprint_script . Use matrix modification to produce many similar tasks. See what kind of files were changes and skip tasks that are not applicable. See changesInclude and changesIncludeOnly documentation for details. Use nested matrix modification to produce even more tasks. Completely exclude tasks from execution graph by any custom condition . Task Naming To name a task one can use the name field. foo_task syntax is a syntactic sugar. Separate name field is very useful when you want to have a rich task name: task : name : Tests (macOS) ... Note: instructions within a task can only be named via a prefix (e.g. test_script ). Visual Task Creation for Beginners If you are just getting started and prefer a more visual way of creating tasks, there is a third-party Cirrus CI Configuration Builder for generating YAML config that might be helpful. Execution Environment \u00b6 In order to specify where to execute a particular task you can choose from a variety of options by defining one of the following fields for a task : Field Name Managed by Description container us Linux Docker Container arm_container us Linux Arm Docker Container windows_container us Windows Docker Container docker_builder us Full-fledged VM pre-configured for running Docker macos_instance us macOS Virtual Machines freebsd_instance us FreeBSD Virtual Machines compute_engine_instance us Full-fledged custom VM persistent_worker you Use any host on any platform and architecture gce_instance you Linux, Windows and FreeBSD Virtual Machines in your GCP project gke_container you Linux Docker Containers on private GKE cluster ec2_instance you Linux Virtual Machines in your AWS eks_instance you Linux Docker Containers on private EKS cluster azure_container_instance you Linux and Windows Docker Container on Azure oke_instance you Linux x86 and Arm Containers on Oracle Cloud Supported Instructions \u00b6 Each task is essentially a collection of instructions that are executed sequentially. The following instructions are supported: script instruction to execute a script. background_script instruction to execute a script in a background. cache instruction to persist files between task runs. artifacts instruction to store and expose files created via a task. file instruction to create a file from an environment variable. Script Instruction \u00b6 A script instruction executes commands via shell on Unix or batch on Windows. A script instruction can be named by adding a name as a prefix. For example test_script or my_very_specific_build_step_script . Naming script instructions helps gather more granular information about task execution. Cirrus CI will use it in future to auto-detect performance regressions. Script commands can be specified as a single string value or a list of string values in a .cirrus.yml configuration file like in the example below: check_task : compile_script : gradle --parallel classes testClasses check_script : - echo \"Here comes more than one script!\" - printenv - gradle check Note: Each script instruction is executed in a newly created process, therefore environment variables are not preserved between them. Background Script Instruction \u00b6 A background_script instruction is absolutely the same as script instruction but Cirrus CI won't wait for the script to finish and will continue execution of further instructions. Background scripts can be useful when something needs to be executed in the background. For example, a database or some emulators. Traditionally the same effect is achieved by adding & to a command like $: command & . Problem here is that logs from command will be mixed into regular logs of the following commands. By using background scripts not only logs will be properly saved and displayed, but also command itself will be properly killed in the end of a task. Here is an example of how background_script instruction can be used to run an android emulator: android_test_task : start_emulator_background_script : emulator -avd test -no-audio -no-window wait_for_emulator_to_boot_script : adb wait-for-device test_script : gradle test Cache Instruction \u00b6 A cache instruction allows to persist a folder and reuse it during the next execution of the task. A cache instruction can be named the same way as script instruction. Here is an example: amd64 test_task : container : image : node:latest node_modules_cache : folder : node_modules reupload_on_changes : false # since there is a fingerprint script fingerprint_script : - echo $CIRRUS_OS - node --version - cat package-lock.json populate_script : - npm install test_script : npm run test arm64 test_task : arm_container : image : node:latest node_modules_cache : folder : node_modules reupload_on_changes : false # since there is a fingerprint script fingerprint_script : - echo $CIRRUS_OS - node --version - cat package-lock.json populate_script : - npm install test_script : npm run test Either folder or a folders field (with a list of folder paths) is required and they tell the agent which folder paths to cache. Folder paths should be generally relative to the working directory (e.g. node_modules ), with the exception of when only a single folder specified. In this case, it can be also an absolute path ( /usr/local/bundle ). Folder paths can contain a \"glob\" pattern to cache multiple files/folders within a working directory (e.g. **/node_modules will cache every node_modules folder within the working directory). A fingerprint_script and fingerprint_key are optional fields that can specify either: a script output of which will be hashed and used as a key for the given cache: node_modules_cache : folder : node_modules fingerprint_script : cat yarn.lock a final cache key: node_modules_cache : folder : node_modules fingerprint_key : 2038-01-20 These two fields are mutually exclusive. By default the task name is used as a fingerprint value. After the last script instruction for the task succeeds, Cirrus CI will calculate checksum of the cached folder (note that it's unrelated to fingerprint_script or fingerprint_key fields) and re-upload the cache if it finds any changes. To avoid a time-costly re-upload, remove volatile files from the cache (for example, in the last script instruction of a task). populate_script is an optional field that can specify a script that will be executed to populate the cache. populate_script should create the folder if it doesn't exist before the cache instruction. If your dependencies are updated often, please pay attention to fingerprint_script and make sure it will produce different outputs for different versions of your dependency (ideally just print locked versions of dependencies). reupload_on_changes is an optional field that can specify whether Cirrus Agent should check if contents of cached folder have changed during task execution and re-upload a cache entry in case of any changes. If reupload_on_changes option is not set explicitly then it will be set to false if fingerprint_script or fingerprint_key is presented and true otherwise. Cirrus Agent will detect additions, deletions and modifications of any files under specified folder . All of the detected changes will be logged under Upload '$CACHE_NAME' cache instructions for easier debugging of cache invalidations. That means the only difference between the example above and below is that yarn install will always be executed in the example below where in the example above only when yarn.lock has changes. amd64 test_task : container : image : node:latest node_modules_cache : folder : node_modules fingerprint_script : cat yarn.lock install_script : yarn install test_script : yarn run test arm64 test_task : arm_container : image : node:latest node_modules_cache : folder : node_modules fingerprint_script : cat yarn.lock install_script : yarn install test_script : yarn run test Caching for Pull Requests Tasks for PRs upload caches to a separate caching namespace to not interfere with caches used by other tasks. But such PR tasks can read all caches even from the main caching namespace for a repository. Scope of cached artifacts Cache artifacts are shared between tasks, so two caches with the same name on e.g. Linux containers and macOS VMs will share the same set of files. This may introduce binary incompatibility between caches. To avoid that, add echo $CIRRUS_OS into fingerprint_script or use $CIRRUS_OS in fingerprint_key , which will distinguish caches based on OS. Manual cache upload \u00b6 Normally caches are uploaded at the end of the task execution. However, you can override the default behavior and upload them earlier. To do this, use the upload_caches instruction, which uploads a list of caches passed to it once executed: amd64 test_task : container : image : node:latest node_modules_cache : folder : node_modules upload_caches : - node_modules install_script : yarn install test_script : yarn run test pip_cache : folder : ~/.cache/pip arm64 test_task : arm_container : image : node:latest node_modules_cache : folder : node_modules upload_caches : - node_modules install_script : yarn install test_script : yarn run test pip_cache : folder : ~/.cache/pip Note that pip cache won't be uploaded in this example: using upload_caches disables the default behavior where all caches are automatically uploaded at the end of the task, so if you want to upload pip cache too, you'll have to either: extend the list of uploaded caches in the first upload_caches instruction insert a second upload_caches instruction that specifically targets pip cache Artifacts Instruction \u00b6 An artifacts instruction allows to store files and expose them in the UI for downloading later. An artifacts instruction can be named the same way as script instruction and has only one required path field which accepts a glob pattern of files relative to $CIRRUS_WORKING_DIR to store. Right now only storing files under $CIRRUS_WORKING_DIR folder as artifacts is supported with a total size limit of 1G for a community task and with no limit on your own infrastructure. In the example below, Build and Test task produces two artifacts: binaries artifacts with all executables built during a successful task completion and junit artifacts with all test reports regardless of the final task status (more about that you can learn in the next section describing execution behavior ). build_and_test_task : # instructions to build and test binaries_artifacts : path : \"build/*\" always : junit_artifacts : path : \"**/test-results/**.xml\" format : junit URLs to the artifacts Latest build artifacts \u00b6 It is possible to refer to the latest artifacts directly (artifacts of the latest successful build). Use the following link format to download the latest artifact of a particular task: https://api.cirrus-ci.com/v1/artifact/github/<USER OR ORGANIZATION>/<REPOSITORY>/<TASK NAME>/<ARTIFACTS_NAME>/<PATH> It is possible to also download an archive of all files within an artifact with the following link: https://api.cirrus-ci.com/v1/artifact/github/<USER OR ORGANIZATION>/<REPOSITORY>/<TASK NAME>/<ARTIFACTS_NAME>.zip By default, Cirrus looks up the latest successful build of the default branch for the repository but the branch name can be customized via ?branch=<BRANCH> query parameter. Current build artifacts \u00b6 It is possible to refer to the artifacts of the current build directly: https://api.cirrus-ci.com/v1/artifact/build/<CIRRUS_BUILD_ID>/<ARTIFACTS_NAME>.zip Note that if several tasks are uploading artifacts with the same name then the ZIP archive from the above link will contain merged content of all artifacts. It's also possible to refer to an artifact of a particular task within a build by name: https://api.cirrus-ci.com/v1/artifact/build/<CIRRUS_BUILD_ID>/<TASK_NAME>/<ARTIFACTS_NAME>.zip It's also possible to download a particular file of an artifact and not the while archive by using <ARTIFACTS_NAME>/<PATH> instead of <ARTIFACTS_NAME>.zip . Artifact Type \u00b6 By default, Cirrus CI will try to guess mimetype of files in artifacts by looking at their extensions. In case when artifacts don't have extensions, it's possible to explicitly set the Content-Type via type field: my_task : my_dotjar_artifacts : path : build/*.jar type : application/java-archive A list of some of the basic types supported can be found here . Artifact Parsing \u00b6 Cirrus CI supports parsing artifacts in order to extract information that can be presented in the UI for a better user experience . Use the format field of an artifact instruction to specify artifact's format (mimetypes): junit_artifacts : path : \"**/test-results/**.xml\" type : text/xml format : junit Currently, Cirrus CI supports: Android Lint Report format GolangCI Lint's JSON format JUnit's XML format Python's Unittest format XCLogParser JetBrains Qodana Please let us know what kind of formats Cirrus CI should support next! File Instruction \u00b6 A file instruction allows to create a file from an environment variable. It is especially useful for situations when execution environment doesn't have proper shell to use echo ... >> ... syntax, for example, within scratch Docker containers . Here is an example of how to populate Docker config from an encrypted environment variable : task : environment : DOCKER_CONFIG : ENCRYPTED[qwerty] docker_config_file : path : /root/.docker/config variable_name : DOCKER_CONFIG Execution Behavior of Instructions \u00b6 By default Cirrus CI executes instructions one after another and stops the overall task execution on the first failure. Sometimes there might be situations when some scripts should always be executed or some debug information needs to be saved on a failure. For such situations the always and on_failure keywords can be used to group instructions. task : test_script : ./run_tests.sh on_failure : debug_script : ./print_additional_debug_info.sh always : test_reports_script : ./print_test_reports.sh In the example above, print_additional_debug_info.sh script will be executed only on failures to output some additional debug information. print_test_reports.sh on the other hand will be executed both on successful and and failed runs to print test reports (test reports are always useful! ). Environment Variables \u00b6 Environment variables can be configured under the env or environment keywords in .cirrus.yml files. Here is an example: echo_task : env : FOO : Bar echo_script : echo $FOO You can reference other environment variables using $VAR , ${VAR} or %VAR% syntax: custom_path_task : env : SDK_ROOT : ${HOME}/sdk PATH : ${SDK_ROOT}/bin:${PATH} custom_script : sdktool install Environment variables may also be set at the root level of .cirrus.yml . In that case, they will be merged with each task's individual environment variables, but the task level variables always take precedence. For example: env : PATH : /sdk/bin:${PATH} echo_task : env : PATH : /opt/bin:${PATH} echo_script : echo $PATH Will output /opt/bin:/usr/local/bin:/usr/bin or similar, but will not include /sdk/bin because this root level setting is ignored. Also some default environment variables are pre-defined: Name Value / Description CI true CIRRUS_CI true CI_NODE_INDEX Index of the current task within CI_NODE_TOTAL tasks CI_NODE_TOTAL Total amount of unique tasks for a given CIRRUS_BUILD_ID build CONTINUOUS_INTEGRATION true CIRRUS_API_CREATED true if the current build was created through the API . CIRRUS_BASE_BRANCH Base branch name if current build was triggered by a PR. For example master CIRRUS_BASE_SHA Base SHA if current build was triggered by a PR CIRRUS_BRANCH Branch name. For example my-feature CIRRUS_BUILD_ID Unique build ID CIRRUS_CHANGE_IN_REPO Git SHA CIRRUS_CHANGE_MESSAGE Commit message or PR title and description, depending on trigger event (Non-PRs or PRs respectively). CIRRUS_CHANGE_TITLE First line of CIRRUS_CHANGE_MESSAGE CIRRUS_CRON Cron Build name if builds was triggered by Cron. CIRRUS_DEFAULT_BRANCH Default repository branch name. For example master CIRRUS_DOCKER_CONTEXT Docker build's context directory to use for Dockerfile as a CI environment . Defaults to project's root directory. CIRRUS_LAST_GREEN_BUILD_ID The build id of the last successful build on the same branch at the time of the current build creation. CIRRUS_LAST_GREEN_CHANGE Corresponding to CIRRUS_LAST_GREEN_BUILD_ID SHA (used in changesInclude and changesIncludeOnly functions). CIRRUS_PR PR number if current build was triggered by a PR. For example 239 . CIRRUS_PR_DRAFT true if current build was triggered by a Draft PR. CIRRUS_TAG Tag name if current build was triggered by a new tag. For example v1.0 CIRRUS_OS, OS Host OS. Either linux , windows or darwin . CIRRUS_TASK_NAME Task name CIRRUS_TASK_ID Unique task ID CIRRUS_RELEASE GitHub Release id if current tag was created for a release. Handy for uploading release assets . CIRRUS_REPO_CLONE_TOKEN Temporary GitHub access token to perform a clone. CIRRUS_REPO_NAME Repository name. For example my-project CIRRUS_REPO_OWNER Repository owner (an organization or a user). For example my-organization CIRRUS_REPO_FULL_NAME Repository full name/slug. For example my-organization/my-project CIRRUS_REPO_CLONE_URL URL used for cloning. For example https://github.com/my-organization/my-project.git CIRRUS_USER_COLLABORATOR true if a user initialized a build is already a contributor to the repository. false otherwise. CIRRUS_USER_PERMISSION admin , write , read or none . CIRRUS_HTTP_CACHE_HOST Host and port number on which local HTTP cache can be accessed on. GITHUB_CHECK_SUITE_ID Monotonically increasing id of a corresponding GitHub Check Suite which caused the Cirrus CI build. CIRRUS_ENV Path to a file, by writing to which you can set task-wide environment variables . Behavioral Environment Variables \u00b6 And some environment variables can be set to control behavior of the Cirrus CI Agent: Name Default Value Description CIRRUS_CLONE_DEPTH 0 which will reflect in a full clone of a single branch Clone depth. CIRRUS_CLONE_SUBMODULES false Set to true to clone submodules recursively. CIRRUS_LOG_TIMESTAMP false Indicate Cirrus Agent to prepend timestamp to each line of logs. CIRRUS_SHELL sh on Linux/macOS/FreeBSD and cmd.exe on Windows. Set to direct to execute each script directly without wrapping the commands in a shell script. Shell that Cirrus CI uses to execute scripts. By default sh is used. CIRRUS_VOLUME /tmp Defines a path for a temporary volume to be mounted into instances running in a Kubernetes cluster. This volume is mounted into all additional containers and is persisted between steps of a pipe . CIRRUS_WORKING_DIR cirrus-ci-build folder inside of a system's temporary folder Working directory where Cirrus CI executes builds. Default to cirrus-ci-build folder inside of a system's temporary folder. Encrypted Variables \u00b6 It is possible to add encrypted variables to a .cirrus.yml file. These variables are decrypted only in builds for commits and pull requests that are made by users with write permission or approved by them. In order to encrypt a variable go to repository's settings page via clicking settings icon on a repository's main page (for example https://cirrus-ci.com/github/my-organization/my-repository ) and follow instructions. Warning Only users with WRITE permissions can add encrypted variables to a repository. An encrypted variable will be presented in a form like ENCRYPTED[qwerty239abc] which can be safely committed to .cirrus.yml file: publish_task : environment : AUTH_TOKEN : ENCRYPTED[qwerty239abc] script : ./publish.sh Cirrus CI encrypts variables with a unique per repository 256-bit encryption key so forks and even repositories within the same organization cannot re-use them. qwerty239abc from the example above is NOT the content of your encrypted variable, it's just an internal ID. No one can brute force your secrets from such ID. In addition, Cirrus CI doesn't know a relation between an encrypted variable and a repository for which the encrypted variable was created. Organization Level Encrypted Variables Sometimes there might be secrets that are used in almost all repositories of an organization. For example, credentials to a compute service where tasks will be executed. In order to create such sharable encrypted variable go to organization's settings page via clicking settings icon on an organization's main page (for example https://cirrus-ci.com/github/my-organization ) and follow instructions in Organization Level Encrypted Variables section. Encrypted Variable for Cloud Credentials In case you use integration with one of supported computing services , an encrypted variable used to store credentials that Cirrus is using to communicate with the computing service won't be decrypted if used in environment variables . These credentials have too many permissions for most of the cases, please create separate credentials with the minimum needed permissions for your specific case. gcp_credentials : SECURED[!qwerty] env : CREDENTIALS : SECURED[!qwerty] # won't be decrypted in any case Skipping Task in Forked Repository In forked repository the decryption of variable fails, which causes failure of task depending on it. To avoid this by default, make the sensitive task conditional: task : name : Task requiring decrypted variables only_if : $CIRRUS_REPO_OWNER == 'my-organization' ... Owner of forked repository can re-enable the task, if they have the required sensitive data, by encrypting the variable by themselves and editing both the encrypted variable and repo-owner condition in the .cirrus.yml file. Cron Builds \u00b6 It is possible to configure invocations of re-occurring builds via the well-known Cron expressions. Cron builds can be configured on a repository's settings page (not in .cirrus.yml ). It's possible to configure several cron builds with unique names which will be available via CIRRUS_CRON environment variable . Each cron build should specify branch to trigger new builds for and a cron expression compatible with Quartz. You can use this generator to generate/validate your expressions. Note: Cron Builds are timed with the UTC timezone. Matrix Modification \u00b6 Sometimes it's useful to run the same task against different software versions. Or run different batches of tests based on an environment variable. For cases like these, the matrix modifier comes very handy. It's possible to use matrix keyword only inside of a particular task to have multiple tasks based on the original one. Each new task will be created from the original task by replacing the whole matrix YAML node with each matrix 's children separately. Let check an example of a .cirrus.yml : amd64 test_task : container : matrix : - image : node:latest - image : node:lts test_script : yarn run test arm64 test_task : arm_container : matrix : - image : node:latest - image : node:lts test_script : yarn run test Which will be expanded into: amd64 test_task : container : image : node:latest test_script : yarn run test test_task : container : image : node:lts test_script : yarn run test arm64 test_task : arm_container : image : node:latest test_script : yarn run test test_task : arm_container : image : node:lts test_script : yarn run test Tip The matrix modifier can be used multiple times within a task. The matrix modification makes it easy to create some pretty complex testing scenarios like this: amd64 task : container : matrix : - image : node:latest - image : node:lts node_modules_cache : folder : node_modules fingerprint_script : - node --version - cat yarn.lock populate_script : yarn install matrix : - name : Build build_script : yarn build - name : Test test_script : yarn run test arm64 task : arm_container : matrix : - image : node:latest - image : node:lts node_modules_cache : folder : node_modules fingerprint_script : - node --version - cat yarn.lock populate_script : yarn install matrix : - name : Build build_script : yarn build - name : Test test_script : yarn run test Task Execution Dependencies \u00b6 Sometimes it might be very handy to execute some tasks only after successful execution of other tasks. For such cases it is possible to specify task names that a particular task depends. Use depends_on keyword to define dependencies: amd64 container : image : node:latest lint_task : script : yarn run lint test_task : script : yarn run test publish_task : depends_on : - test - lint script : yarn run publish arm64 arm_container : image : node:latest lint_task : script : yarn run lint test_task : script : yarn run test publish_task : depends_on : - test - lint script : yarn run publish Task Names and Aliases It is possible to specify the task's name via the name field. lint_task syntax is a syntactic sugar that will be expanded into: task : name : lint ... Names can be also pretty complex: task : name : Test Shard $TESTS_SPLIT env : matrix : TESTS_SPLIT : 1/3 TESTS_SPLIT : 2/2 TESTS_SPLIT : 3/3 tests_script : ./.ci/tests.sh deploy_task : only_if : $CIRRUS_BRANCH == 'master' depends_on : - Test Shard 1/3 - Test Shard 2/3 - Test Shard 3/3 script : ./.ci/deploy.sh ... Complex task names make it difficult to list and maintain all of such task names in your depends_on field. In order to make it simpler you can use the alias field to have a short simplified name for several tasks to use in depends_on . Here is a modified version of an example above that leverages the alias field: task : name : Test Shard $TESTS_SPLIT alias : Tests env : matrix : TESTS_SPLIT : 1/3 TESTS_SPLIT : 2/2 TESTS_SPLIT : 3/3 tests_script : ./.ci/tests.sh deploy_task : only_if : $CIRRUS_BRANCH == 'master' depends_on : Tests script : ./.ci/deploy.sh Conditional Task Execution \u00b6 Some tasks are meant to be created only if a certain condition is met. And some tasks can be skipped in some cases. Cirrus CI supports the only_if and skip keywords in order to provide such flexibility: The only_if keyword controls whether or not a task will be created. For example, you may want to publish only changes committed to the master branch. publish_task : only_if : $CIRRUS_BRANCH == 'master' script : yarn run publish The skip keyword allows to skip execution of a task and mark it as successful. For example, you may want to skip linting if no source files have changed since the last successful run. lint_task : skip : \"!changesInclude('.cirrus.yml', '**.{js,ts}')\" script : yarn run lint Skip CI Completely Just include [skip ci] or [skip cirrus] in the first line of your commit message in order to skip CI execution for a commit completely. If you push multiple commits at the same time, only the first line of the last commit message will be checked for [skip ci] or [ci skip] . If you open a PR, PR title will be checked for [skip ci] or [ci skip] instead of the last commit message on the PR branch. Supported Operators \u00b6 Currently only basic operators like == , != , =~ , !=~ , && , || and unary ! are supported in only_if and skip expressions. Environment variables can also be used as usually. Pattern Matching Example Use =~ operator for pattern matching. check_aggreement_task : only_if : $CIRRUS_BRANCH =~ 'pull/.*' Note that =~ operator can match against multiline values (dotall mode) and therefore looking for the exact occurrence of the regular expression so don't forget to use .* around your term for matching it at any position (for example, $CIRRUS_CHANGE_TITLE =~ '.*[docs].*' ). Supported Functions \u00b6 Currently two functions are supported in the only_if and skip expressions: changesInclude function allows to check which files were changed changesIncludeOnly is a more strict version of changesInclude , i.e. it won't evaluate to true if there are changed files other than the ones covered by patterns These two functions behave differently for PR builds and regular builds: For PR builds, functions check the list of files affected by the PR. For regular builds, the CIRRUS_LAST_GREEN_CHANGE environment variable will be used to determine list of affected files between CIRRUS_LAST_GREEN_CHANGE and CIRRUS_CHANGE_IN_REPO . changesInclude function can be very useful for skipping some tasks when no changes to sources have been made since the last successful Cirrus CI build. lint_task : skip : \"!changesInclude('.cirrus.yml', '**.{js,ts}')\" script : yarn run lint changesIncludeOnly function can be used to skip running a heavyweight task if only documentation was changed, for example: build_task : skip : \"changesIncludeOnly('doc/*')\" Auto-Cancellation of Tasks \u00b6 Cirrus CI can automatically cancel tasks in case of new pushes to the same branch. By default, Cirrus CI auto-cancels all tasks for non default branch (for most repositories master branch) but this behavior can be changed by specifying auto_cancellation field: task : auto_cancellation : $CIRRUS_BRANCH != 'master' && $CIRRUS_BRANCH !=~ 'release/.*' ... Stateful Tasks \u00b6 It's possible to tell Cirrus CI that a certain task is stateful and Cirrus CI will use a slightly different scheduling algorithm to minimize chances of such tasks being interrupted. Stateful tasks are intended to use low CPU count. Scheduling times of such stateful tasks might be a bit longer then usual especially for tasks with high CPU requirements. By default, Cirrus CI marks a task as stateful if its name contains one of the following terms: deploy , push , publish , upload or release . Otherwise, you can explicitly mark a task as stateful via stateful field: task : name : Propagate to Production stateful : true ... Failure Toleration \u00b6 Sometimes tasks can play a role of sanity checks. For example, a task can check that your library is working with the latest nightly version of some dependency package. It will be great to be notified about such failures but it's not necessary to fail the whole build when a failure occurs. Cirrus CI has the allow_failures keyword which will make a task to not affect the overall status of a build. test_nightly_task : allow_failures : $SOME_PACKAGE_DEPENDENCY_VERSION == 'nightly' Skipping Notifications You can also skip posting red statuses to GitHub via skip_notifications field. skip_notifications : $SOME_PACKAGE_DEPENDENCY_VERSION == 'nightly' It can help to track potential issues overtime without distracting the main workflow. Manual tasks \u00b6 By default a Cirrus CI task is automatically triggered when all its dependency tasks finished successfully. Sometimes though, it can be very handy to trigger some tasks manually, for example, perform a deployment to staging for manual testing upon all automation checks have succeeded. In order change the default behavior please use trigger_type field like this: task : name : \"Staging Deploy\" trigger_type : manual depends_on : - Tests (Unit) - Tests (Ingegration) - Lint You'll be able to manually trigger such paused tasks via Cirrus CI Web UI or directly from GitHub Checks page. Task Execution Lock \u00b6 Some CI tasks perform external operations which are required to be executed one at a time. For example, parallel deploys to the same environment is usually a bad idea. In order to restrict parallel execution of a certain task within a repository, you can use execution_lock to specify a task's lock key, a unique string that will be used to make sure that any tasks with the same execution_lock string are executed one at a time. Here is an example of how to make sure deployments on a specific branch can not run in parallel: task : name : \"Automatic Staging Deploy\" execution_lock : $CIRRUS_BRANCH You'll be able to manually trigger such paused tasks via the Cirrus CI Web Dashboard or directly from the commit's checks page on GitHub. Required PR Labels \u00b6 Similar to manual tasks Cirrus CI can pause execution of tasks until a corresponding PR gets labeled. This can be particular useful when you'd like to do an initial review before running all unit and integration tests on every supported platform . Use the required_pr_labels field to specify a list of labels a PR requires to have in order to trigger a task. Here is a simple example of .cirrus.yml config that automatically runs a linting tool but requires initial-review label being presented in order to run tests: lint_task : # ... test_task : required_pr_labels : initial-review # ... Note: required_pr_labels has no effect on tasks created for non-PR builds. You can also require multiple labels to continue executing the task for even more flexibility: deploy_task : required_pr_labels : - initial-review - ready-for-staging depends_on : build # ... In the example above both initial-review and ready-for-staging labels should be presented on a PR in order to perform a deployment via deploy task. HTTP Cache \u00b6 For the most cases regular caching mechanism where Cirrus CI caches a folder is more than enough. But modern build systems like Gradle , Bazel and Pants can take advantage of remote caching. Remote caching is when a build system uploads and downloads intermediate results of a build execution while the build itself is still executing. Cirrus CI agent starts a local caching server and exposes it via CIRRUS_HTTP_CACHE_HOST environments variable. Caching server supports GET , POST and HEAD requests to upload, download and check presence of artifacts. Info If port 12321 is available CIRRUS_HTTP_CACHE_HOST will be equal to localhost:12321 . For example running the following command: curl -s -X POST --data-binary @myfolder.tar.gz http:// $CIRRUS_HTTP_CACHE_HOST /name-key ...has the same effect as the following caching instruction : name_cache : folder : myfolder fingerprint_key : key Info To see how HTTP Cache can be used with Gradle's Build Cache please check this example . Additional Containers \u00b6 Sometimes one container is not enough to run a CI build. For example, your application might use a MySQL database as a storage. In this case you most likely want a MySQL instance running for your tests. One option here is to pre-install MySQL and use a background_script to start it. This approach has some inconveniences like the need to pre-install MySQL by building a custom Docker container. For such use cases Cirrus CI allows to run additional containers in parallel with the main container that executes a task. Each additional container is defined under additional_containers keyword in .cirrus.yml . Each additional container should have a unique name and specify at least Docker image and port that this container exposes. In the example below we use an official MySQL Docker image that exposes the standard MySQL port (3306). Tests will be able to access MySQL instance via localhost:3306 . amd64 container : image : golang:latest additional_containers : - name : mysql image : mysql:latest port : 3306 cpu : 1.0 memory : 512Mi env : MYSQL_ROOT_PASSWORD : \"\" arm64 arm_container : image : golang:latest additional_containers : - name : mysql image : mysql:latest port : 3306 cpu : 1.0 memory : 512Mi env : MYSQL_ROOT_PASSWORD : \"\" Additional container can be very handy in many scenarios. Please check Cirrus CI catalog of examples for more details. Default Resources By default, each additional container will get 0.5 CPU and 512Mi of memory. These values can be configured as usual via cpu and memory fields. Port Mapping It's also possible to map ports of additional containers by using <HOST_PORT>:<CONTAINER_PORT> format for the port field. For example, port: 80:8080 will map port 8080 of the container to be available on local port 80 within a task. Note: don't use port mapping unless absolutely necessary. A perfect use case is when you have several additional containers which start the service on the same port and there's no easy way to change that. Port mapping limits the number of places the container can be scheduled and will affect how fast such tasks are scheduled. To specify multiple mappings use the ports field, instead of the port : ports : - 8080 - 3306 Overriding Default Command It's also possible to override the default CMD of an additional container via command field: amd64 container : image : golang:latest additional_containers : - name : mysql image : mysql:latest port : 7777 command : mysqld --port 7777 env : MYSQL_ROOT_PASSWORD : \"\" arm64 arm_container : image : golang:latest additional_containers : - name : mysql image : mysql:latest port : 7777 command : mysqld --port 7777 env : MYSQL_ROOT_PASSWORD : \"\" Warning Note that additional_containers can be used only with Community Cluster or Google's Kubernetes Engine . Embedded Badges \u00b6 Cirrus CI provides a way to embed a badge that can represent status of your builds into a ReadMe file or a website. For example, this is a badge for cirruslabs/cirrus-ci-web repository that contains Cirrus CI's front end: In order to embed such a check into a \"read-me\" file or your website, just use a URL to a badge that looks like this: https://api.cirrus-ci.com/github/<USER OR ORGANIZATION>/<REPOSITORY>.svg If you want a badge for a particular branch, use the ?branch=<BRANCH NAME> query parameter (at the end of the URL) like this: https://api.cirrus-ci.com/github/<USER OR ORGANIZATION>/<REPOSITORY>.svg?branch=<BRANCH NAME> By default, Cirrus picks the latest build in a final state for the repository or a particular branch if branch parameter is specified. It's also possible to explicitly set a concrete build to use with ?buildId=<BUILD ID> query parameter. If you want a badge for a particular task within the latest finished build, use the ?task=<TASK NAME> query parameter (at the end of the URL) like this: https://api.cirrus-ci.com/github/<USER OR ORGANIZATION>/<REPOSITORY>.svg?task=tests You can even pick a specific script instruction within the task with an additional script=<SCRIPT NAME> parameter: https://api.cirrus-ci.com/github/<USER OR ORGANIZATION>/<REPOSITORY>.svg?task=build&script=lint Badges in Markdown \u00b6 Here is how Cirrus CI's badge can be embeded in a Markdown file: [ ![Build Status ]( https://api.cirrus-ci.com/github/<USER OR ORGANIZATION>/<REPOSITORY>.svg )](https://cirrus-ci.com/github/<USER OR ORGANIZATION>/<REPOSITORY>) CCTray XML \u00b6 Cirrus CI supports exporting information about the latest repository builds via the CCTray XML format . Use the following URL format with a tool of your choice (such as CCMenu ): https://api.cirrus-ci.com/github/<USER OR ORGANIZATION>/<REPOSITORY>/cctray.xml Note: for private repositories you'll need to configure access token .","title":"Writing Tasks"},{"location":"guide/writing-tasks/#execution-environment","text":"In order to specify where to execute a particular task you can choose from a variety of options by defining one of the following fields for a task : Field Name Managed by Description container us Linux Docker Container arm_container us Linux Arm Docker Container windows_container us Windows Docker Container docker_builder us Full-fledged VM pre-configured for running Docker macos_instance us macOS Virtual Machines freebsd_instance us FreeBSD Virtual Machines compute_engine_instance us Full-fledged custom VM persistent_worker you Use any host on any platform and architecture gce_instance you Linux, Windows and FreeBSD Virtual Machines in your GCP project gke_container you Linux Docker Containers on private GKE cluster ec2_instance you Linux Virtual Machines in your AWS eks_instance you Linux Docker Containers on private EKS cluster azure_container_instance you Linux and Windows Docker Container on Azure oke_instance you Linux x86 and Arm Containers on Oracle Cloud","title":"Execution Environment"},{"location":"guide/writing-tasks/#supported-instructions","text":"Each task is essentially a collection of instructions that are executed sequentially. The following instructions are supported: script instruction to execute a script. background_script instruction to execute a script in a background. cache instruction to persist files between task runs. artifacts instruction to store and expose files created via a task. file instruction to create a file from an environment variable.","title":"Supported Instructions"},{"location":"guide/writing-tasks/#script-instruction","text":"A script instruction executes commands via shell on Unix or batch on Windows. A script instruction can be named by adding a name as a prefix. For example test_script or my_very_specific_build_step_script . Naming script instructions helps gather more granular information about task execution. Cirrus CI will use it in future to auto-detect performance regressions. Script commands can be specified as a single string value or a list of string values in a .cirrus.yml configuration file like in the example below: check_task : compile_script : gradle --parallel classes testClasses check_script : - echo \"Here comes more than one script!\" - printenv - gradle check Note: Each script instruction is executed in a newly created process, therefore environment variables are not preserved between them.","title":"Script Instruction"},{"location":"guide/writing-tasks/#background-script-instruction","text":"A background_script instruction is absolutely the same as script instruction but Cirrus CI won't wait for the script to finish and will continue execution of further instructions. Background scripts can be useful when something needs to be executed in the background. For example, a database or some emulators. Traditionally the same effect is achieved by adding & to a command like $: command & . Problem here is that logs from command will be mixed into regular logs of the following commands. By using background scripts not only logs will be properly saved and displayed, but also command itself will be properly killed in the end of a task. Here is an example of how background_script instruction can be used to run an android emulator: android_test_task : start_emulator_background_script : emulator -avd test -no-audio -no-window wait_for_emulator_to_boot_script : adb wait-for-device test_script : gradle test","title":"Background Script Instruction"},{"location":"guide/writing-tasks/#cache-instruction","text":"A cache instruction allows to persist a folder and reuse it during the next execution of the task. A cache instruction can be named the same way as script instruction. Here is an example: amd64 test_task : container : image : node:latest node_modules_cache : folder : node_modules reupload_on_changes : false # since there is a fingerprint script fingerprint_script : - echo $CIRRUS_OS - node --version - cat package-lock.json populate_script : - npm install test_script : npm run test arm64 test_task : arm_container : image : node:latest node_modules_cache : folder : node_modules reupload_on_changes : false # since there is a fingerprint script fingerprint_script : - echo $CIRRUS_OS - node --version - cat package-lock.json populate_script : - npm install test_script : npm run test Either folder or a folders field (with a list of folder paths) is required and they tell the agent which folder paths to cache. Folder paths should be generally relative to the working directory (e.g. node_modules ), with the exception of when only a single folder specified. In this case, it can be also an absolute path ( /usr/local/bundle ). Folder paths can contain a \"glob\" pattern to cache multiple files/folders within a working directory (e.g. **/node_modules will cache every node_modules folder within the working directory). A fingerprint_script and fingerprint_key are optional fields that can specify either: a script output of which will be hashed and used as a key for the given cache: node_modules_cache : folder : node_modules fingerprint_script : cat yarn.lock a final cache key: node_modules_cache : folder : node_modules fingerprint_key : 2038-01-20 These two fields are mutually exclusive. By default the task name is used as a fingerprint value. After the last script instruction for the task succeeds, Cirrus CI will calculate checksum of the cached folder (note that it's unrelated to fingerprint_script or fingerprint_key fields) and re-upload the cache if it finds any changes. To avoid a time-costly re-upload, remove volatile files from the cache (for example, in the last script instruction of a task). populate_script is an optional field that can specify a script that will be executed to populate the cache. populate_script should create the folder if it doesn't exist before the cache instruction. If your dependencies are updated often, please pay attention to fingerprint_script and make sure it will produce different outputs for different versions of your dependency (ideally just print locked versions of dependencies). reupload_on_changes is an optional field that can specify whether Cirrus Agent should check if contents of cached folder have changed during task execution and re-upload a cache entry in case of any changes. If reupload_on_changes option is not set explicitly then it will be set to false if fingerprint_script or fingerprint_key is presented and true otherwise. Cirrus Agent will detect additions, deletions and modifications of any files under specified folder . All of the detected changes will be logged under Upload '$CACHE_NAME' cache instructions for easier debugging of cache invalidations. That means the only difference between the example above and below is that yarn install will always be executed in the example below where in the example above only when yarn.lock has changes. amd64 test_task : container : image : node:latest node_modules_cache : folder : node_modules fingerprint_script : cat yarn.lock install_script : yarn install test_script : yarn run test arm64 test_task : arm_container : image : node:latest node_modules_cache : folder : node_modules fingerprint_script : cat yarn.lock install_script : yarn install test_script : yarn run test Caching for Pull Requests Tasks for PRs upload caches to a separate caching namespace to not interfere with caches used by other tasks. But such PR tasks can read all caches even from the main caching namespace for a repository. Scope of cached artifacts Cache artifacts are shared between tasks, so two caches with the same name on e.g. Linux containers and macOS VMs will share the same set of files. This may introduce binary incompatibility between caches. To avoid that, add echo $CIRRUS_OS into fingerprint_script or use $CIRRUS_OS in fingerprint_key , which will distinguish caches based on OS.","title":"Cache Instruction"},{"location":"guide/writing-tasks/#manual-cache-upload","text":"Normally caches are uploaded at the end of the task execution. However, you can override the default behavior and upload them earlier. To do this, use the upload_caches instruction, which uploads a list of caches passed to it once executed: amd64 test_task : container : image : node:latest node_modules_cache : folder : node_modules upload_caches : - node_modules install_script : yarn install test_script : yarn run test pip_cache : folder : ~/.cache/pip arm64 test_task : arm_container : image : node:latest node_modules_cache : folder : node_modules upload_caches : - node_modules install_script : yarn install test_script : yarn run test pip_cache : folder : ~/.cache/pip Note that pip cache won't be uploaded in this example: using upload_caches disables the default behavior where all caches are automatically uploaded at the end of the task, so if you want to upload pip cache too, you'll have to either: extend the list of uploaded caches in the first upload_caches instruction insert a second upload_caches instruction that specifically targets pip cache","title":"Manual cache upload"},{"location":"guide/writing-tasks/#artifacts-instruction","text":"An artifacts instruction allows to store files and expose them in the UI for downloading later. An artifacts instruction can be named the same way as script instruction and has only one required path field which accepts a glob pattern of files relative to $CIRRUS_WORKING_DIR to store. Right now only storing files under $CIRRUS_WORKING_DIR folder as artifacts is supported with a total size limit of 1G for a community task and with no limit on your own infrastructure. In the example below, Build and Test task produces two artifacts: binaries artifacts with all executables built during a successful task completion and junit artifacts with all test reports regardless of the final task status (more about that you can learn in the next section describing execution behavior ). build_and_test_task : # instructions to build and test binaries_artifacts : path : \"build/*\" always : junit_artifacts : path : \"**/test-results/**.xml\" format : junit URLs to the artifacts","title":"Artifacts Instruction"},{"location":"guide/writing-tasks/#latest-build-artifacts","text":"It is possible to refer to the latest artifacts directly (artifacts of the latest successful build). Use the following link format to download the latest artifact of a particular task: https://api.cirrus-ci.com/v1/artifact/github/<USER OR ORGANIZATION>/<REPOSITORY>/<TASK NAME>/<ARTIFACTS_NAME>/<PATH> It is possible to also download an archive of all files within an artifact with the following link: https://api.cirrus-ci.com/v1/artifact/github/<USER OR ORGANIZATION>/<REPOSITORY>/<TASK NAME>/<ARTIFACTS_NAME>.zip By default, Cirrus looks up the latest successful build of the default branch for the repository but the branch name can be customized via ?branch=<BRANCH> query parameter.","title":"Latest build artifacts"},{"location":"guide/writing-tasks/#current-build-artifacts","text":"It is possible to refer to the artifacts of the current build directly: https://api.cirrus-ci.com/v1/artifact/build/<CIRRUS_BUILD_ID>/<ARTIFACTS_NAME>.zip Note that if several tasks are uploading artifacts with the same name then the ZIP archive from the above link will contain merged content of all artifacts. It's also possible to refer to an artifact of a particular task within a build by name: https://api.cirrus-ci.com/v1/artifact/build/<CIRRUS_BUILD_ID>/<TASK_NAME>/<ARTIFACTS_NAME>.zip It's also possible to download a particular file of an artifact and not the while archive by using <ARTIFACTS_NAME>/<PATH> instead of <ARTIFACTS_NAME>.zip .","title":"Current build artifacts"},{"location":"guide/writing-tasks/#artifact-type","text":"By default, Cirrus CI will try to guess mimetype of files in artifacts by looking at their extensions. In case when artifacts don't have extensions, it's possible to explicitly set the Content-Type via type field: my_task : my_dotjar_artifacts : path : build/*.jar type : application/java-archive A list of some of the basic types supported can be found here .","title":"Artifact Type"},{"location":"guide/writing-tasks/#artifact-parsing","text":"Cirrus CI supports parsing artifacts in order to extract information that can be presented in the UI for a better user experience . Use the format field of an artifact instruction to specify artifact's format (mimetypes): junit_artifacts : path : \"**/test-results/**.xml\" type : text/xml format : junit Currently, Cirrus CI supports: Android Lint Report format GolangCI Lint's JSON format JUnit's XML format Python's Unittest format XCLogParser JetBrains Qodana Please let us know what kind of formats Cirrus CI should support next!","title":"Artifact Parsing"},{"location":"guide/writing-tasks/#file-instruction","text":"A file instruction allows to create a file from an environment variable. It is especially useful for situations when execution environment doesn't have proper shell to use echo ... >> ... syntax, for example, within scratch Docker containers . Here is an example of how to populate Docker config from an encrypted environment variable : task : environment : DOCKER_CONFIG : ENCRYPTED[qwerty] docker_config_file : path : /root/.docker/config variable_name : DOCKER_CONFIG","title":"File Instruction"},{"location":"guide/writing-tasks/#execution-behavior-of-instructions","text":"By default Cirrus CI executes instructions one after another and stops the overall task execution on the first failure. Sometimes there might be situations when some scripts should always be executed or some debug information needs to be saved on a failure. For such situations the always and on_failure keywords can be used to group instructions. task : test_script : ./run_tests.sh on_failure : debug_script : ./print_additional_debug_info.sh always : test_reports_script : ./print_test_reports.sh In the example above, print_additional_debug_info.sh script will be executed only on failures to output some additional debug information. print_test_reports.sh on the other hand will be executed both on successful and and failed runs to print test reports (test reports are always useful! ).","title":"Execution Behavior of Instructions"},{"location":"guide/writing-tasks/#environment-variables","text":"Environment variables can be configured under the env or environment keywords in .cirrus.yml files. Here is an example: echo_task : env : FOO : Bar echo_script : echo $FOO You can reference other environment variables using $VAR , ${VAR} or %VAR% syntax: custom_path_task : env : SDK_ROOT : ${HOME}/sdk PATH : ${SDK_ROOT}/bin:${PATH} custom_script : sdktool install Environment variables may also be set at the root level of .cirrus.yml . In that case, they will be merged with each task's individual environment variables, but the task level variables always take precedence. For example: env : PATH : /sdk/bin:${PATH} echo_task : env : PATH : /opt/bin:${PATH} echo_script : echo $PATH Will output /opt/bin:/usr/local/bin:/usr/bin or similar, but will not include /sdk/bin because this root level setting is ignored. Also some default environment variables are pre-defined: Name Value / Description CI true CIRRUS_CI true CI_NODE_INDEX Index of the current task within CI_NODE_TOTAL tasks CI_NODE_TOTAL Total amount of unique tasks for a given CIRRUS_BUILD_ID build CONTINUOUS_INTEGRATION true CIRRUS_API_CREATED true if the current build was created through the API . CIRRUS_BASE_BRANCH Base branch name if current build was triggered by a PR. For example master CIRRUS_BASE_SHA Base SHA if current build was triggered by a PR CIRRUS_BRANCH Branch name. For example my-feature CIRRUS_BUILD_ID Unique build ID CIRRUS_CHANGE_IN_REPO Git SHA CIRRUS_CHANGE_MESSAGE Commit message or PR title and description, depending on trigger event (Non-PRs or PRs respectively). CIRRUS_CHANGE_TITLE First line of CIRRUS_CHANGE_MESSAGE CIRRUS_CRON Cron Build name if builds was triggered by Cron. CIRRUS_DEFAULT_BRANCH Default repository branch name. For example master CIRRUS_DOCKER_CONTEXT Docker build's context directory to use for Dockerfile as a CI environment . Defaults to project's root directory. CIRRUS_LAST_GREEN_BUILD_ID The build id of the last successful build on the same branch at the time of the current build creation. CIRRUS_LAST_GREEN_CHANGE Corresponding to CIRRUS_LAST_GREEN_BUILD_ID SHA (used in changesInclude and changesIncludeOnly functions). CIRRUS_PR PR number if current build was triggered by a PR. For example 239 . CIRRUS_PR_DRAFT true if current build was triggered by a Draft PR. CIRRUS_TAG Tag name if current build was triggered by a new tag. For example v1.0 CIRRUS_OS, OS Host OS. Either linux , windows or darwin . CIRRUS_TASK_NAME Task name CIRRUS_TASK_ID Unique task ID CIRRUS_RELEASE GitHub Release id if current tag was created for a release. Handy for uploading release assets . CIRRUS_REPO_CLONE_TOKEN Temporary GitHub access token to perform a clone. CIRRUS_REPO_NAME Repository name. For example my-project CIRRUS_REPO_OWNER Repository owner (an organization or a user). For example my-organization CIRRUS_REPO_FULL_NAME Repository full name/slug. For example my-organization/my-project CIRRUS_REPO_CLONE_URL URL used for cloning. For example https://github.com/my-organization/my-project.git CIRRUS_USER_COLLABORATOR true if a user initialized a build is already a contributor to the repository. false otherwise. CIRRUS_USER_PERMISSION admin , write , read or none . CIRRUS_HTTP_CACHE_HOST Host and port number on which local HTTP cache can be accessed on. GITHUB_CHECK_SUITE_ID Monotonically increasing id of a corresponding GitHub Check Suite which caused the Cirrus CI build. CIRRUS_ENV Path to a file, by writing to which you can set task-wide environment variables .","title":"Environment Variables"},{"location":"guide/writing-tasks/#behavioral-environment-variables","text":"And some environment variables can be set to control behavior of the Cirrus CI Agent: Name Default Value Description CIRRUS_CLONE_DEPTH 0 which will reflect in a full clone of a single branch Clone depth. CIRRUS_CLONE_SUBMODULES false Set to true to clone submodules recursively. CIRRUS_LOG_TIMESTAMP false Indicate Cirrus Agent to prepend timestamp to each line of logs. CIRRUS_SHELL sh on Linux/macOS/FreeBSD and cmd.exe on Windows. Set to direct to execute each script directly without wrapping the commands in a shell script. Shell that Cirrus CI uses to execute scripts. By default sh is used. CIRRUS_VOLUME /tmp Defines a path for a temporary volume to be mounted into instances running in a Kubernetes cluster. This volume is mounted into all additional containers and is persisted between steps of a pipe . CIRRUS_WORKING_DIR cirrus-ci-build folder inside of a system's temporary folder Working directory where Cirrus CI executes builds. Default to cirrus-ci-build folder inside of a system's temporary folder.","title":"Behavioral Environment Variables"},{"location":"guide/writing-tasks/#encrypted-variables","text":"It is possible to add encrypted variables to a .cirrus.yml file. These variables are decrypted only in builds for commits and pull requests that are made by users with write permission or approved by them. In order to encrypt a variable go to repository's settings page via clicking settings icon on a repository's main page (for example https://cirrus-ci.com/github/my-organization/my-repository ) and follow instructions. Warning Only users with WRITE permissions can add encrypted variables to a repository. An encrypted variable will be presented in a form like ENCRYPTED[qwerty239abc] which can be safely committed to .cirrus.yml file: publish_task : environment : AUTH_TOKEN : ENCRYPTED[qwerty239abc] script : ./publish.sh Cirrus CI encrypts variables with a unique per repository 256-bit encryption key so forks and even repositories within the same organization cannot re-use them. qwerty239abc from the example above is NOT the content of your encrypted variable, it's just an internal ID. No one can brute force your secrets from such ID. In addition, Cirrus CI doesn't know a relation between an encrypted variable and a repository for which the encrypted variable was created. Organization Level Encrypted Variables Sometimes there might be secrets that are used in almost all repositories of an organization. For example, credentials to a compute service where tasks will be executed. In order to create such sharable encrypted variable go to organization's settings page via clicking settings icon on an organization's main page (for example https://cirrus-ci.com/github/my-organization ) and follow instructions in Organization Level Encrypted Variables section. Encrypted Variable for Cloud Credentials In case you use integration with one of supported computing services , an encrypted variable used to store credentials that Cirrus is using to communicate with the computing service won't be decrypted if used in environment variables . These credentials have too many permissions for most of the cases, please create separate credentials with the minimum needed permissions for your specific case. gcp_credentials : SECURED[!qwerty] env : CREDENTIALS : SECURED[!qwerty] # won't be decrypted in any case Skipping Task in Forked Repository In forked repository the decryption of variable fails, which causes failure of task depending on it. To avoid this by default, make the sensitive task conditional: task : name : Task requiring decrypted variables only_if : $CIRRUS_REPO_OWNER == 'my-organization' ... Owner of forked repository can re-enable the task, if they have the required sensitive data, by encrypting the variable by themselves and editing both the encrypted variable and repo-owner condition in the .cirrus.yml file.","title":"Encrypted Variables"},{"location":"guide/writing-tasks/#cron-builds","text":"It is possible to configure invocations of re-occurring builds via the well-known Cron expressions. Cron builds can be configured on a repository's settings page (not in .cirrus.yml ). It's possible to configure several cron builds with unique names which will be available via CIRRUS_CRON environment variable . Each cron build should specify branch to trigger new builds for and a cron expression compatible with Quartz. You can use this generator to generate/validate your expressions. Note: Cron Builds are timed with the UTC timezone.","title":"Cron Builds"},{"location":"guide/writing-tasks/#matrix-modification","text":"Sometimes it's useful to run the same task against different software versions. Or run different batches of tests based on an environment variable. For cases like these, the matrix modifier comes very handy. It's possible to use matrix keyword only inside of a particular task to have multiple tasks based on the original one. Each new task will be created from the original task by replacing the whole matrix YAML node with each matrix 's children separately. Let check an example of a .cirrus.yml : amd64 test_task : container : matrix : - image : node:latest - image : node:lts test_script : yarn run test arm64 test_task : arm_container : matrix : - image : node:latest - image : node:lts test_script : yarn run test Which will be expanded into: amd64 test_task : container : image : node:latest test_script : yarn run test test_task : container : image : node:lts test_script : yarn run test arm64 test_task : arm_container : image : node:latest test_script : yarn run test test_task : arm_container : image : node:lts test_script : yarn run test Tip The matrix modifier can be used multiple times within a task. The matrix modification makes it easy to create some pretty complex testing scenarios like this: amd64 task : container : matrix : - image : node:latest - image : node:lts node_modules_cache : folder : node_modules fingerprint_script : - node --version - cat yarn.lock populate_script : yarn install matrix : - name : Build build_script : yarn build - name : Test test_script : yarn run test arm64 task : arm_container : matrix : - image : node:latest - image : node:lts node_modules_cache : folder : node_modules fingerprint_script : - node --version - cat yarn.lock populate_script : yarn install matrix : - name : Build build_script : yarn build - name : Test test_script : yarn run test","title":"Matrix Modification"},{"location":"guide/writing-tasks/#task-execution-dependencies","text":"Sometimes it might be very handy to execute some tasks only after successful execution of other tasks. For such cases it is possible to specify task names that a particular task depends. Use depends_on keyword to define dependencies: amd64 container : image : node:latest lint_task : script : yarn run lint test_task : script : yarn run test publish_task : depends_on : - test - lint script : yarn run publish arm64 arm_container : image : node:latest lint_task : script : yarn run lint test_task : script : yarn run test publish_task : depends_on : - test - lint script : yarn run publish Task Names and Aliases It is possible to specify the task's name via the name field. lint_task syntax is a syntactic sugar that will be expanded into: task : name : lint ... Names can be also pretty complex: task : name : Test Shard $TESTS_SPLIT env : matrix : TESTS_SPLIT : 1/3 TESTS_SPLIT : 2/2 TESTS_SPLIT : 3/3 tests_script : ./.ci/tests.sh deploy_task : only_if : $CIRRUS_BRANCH == 'master' depends_on : - Test Shard 1/3 - Test Shard 2/3 - Test Shard 3/3 script : ./.ci/deploy.sh ... Complex task names make it difficult to list and maintain all of such task names in your depends_on field. In order to make it simpler you can use the alias field to have a short simplified name for several tasks to use in depends_on . Here is a modified version of an example above that leverages the alias field: task : name : Test Shard $TESTS_SPLIT alias : Tests env : matrix : TESTS_SPLIT : 1/3 TESTS_SPLIT : 2/2 TESTS_SPLIT : 3/3 tests_script : ./.ci/tests.sh deploy_task : only_if : $CIRRUS_BRANCH == 'master' depends_on : Tests script : ./.ci/deploy.sh","title":"Task Execution Dependencies"},{"location":"guide/writing-tasks/#conditional-task-execution","text":"Some tasks are meant to be created only if a certain condition is met. And some tasks can be skipped in some cases. Cirrus CI supports the only_if and skip keywords in order to provide such flexibility: The only_if keyword controls whether or not a task will be created. For example, you may want to publish only changes committed to the master branch. publish_task : only_if : $CIRRUS_BRANCH == 'master' script : yarn run publish The skip keyword allows to skip execution of a task and mark it as successful. For example, you may want to skip linting if no source files have changed since the last successful run. lint_task : skip : \"!changesInclude('.cirrus.yml', '**.{js,ts}')\" script : yarn run lint Skip CI Completely Just include [skip ci] or [skip cirrus] in the first line of your commit message in order to skip CI execution for a commit completely. If you push multiple commits at the same time, only the first line of the last commit message will be checked for [skip ci] or [ci skip] . If you open a PR, PR title will be checked for [skip ci] or [ci skip] instead of the last commit message on the PR branch.","title":"Conditional Task Execution"},{"location":"guide/writing-tasks/#supported-operators","text":"Currently only basic operators like == , != , =~ , !=~ , && , || and unary ! are supported in only_if and skip expressions. Environment variables can also be used as usually. Pattern Matching Example Use =~ operator for pattern matching. check_aggreement_task : only_if : $CIRRUS_BRANCH =~ 'pull/.*' Note that =~ operator can match against multiline values (dotall mode) and therefore looking for the exact occurrence of the regular expression so don't forget to use .* around your term for matching it at any position (for example, $CIRRUS_CHANGE_TITLE =~ '.*[docs].*' ).","title":"Supported Operators"},{"location":"guide/writing-tasks/#supported-functions","text":"Currently two functions are supported in the only_if and skip expressions: changesInclude function allows to check which files were changed changesIncludeOnly is a more strict version of changesInclude , i.e. it won't evaluate to true if there are changed files other than the ones covered by patterns These two functions behave differently for PR builds and regular builds: For PR builds, functions check the list of files affected by the PR. For regular builds, the CIRRUS_LAST_GREEN_CHANGE environment variable will be used to determine list of affected files between CIRRUS_LAST_GREEN_CHANGE and CIRRUS_CHANGE_IN_REPO . changesInclude function can be very useful for skipping some tasks when no changes to sources have been made since the last successful Cirrus CI build. lint_task : skip : \"!changesInclude('.cirrus.yml', '**.{js,ts}')\" script : yarn run lint changesIncludeOnly function can be used to skip running a heavyweight task if only documentation was changed, for example: build_task : skip : \"changesIncludeOnly('doc/*')\"","title":"Supported Functions"},{"location":"guide/writing-tasks/#auto-cancellation-of-tasks","text":"Cirrus CI can automatically cancel tasks in case of new pushes to the same branch. By default, Cirrus CI auto-cancels all tasks for non default branch (for most repositories master branch) but this behavior can be changed by specifying auto_cancellation field: task : auto_cancellation : $CIRRUS_BRANCH != 'master' && $CIRRUS_BRANCH !=~ 'release/.*' ...","title":"Auto-Cancellation of Tasks"},{"location":"guide/writing-tasks/#stateful-tasks","text":"It's possible to tell Cirrus CI that a certain task is stateful and Cirrus CI will use a slightly different scheduling algorithm to minimize chances of such tasks being interrupted. Stateful tasks are intended to use low CPU count. Scheduling times of such stateful tasks might be a bit longer then usual especially for tasks with high CPU requirements. By default, Cirrus CI marks a task as stateful if its name contains one of the following terms: deploy , push , publish , upload or release . Otherwise, you can explicitly mark a task as stateful via stateful field: task : name : Propagate to Production stateful : true ...","title":"Stateful Tasks"},{"location":"guide/writing-tasks/#failure-toleration","text":"Sometimes tasks can play a role of sanity checks. For example, a task can check that your library is working with the latest nightly version of some dependency package. It will be great to be notified about such failures but it's not necessary to fail the whole build when a failure occurs. Cirrus CI has the allow_failures keyword which will make a task to not affect the overall status of a build. test_nightly_task : allow_failures : $SOME_PACKAGE_DEPENDENCY_VERSION == 'nightly' Skipping Notifications You can also skip posting red statuses to GitHub via skip_notifications field. skip_notifications : $SOME_PACKAGE_DEPENDENCY_VERSION == 'nightly' It can help to track potential issues overtime without distracting the main workflow.","title":"Failure Toleration"},{"location":"guide/writing-tasks/#manual-tasks","text":"By default a Cirrus CI task is automatically triggered when all its dependency tasks finished successfully. Sometimes though, it can be very handy to trigger some tasks manually, for example, perform a deployment to staging for manual testing upon all automation checks have succeeded. In order change the default behavior please use trigger_type field like this: task : name : \"Staging Deploy\" trigger_type : manual depends_on : - Tests (Unit) - Tests (Ingegration) - Lint You'll be able to manually trigger such paused tasks via Cirrus CI Web UI or directly from GitHub Checks page.","title":"Manual tasks"},{"location":"guide/writing-tasks/#task-execution-lock","text":"Some CI tasks perform external operations which are required to be executed one at a time. For example, parallel deploys to the same environment is usually a bad idea. In order to restrict parallel execution of a certain task within a repository, you can use execution_lock to specify a task's lock key, a unique string that will be used to make sure that any tasks with the same execution_lock string are executed one at a time. Here is an example of how to make sure deployments on a specific branch can not run in parallel: task : name : \"Automatic Staging Deploy\" execution_lock : $CIRRUS_BRANCH You'll be able to manually trigger such paused tasks via the Cirrus CI Web Dashboard or directly from the commit's checks page on GitHub.","title":"Task Execution Lock"},{"location":"guide/writing-tasks/#required-pr-labels","text":"Similar to manual tasks Cirrus CI can pause execution of tasks until a corresponding PR gets labeled. This can be particular useful when you'd like to do an initial review before running all unit and integration tests on every supported platform . Use the required_pr_labels field to specify a list of labels a PR requires to have in order to trigger a task. Here is a simple example of .cirrus.yml config that automatically runs a linting tool but requires initial-review label being presented in order to run tests: lint_task : # ... test_task : required_pr_labels : initial-review # ... Note: required_pr_labels has no effect on tasks created for non-PR builds. You can also require multiple labels to continue executing the task for even more flexibility: deploy_task : required_pr_labels : - initial-review - ready-for-staging depends_on : build # ... In the example above both initial-review and ready-for-staging labels should be presented on a PR in order to perform a deployment via deploy task.","title":"Required PR Labels"},{"location":"guide/writing-tasks/#http-cache","text":"For the most cases regular caching mechanism where Cirrus CI caches a folder is more than enough. But modern build systems like Gradle , Bazel and Pants can take advantage of remote caching. Remote caching is when a build system uploads and downloads intermediate results of a build execution while the build itself is still executing. Cirrus CI agent starts a local caching server and exposes it via CIRRUS_HTTP_CACHE_HOST environments variable. Caching server supports GET , POST and HEAD requests to upload, download and check presence of artifacts. Info If port 12321 is available CIRRUS_HTTP_CACHE_HOST will be equal to localhost:12321 . For example running the following command: curl -s -X POST --data-binary @myfolder.tar.gz http:// $CIRRUS_HTTP_CACHE_HOST /name-key ...has the same effect as the following caching instruction : name_cache : folder : myfolder fingerprint_key : key Info To see how HTTP Cache can be used with Gradle's Build Cache please check this example .","title":"HTTP Cache"},{"location":"guide/writing-tasks/#additional-containers","text":"Sometimes one container is not enough to run a CI build. For example, your application might use a MySQL database as a storage. In this case you most likely want a MySQL instance running for your tests. One option here is to pre-install MySQL and use a background_script to start it. This approach has some inconveniences like the need to pre-install MySQL by building a custom Docker container. For such use cases Cirrus CI allows to run additional containers in parallel with the main container that executes a task. Each additional container is defined under additional_containers keyword in .cirrus.yml . Each additional container should have a unique name and specify at least Docker image and port that this container exposes. In the example below we use an official MySQL Docker image that exposes the standard MySQL port (3306). Tests will be able to access MySQL instance via localhost:3306 . amd64 container : image : golang:latest additional_containers : - name : mysql image : mysql:latest port : 3306 cpu : 1.0 memory : 512Mi env : MYSQL_ROOT_PASSWORD : \"\" arm64 arm_container : image : golang:latest additional_containers : - name : mysql image : mysql:latest port : 3306 cpu : 1.0 memory : 512Mi env : MYSQL_ROOT_PASSWORD : \"\" Additional container can be very handy in many scenarios. Please check Cirrus CI catalog of examples for more details. Default Resources By default, each additional container will get 0.5 CPU and 512Mi of memory. These values can be configured as usual via cpu and memory fields. Port Mapping It's also possible to map ports of additional containers by using <HOST_PORT>:<CONTAINER_PORT> format for the port field. For example, port: 80:8080 will map port 8080 of the container to be available on local port 80 within a task. Note: don't use port mapping unless absolutely necessary. A perfect use case is when you have several additional containers which start the service on the same port and there's no easy way to change that. Port mapping limits the number of places the container can be scheduled and will affect how fast such tasks are scheduled. To specify multiple mappings use the ports field, instead of the port : ports : - 8080 - 3306 Overriding Default Command It's also possible to override the default CMD of an additional container via command field: amd64 container : image : golang:latest additional_containers : - name : mysql image : mysql:latest port : 7777 command : mysqld --port 7777 env : MYSQL_ROOT_PASSWORD : \"\" arm64 arm_container : image : golang:latest additional_containers : - name : mysql image : mysql:latest port : 7777 command : mysqld --port 7777 env : MYSQL_ROOT_PASSWORD : \"\" Warning Note that additional_containers can be used only with Community Cluster or Google's Kubernetes Engine .","title":"Additional Containers"},{"location":"guide/writing-tasks/#embedded-badges","text":"Cirrus CI provides a way to embed a badge that can represent status of your builds into a ReadMe file or a website. For example, this is a badge for cirruslabs/cirrus-ci-web repository that contains Cirrus CI's front end: In order to embed such a check into a \"read-me\" file or your website, just use a URL to a badge that looks like this: https://api.cirrus-ci.com/github/<USER OR ORGANIZATION>/<REPOSITORY>.svg If you want a badge for a particular branch, use the ?branch=<BRANCH NAME> query parameter (at the end of the URL) like this: https://api.cirrus-ci.com/github/<USER OR ORGANIZATION>/<REPOSITORY>.svg?branch=<BRANCH NAME> By default, Cirrus picks the latest build in a final state for the repository or a particular branch if branch parameter is specified. It's also possible to explicitly set a concrete build to use with ?buildId=<BUILD ID> query parameter. If you want a badge for a particular task within the latest finished build, use the ?task=<TASK NAME> query parameter (at the end of the URL) like this: https://api.cirrus-ci.com/github/<USER OR ORGANIZATION>/<REPOSITORY>.svg?task=tests You can even pick a specific script instruction within the task with an additional script=<SCRIPT NAME> parameter: https://api.cirrus-ci.com/github/<USER OR ORGANIZATION>/<REPOSITORY>.svg?task=build&script=lint","title":"Embedded Badges"},{"location":"guide/writing-tasks/#badges-in-markdown","text":"Here is how Cirrus CI's badge can be embeded in a Markdown file: [ ![Build Status ]( https://api.cirrus-ci.com/github/<USER OR ORGANIZATION>/<REPOSITORY>.svg )](https://cirrus-ci.com/github/<USER OR ORGANIZATION>/<REPOSITORY>)","title":"Badges in Markdown"},{"location":"guide/writing-tasks/#cctray-xml","text":"Cirrus CI supports exporting information about the latest repository builds via the CCTray XML format . Use the following URL format with a tool of your choice (such as CCMenu ): https://api.cirrus-ci.com/github/<USER OR ORGANIZATION>/<REPOSITORY>/cctray.xml Note: for private repositories you'll need to configure access token .","title":"CCTray XML"},{"location":"legal/privacy/","text":"Privacy Policy \u00b6 In addition to this Privacy Policy, Cirrus Labs also has a Terms of Service . The Gist \u00b6 Cirrus Labs Inc will collect certain non-personally identify information about you as you use our sites. We may use this data to better understand our users. We can also publish this data, but the data will be about a large group of users, not individuals. We will also ask you to provide personal information, but you'll always be able to opt out. If you give us personal information, we won't do anything evil with it. We can also use cookies, but you can choose not to store these. That's the basic idea, but you must read through the entire Privacy Policy below and agree with all the details before you use any of our sites. Reuse \u00b6 This document is based upon the Automattic Privacy Policy and is licensed under Creative Commons Attribution Share-Alike License 2.5 . Basically, this means you can use it verbatim or edited, but you must release new versions under the same license and you have to credit Automattic somewhere (like this!). Automattic is not connected with and does not sponsor or endorse Cirrus Labs Inc or its use of the work. Cirrus Labs Inc (\"Cirrus Labs\") makes available services include our web sites ( https://cirrus-ci.org/ ), our blog, our API, and any other software, sites, and services offered by Cirrus Labs Inc in connection to any of those (taken together, the \"Service\"). It is Cirrus Labs Inc's policy to respect your privacy regarding any information we may collect while operating our websites. Questions \u00b6 If you have question about this Privacy Policy, please contact us at hello@cirruslabs.org Visitors \u00b6 Like most website operators, Cirrus Labs Inc collects non-personally-identifying information of the sort that web browsers and servers typically make available, such as the browser type, language preference, referring site, and the date and time of each visitor request. Cirrus Labs Inc's purpose in collecting non-personally identifying information is to better understand how Cirrus Labs Inc's visitors use its website. From time to time, Cirrus Labs Inc may release non-personally-identifying information in the aggregate, e.g., by publishing a report on trends in the usage of its website. Cirrus Labs Inc also collects potentially personally-identifying information like Internet Protocol (IP) addresses. Cirrus Labs Inc does not use such information to identify its visitors, however, and does not disclose such information, other than under the same circumstances that it uses and discloses personally-identifying information, as described below. We may also collect and use IP addresses to block users who violated our Terms of Service. Gathering of Personally-Identifying Information \u00b6 Certain visitors to Cirrus Labs Inc's websites choose to interact with Cirrus Labs Inc in ways that require Cirrus Labs Inc to gather personally-identifying information. The amount and type of information that Cirrus Labs Inc gathers depends on the nature of the interaction. Cirrus Labs Inc collects such information only insofar as is necessary or appropriate to fulfill the purpose of the visitor's interaction with Cirrus Labs Inc. Cirrus Labs Inc does not disclose personally-identifying information other than as described below. And visitors can always refuse to supply personally-identifying information, with the caveat that it may prevent them from engaging in certain Service-related activities. Additionally, some interactions, such as posting a comment, may ask for optional personal information. For instance, when posting a comment, may provide a website that will be displayed along with a user's name when the comment is displayed. Supplying such personal information is completely optional and is only displayed for the benefit and the convenience of the user. Aggregated Statistics \u00b6 Cirrus Labs Inc may collect statistics about the behavior of visitors to the Service. For instance, Cirrus Labs Inc may monitor the most popular parts of the https://cirrus-ci.org/ . Cirrus Labs Inc may display this information publicly or provide it to others. However, Cirrus Labs Inc does not disclose personally-identifying information other than as described below. Protection of Certain Personally-Identifying Information \u00b6 Cirrus Labs Inc discloses potentially personally-identifying and personally-identifying information only to those of its employees, contractors and affiliated organizations that (i) need to know that information in order to process it on Cirrus Labs Inc's behalf or to provide services available at Cirrus Labs Inc's websites, and (ii) that have agreed not to disclose it to others. Some of those employees, contractors and affiliated organizations may be located outside of your home country; by using the Service, you consent to the transfer of such information to them. Cirrus Labs Inc will not rent or sell potentially personally-identifying and personally-identifying information to anyone. Other than to its employees, contractors and affiliated organizations, as described above, Cirrus Labs Inc discloses potentially personally-identifying and personally-identifying information only when required to do so by law, or when Cirrus Labs Inc believes in good faith that disclosure is reasonably necessary to protect the property or rights of Cirrus Labs Inc, third parties or the public at large. If you are a registered user of the Service and have supplied your email address, Cirrus Labs Inc may occasionally send you an email to tell you about new features, solicit your feedback, or just keep you up to date with what's going on with Cirrus Labs Inc and our products. We primarily use our website and blog to communicate this type of information, so we expect to keep this type of email to a minimum. If you send us a request (for example via a support email or via one of our feedback mechanisms), we reserve the right to publish it in order to help us clarify or respond to your request or to help us support other users. Cirrus Labs Inc takes all measures reasonably necessary to protect against the unauthorized access, use, alteration or destruction of potentially personally-identifying and personally-identifying information. Browser Cookies \u00b6 A cookie is a string of information that a website stores on a visitor's computer, and that the visitor's browser provides to the Service each time the visitor returns. Cirrus Labs Inc uses cookies to help Cirrus Labs Inc identify and track visitors, their usage of Cirrus Labs Inc Service, and their Service access preferences. Cirrus Labs Inc visitors who do not wish to have cookies placed on their computers should set their browsers to refuse cookies before using Cirrus Labs Inc's websites, with the drawback that certain features of Cirrus Labs Inc's websites may not function properly without the aid of cookies. Data Storage \u00b6 Cirrus Labs Inc uses third party vendors and hosting partners to provide the necessary hardware, software, networking, storage, and related technology required to run the Service. You understand that although you retain full rights to your data, it may be stored on third party storage and transmitted through third party networks. Privacy Policy Changes \u00b6 Although most changes are likely to be minor, Cirrus Labs Inc may change its Privacy Policy from time to time, and in Cirrus Labs Inc's sole discretion. Cirrus Labs Inc encourages visitors to frequently check this page for any changes to its Privacy Policy. Your continued use of this site after any change in this Privacy Policy will constitute your acceptance of such change. This page was last updated on 05/23/2019.","title":"Privacy"},{"location":"legal/privacy/#privacy-policy","text":"In addition to this Privacy Policy, Cirrus Labs also has a Terms of Service .","title":"Privacy Policy"},{"location":"legal/privacy/#the-gist","text":"Cirrus Labs Inc will collect certain non-personally identify information about you as you use our sites. We may use this data to better understand our users. We can also publish this data, but the data will be about a large group of users, not individuals. We will also ask you to provide personal information, but you'll always be able to opt out. If you give us personal information, we won't do anything evil with it. We can also use cookies, but you can choose not to store these. That's the basic idea, but you must read through the entire Privacy Policy below and agree with all the details before you use any of our sites.","title":"The Gist"},{"location":"legal/privacy/#reuse","text":"This document is based upon the Automattic Privacy Policy and is licensed under Creative Commons Attribution Share-Alike License 2.5 . Basically, this means you can use it verbatim or edited, but you must release new versions under the same license and you have to credit Automattic somewhere (like this!). Automattic is not connected with and does not sponsor or endorse Cirrus Labs Inc or its use of the work. Cirrus Labs Inc (\"Cirrus Labs\") makes available services include our web sites ( https://cirrus-ci.org/ ), our blog, our API, and any other software, sites, and services offered by Cirrus Labs Inc in connection to any of those (taken together, the \"Service\"). It is Cirrus Labs Inc's policy to respect your privacy regarding any information we may collect while operating our websites.","title":"Reuse"},{"location":"legal/privacy/#questions","text":"If you have question about this Privacy Policy, please contact us at hello@cirruslabs.org","title":"Questions"},{"location":"legal/privacy/#visitors","text":"Like most website operators, Cirrus Labs Inc collects non-personally-identifying information of the sort that web browsers and servers typically make available, such as the browser type, language preference, referring site, and the date and time of each visitor request. Cirrus Labs Inc's purpose in collecting non-personally identifying information is to better understand how Cirrus Labs Inc's visitors use its website. From time to time, Cirrus Labs Inc may release non-personally-identifying information in the aggregate, e.g., by publishing a report on trends in the usage of its website. Cirrus Labs Inc also collects potentially personally-identifying information like Internet Protocol (IP) addresses. Cirrus Labs Inc does not use such information to identify its visitors, however, and does not disclose such information, other than under the same circumstances that it uses and discloses personally-identifying information, as described below. We may also collect and use IP addresses to block users who violated our Terms of Service.","title":"Visitors"},{"location":"legal/privacy/#gathering-of-personally-identifying-information","text":"Certain visitors to Cirrus Labs Inc's websites choose to interact with Cirrus Labs Inc in ways that require Cirrus Labs Inc to gather personally-identifying information. The amount and type of information that Cirrus Labs Inc gathers depends on the nature of the interaction. Cirrus Labs Inc collects such information only insofar as is necessary or appropriate to fulfill the purpose of the visitor's interaction with Cirrus Labs Inc. Cirrus Labs Inc does not disclose personally-identifying information other than as described below. And visitors can always refuse to supply personally-identifying information, with the caveat that it may prevent them from engaging in certain Service-related activities. Additionally, some interactions, such as posting a comment, may ask for optional personal information. For instance, when posting a comment, may provide a website that will be displayed along with a user's name when the comment is displayed. Supplying such personal information is completely optional and is only displayed for the benefit and the convenience of the user.","title":"Gathering of Personally-Identifying Information"},{"location":"legal/privacy/#aggregated-statistics","text":"Cirrus Labs Inc may collect statistics about the behavior of visitors to the Service. For instance, Cirrus Labs Inc may monitor the most popular parts of the https://cirrus-ci.org/ . Cirrus Labs Inc may display this information publicly or provide it to others. However, Cirrus Labs Inc does not disclose personally-identifying information other than as described below.","title":"Aggregated Statistics"},{"location":"legal/privacy/#protection-of-certain-personally-identifying-information","text":"Cirrus Labs Inc discloses potentially personally-identifying and personally-identifying information only to those of its employees, contractors and affiliated organizations that (i) need to know that information in order to process it on Cirrus Labs Inc's behalf or to provide services available at Cirrus Labs Inc's websites, and (ii) that have agreed not to disclose it to others. Some of those employees, contractors and affiliated organizations may be located outside of your home country; by using the Service, you consent to the transfer of such information to them. Cirrus Labs Inc will not rent or sell potentially personally-identifying and personally-identifying information to anyone. Other than to its employees, contractors and affiliated organizations, as described above, Cirrus Labs Inc discloses potentially personally-identifying and personally-identifying information only when required to do so by law, or when Cirrus Labs Inc believes in good faith that disclosure is reasonably necessary to protect the property or rights of Cirrus Labs Inc, third parties or the public at large. If you are a registered user of the Service and have supplied your email address, Cirrus Labs Inc may occasionally send you an email to tell you about new features, solicit your feedback, or just keep you up to date with what's going on with Cirrus Labs Inc and our products. We primarily use our website and blog to communicate this type of information, so we expect to keep this type of email to a minimum. If you send us a request (for example via a support email or via one of our feedback mechanisms), we reserve the right to publish it in order to help us clarify or respond to your request or to help us support other users. Cirrus Labs Inc takes all measures reasonably necessary to protect against the unauthorized access, use, alteration or destruction of potentially personally-identifying and personally-identifying information.","title":"Protection of Certain Personally-Identifying Information"},{"location":"legal/privacy/#browser-cookies","text":"A cookie is a string of information that a website stores on a visitor's computer, and that the visitor's browser provides to the Service each time the visitor returns. Cirrus Labs Inc uses cookies to help Cirrus Labs Inc identify and track visitors, their usage of Cirrus Labs Inc Service, and their Service access preferences. Cirrus Labs Inc visitors who do not wish to have cookies placed on their computers should set their browsers to refuse cookies before using Cirrus Labs Inc's websites, with the drawback that certain features of Cirrus Labs Inc's websites may not function properly without the aid of cookies.","title":"Browser Cookies"},{"location":"legal/privacy/#data-storage","text":"Cirrus Labs Inc uses third party vendors and hosting partners to provide the necessary hardware, software, networking, storage, and related technology required to run the Service. You understand that although you retain full rights to your data, it may be stored on third party storage and transmitted through third party networks.","title":"Data Storage"},{"location":"legal/privacy/#privacy-policy-changes","text":"Although most changes are likely to be minor, Cirrus Labs Inc may change its Privacy Policy from time to time, and in Cirrus Labs Inc's sole discretion. Cirrus Labs Inc encourages visitors to frequently check this page for any changes to its Privacy Policy. Your continued use of this site after any change in this Privacy Policy will constitute your acceptance of such change. This page was last updated on 05/23/2019.","title":"Privacy Policy Changes"},{"location":"legal/terms/","text":"Terms of Service \u00b6 In addition to these Terms of Service, Cirrus Labs also has a Privacy Policy . The Gist \u00b6 Cirrus Labs Inc (\"Cirrus Labs\") operates the Cirrus CI service, which we hope you use. If you use it, please use it responsibly. If you don't, we'll have to terminate your subscription. For paid plans, you'll be charged on a monthly basis. You can cancel anytime, but there are no refunds. You own the source code that you provide to Cirrus CI and you're responsible for keeping it safe. The Terms of Service, the Cirrus CI Service, and our prices can change at any time. We'll warn you 30 days in advance of any price changes. We'll try to warn you about major changes to the Terms of Service or Cirrus CI, but we make no guarantees. That's the basic idea, but you must read through the entire Terms of Service below and agree with all the details before you use any of our websites or services (whether or not you have signed up). Reuse \u00b6 This document is an adaptation of the Code Climate Terms of Service , which is an adaptation of the Heroku Terms of Service , which is turn an adaptation of the Google App Engine Terms of Service . The original work has been modified with permission under the Creative Commons Attribution 3.0 License . Neither Code Climate, Inc, nor Heroku, Inc. nor Google, Inc. is connected with and they do not sponsor or endorse Cirrus CI or its use of the work. You're welcome to adapt and use this document for your own needs. If you make an improvement, we'd appreciate it if you would let us know so we can consider improving our own document. Your Agreement with Cirrus Labs Inc \u00b6 Your use of the Cirrus CI Service is governed by this agreement (the \"Terms\"). The \"Service\" means the services Cirrus CI makes available include our web sites ( https://cirrus-ci.org/ , https://cirrus-ci.com/ ), our blog, our API, and any other software, sites, and services offered by Cirrus Labs in connection to any of those. \"Customer Source Code\" means any source code you directly or indirectly submit to Cirrus CI for the purpose of using the Service. \"Content\" means all content generated by Cirrus CI on your behalf (including metric data) and does not include Customer Source Code. In order to use the Service, You (the \"Customer\", \"You\", or \"Your\") must first agree to the Terms. You understand and agree that Cirrus Labs will treat Your use of the Service as acceptance of the Terms from that point onwards. Cirrus Labs may make changes to the Terms from time to time. You may reject the changes by terminating Your subscription. You understand and agree that if You use the Service after the date on which the Terms have changed, Cirrus Labs will treat Your use as acceptance of the updated Terms. If you have any question about the Terms, please contact us . Your Cirrus CI User \u00b6 You may not use the Service if You are a person barred from receiving the Service under the laws of the United States or other countries, including the country in which You are resident or from which You use the Service. You may not use the service unless you are over the age of 13. You must be a human. Sign ups via automated methods are not permitted. Use of the Service \u00b6 You must provide accurate and complete registration information any time You register to use the Service. You are responsible for the security of Your passwords and for any use of Your user. Your use of the Service must comply with all applicable laws, regulations and ordinances. You agree to not engage in any activity that interferes with or disrupts the Service. Cirrus Labs reserves the right to enforce quotas and usage limits (to any resources, including the API) at its sole discretion, with or without notice, which may result in Cirrus Labs disabling or throttling your usage of the Service for any amount of time. Shared users are forbidden unless you pay for all Git commit authors from the last 30 days. Service Policies and Privacy \u00b6 The Service shall be subject to the privacy policy for the Service available at Privacy Policy , hereby expressly into the Terms of Service by reference. You agree to the use of Your data in accordance with Cirrus CI's privacy policies. Fees for Use of the Service \u00b6 The Service may be provided to You without charge up with certain limits or for a certain \"trial\" period of time. All payments for use of the Service will go through GitHub according to GitHub Marketplace Terms of Service and GitHub Marketplace Developer Agreement . Cirrus Labs may change its fees and payment policies for the Service by notifying You at least thirty (30) days before the beginning of the billing cycle in which such change will take effect. Cancellation and Termination \u00b6 You must cancel your subscription via GitHub Marketplace with respect to GitHub Marketplace Terms of Service . You agree that Cirrus Labs, in its sole discretion and for any or no reason, may terminate or suspend Your subscription. You agree that any termination of Your access to the Service may be without prior notice, and You agree that Cirrus CI will not be liable to You or any third party for such termination. Customer Source Code \u00b6 Cirrus Labs claims no ownership or control over any Customer Source Code. You retain copyright and any other rights You already hold in the Customer Source Code and You are responsible for protecting those rights, as appropriate. You agree to assume full responsibility for configuring the Service to allow appropriate access to any Customer Source Code provided to the Service. You understand that private projects will display Customer Source Code to You and any collaborators that you designate for that project. You retain sole responsibility for any collaborators or third-party services that you allow to view Customer Source Code and entrust them at your own risk. Cirrus Labs is not responsible if you fail to configure, or misconfigure, your project and inadvertently allow unauthorized parties to view any Customer Source Code. Ideas and Feedback \u00b6 You may choose to or we may invite You to submit comments or ideas about the Service, including but not limited to ideas about improving the Service or our products (\"Ideas\"). By submitting any Idea, You agree that Your disclosure is unsolicited and without restriction and will not place Cirrus Labs under any fiduciary or other obligation, and that we are free to use the Idea without any additional compensation to You, and/or to disclose the Idea on a non-confidential basis or otherwise to anyone. Modification of the Service \u00b6 You acknowledge and agree that the Service may change from time to time without prior notice to You. Changes include, without limitation, changes to fee and payment policies, security patches, added or removed functionality, and other enhancements or restrictions. Cirrus Labs shall not be liable to you or to any third party for any modification, price change, suspension or discontinuance of the Service. External Resources \u00b6 The Service may include hyperlinks to other websites or content or resources or email content. You acknowledge and agree that Cirrus Labs is not responsible for the availability of any such external sites or resources, and does not endorse any advertising, products or other materials on or available from such web sites or resources. License from Cirrus CI and Restrictions \u00b6 All of the content available on or through the Service, including without limitation, text, photographs, graphics, logos, trade/service marks, and/or audiovisual content, but expressly excluding Customer Source Code, is owned and/or controlled by Cirrus Labs, or other licensors or Service users and is protected, as applicable, by copyright, trademark, trade dress, patent, and trade secret laws, other proprietary rights, and international treaties. You acknowledge that the Service and any underlying technology or software used in connection with the Service contain our proprietary information. Subject to and conditioned upon your compliance with these Terms of Service, we grant to you a personal, worldwide, royalty-free, non-assignable and non-exclusive license to use the software provided to You by Cirrus Labs as part of the Service as provided to You by Cirrus Labs. This license is for the sole purpose of enabling You to use and enjoy the benefit of the Service as provided by Cirrus Labs, in the manner permitted by the Terms. You may not (and You may not permit anyone else to): (a) copy, modify, create a derivative work of, reverse engineer, decompile or otherwise attempt to extract the source code of the Service or any part thereof, unless this is expressly permitted or required by law, or unless You have been specifically told that You may do so by Cirrus Labs, in writing (e.g., through an open source software license); or (b) attempt to disable or circumvent any security mechanisms used by the Service. Open source software licenses for components of the Service released under an open source license constitute separate written agreements. To the limited extent that the open source software licenses expressly supersede these Terms of Service, the open source licenses govern Your agreement with Cirrus Labs for the use of the components of the Service released under an open source license. You may not use the Service in any manner that could damage, disable, overburden or impair our servers or networks, or interfere with any other users' use or enjoyment of the Service. You may not attempt to gain unauthorized access to any of the Service, member accounts, or computer systems or networks, through hacking, password mining or any other means. Without limiting anything else contained herein, you agree that you shall not (and you agree not to allow any third party to): remove any notices of copyright, trademark or other proprietary rights contained in/on or accessible through the Service or in any content or other material obtained via the Service; use any robot, spider, website search/retrieval application, or other automated device, process or means to access, retrieve or index any portion of the Service; reformat or frame any portion of the web pages that are part of the Service; use the Service for commercial purposes not permitted under these Terms; create users by automated means or under false or fraudulent pretenses; attempt to defeat any security or verification measure relating to the Service; provide or use tracking or monitoring functionality in connection with the Service, including, without limitation, to identify other users\u2019 actions or activities; impersonate or attempt to impersonate Cirrus Labs or any employee, contractor or associate of Cirrus Labs, or any other person or entity; or collect or store personal data about other users in connection with the prohibited activities described in this paragraph. Our Copyright Dispute Policy \u00b6 Cirrus Labs respects the intellectual property of others and requires that our users do the same. It is our policy to terminate the membership of repeat infringers. If you believe that material or content residing on or accessible through the Service infringes a copyright, please send a notice of copyright infringement containing the following information to the Designated Copyright Agent listed below: identification of the copyrighted work claimed to have been infringed, or, if multiple copyrighted works are covered by a single notification, a representative list of such works; identification of the claimed infringing material and information reasonably sufficient to permit us to locate the material on the Cirrus CI Service (providing the URL(s) of the claimed infringing material satisfies this requirement); information reasonably sufficient to permit us to contact you, such as an address, telephone number, and an email address; a statement by you that you have a good faith belief that the disputed use is not authorized by the copyright owner, its agent, or the law; a statement by you, made under penalty of perjury, that the above information in your notification is accurate and that you are the copyright owner or are authorized to act on the copyright owner's behalf; and your physical or electronic signature. Our Designated Copyright Agent for notification of claimed infringement can be reached by email at: hello@cirruslabs.org . The Service may contain advertisements and/or links to other websites (\u201cThird Party Sites\u201d). Cirrus Labs does not endorse, sanction or verify the accuracy or ownership of the information contained in/on any Third Party Site or any products or services advertised on Third Party Sites. If you decide to leave the Site and navigate to Third Party Sites, or install any software or download content from any such Third Party Sites, you do so at your own risk. Once you access a Third Party Site through a link on our Site, you may no longer be protected by these Terms of Service and you may be subject to the terms and conditions of such Third Party Site. You should review the applicable policies, including privacy and data gathering practices, of any Third Party Site to which you navigate from the Site, or relating to any software you use or install from a Third Party Site. Concerns regarding a Third Party Site should be directed to the Third Party Site itself. Cirrus CI bears no responsibility for any action associated with any Third Party Site. Disclaimer of Warranties \u00b6 IF YOU ACCESS THE SERVICE, YOU DO SO AT YOUR OWN RISK. WE PROVIDE THE SERVICE \u201cAS IS\u201d, \u201cWITH ALL FAULTS\u201d AND \u201cAS AVAILABLE.\u201d WE MAKE NO EXPRESS OR IMPLIED WARRANTIES OR GUARANTEES ABOUT THE SERVICE. TO THE MAXIMUM EXTENT PERMITTED BY LAW, WE HEREBY DISCLAIM ALL SUCH WARRANTIES, INCLUDING ALL STATUTORY WARRANTIES, WITH RESPECT TO THE SERVICE, INCLUDING WITHOUT LIMITATION ANY WARRANTIES THAT THE SERVICE IS MERCHANTABLE, OF SATISFACTORY QUALITY, ACCURATE, FIT FOR A PARTICULAR PURPOSE OR NEED, OR NON-INFRINGING. WE DO NOT GUARANTEE THAT THE RESULTS THAT MAY BE OBTAINED FROM THE USE OF THE SERVICE WILL BE EFFECTIVE, RELIABLE OR ACCURATE OR WILL MEET YOUR REQUIREMENTS. WE DO NOT GUARANTEE THAT YOU WILL BE ABLE TO ACCESS OR USE THE SERVICE (EITHER DIRECTLY OR THROUGH THIRD-PARTY NETWORKS) AT TIMES OR LOCATIONS OF YOUR CHOOSING. WE ARE NOT RESPONSIBLE FOR THE ACCURACY, RELIABILITY, TIMELINESS OR COMPLETENESS OF INFORMATION PROVIDED BY ANY OTHER USERS OF THE SERVICE OR ANY OTHER DATA OR INFORMATION PROVIDED OR RECEIVED THROUGH THE SERVICE. EXCEPT AS EXPRESSLY SET FORTH HEREIN, CIRRUS LABS MAKES NO WARRANTIES ABOUT THE INFORMATION SYSTEMS, SOFTWARE AND FUNCTIONS MADE ACCESSIBLE BY OR THROUGH THE SERVICE OR ANY SECURITY ASSOCIATED WITH THE TRANSMISSION OF SENSITIVE INFORMATION. CIRRUS LABS DOES NOT WARRANT THAT THE SERVICE WILL OPERATE ERROR-FREE, THAT ERRORS IN THE SERVICE WILL BE FIXED, THAT LOSS OF DATA WILL NOT OCCUR, OR THAT THE SERVICE OR SOFTWARE ARE FREE OF COMPUTER VIRUSES, CONTAMINANTS OR OTHER HARMFUL ITEMS. UNDER NO CIRCUMSTANCES WILL CIRRUS LABS, ANY OF OUR AFFILIATES, DISTRIBUTORS, PARTNERS, LICENSORS, AND/OR ANY OF OUR OR THEIR DIRECTORS, OFFICERS, EMPLOYEES, CONSULTANTS, AGENTS, OR OTHER REPRESENTATIVES BE LIABLE FOR ANY LOSS OR DAMAGE CAUSED BY YOUR RELIANCE ON INFORMATION OBTAINED THROUGH THE SERVICE. Limitations on Liability \u00b6 YOUR SOLE AND EXCLUSIVE REMEDY FOR ANY DISPUTE WITH US IS THE CANCELLATION OF YOUR REGISTRATION. IN NO EVENT SHALL OUR TOTAL CUMULATIVE LIABILITY TO YOU FOR ANY AND ALL CLAIMS RELATING TO OR ARISING OUT OF YOUR USE OF THE SERVICE, REGARDLESS OF THE FORM OF ACTION, EXCEED THE GREATER OF: (A) THE TOTAL AMOUNT OF FEES, IF ANY, THAT YOU PAID TO UTILIZE THE SERVICE OR (B) ONE HUNDRED DOLLARS ($100). IN NO EVENT SHALL WE BE LIABLE TO YOU (OR TO ANY THIRD PARTY CLAIMING UNDER OR THROUGH YOU) FOR ANY DIRECT, INDIRECT, SPECIAL, INCIDENTAL, CONSEQUENTIAL, PUNITIVE OR EXEMPLARY DAMAGES OR ANY BODILY INJURY, EMOTIONAL DISTRESS, DEATH OR ANY OTHER DAMAGES ARISING FROM YOUR USE OF OR INABILITY TO USE THE SERVICE, WHETHER ON-LINE OR OFF-LINE, OR OTHERWISE IN CONNECTION WITH THE SERVICE. THESE EXCLUSIONS APPLY TO ANY CLAIMS FOR LOST PROFITS, LOST DATA, LOSS OF GOODWILL OR BUSINESS REPUTATION, COST OF PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES, WORK STOPPAGE, COMPUTER FAILURE OR MALFUNCTION, ANY OTHER COMMERCIAL DAMAGES OR LOSSES, OR ANY PERSONAL INJURY OR PROPERTY DAMAGES, EVEN IF WE KNEW OR SHOULD HAVE KNOWN OF THE POSSIBILITY OF SUCH DAMAGES. BECAUSE SOME STATES OR JURISDICTIONS DO NOT ALLOW THE EXCLUSION OR THE LIMITATION OF LIABILITY FOR CONSEQUENTIAL OR INCIDENTAL DAMAGES, IN SUCH STATES OR JURISDICTIONS, OUR LIABILITY SHALL BE LIMITED TO THE EXTENT PERMITTED BY LAW. IF YOU ARE A CALIFORNIA RESIDENT, YOU WAIVE YOUR RIGHTS WITH RESPECT TO CALIFORNIA CIVIL CODE SECTION 1542, WHICH SAYS \"A GENERAL RELEASE DOES NOT EXTEND TO CLAIMS WHICH THE CREDITOR DOES NOT KNOW OR SUSPECT TO EXIST IN HIS FAVOR AT THE TIME OF EXECUTING THE RELEASE, WHICH, IF KNOWN BY HIM MUST HAVE MATERIALLY AFFECTED HIS SETTLEMENT WITH THE DEBTOR.\u201d Indemnification \u00b6 You agree to hold harmless and indemnify Cirrus Labs, and its subsidiaries, affiliates, officers, agents, employees, advertisers, licensors, suppliers or partners (collectively \"Cirrus Labs and Partners\") from and against any third party claim arising from or in any way related to (a) Your breach of the Terms, (b) Your use of the Service, \u00a9 Your violation of applicable laws, rules or regulations in connection with the Service, or (d) Your Customer Source Code, including any liability or expense arising from all claims, losses, damages (actual and consequential), suits, judgments, litigation costs and attorneys' fees, of every kind and nature. In such a case, Cirrus Labs will provide You with written notice of such claim, suit or action. Choice of Law and Dispute Resolution \u00b6 The Terms of Service shall be deemed to have been entered into and shall be construed and enforced in accordance with the laws of the State of New York as applied to contracts made and performed entirely within New York, without giving effect to any conflicts of law statutes. Any controversy, dispute or claim arising out of or related to the Terms of Service or the Service shall be settled by final and binding arbitration to be conducted by an arbitration tribunal in the State of New York and the County of New York, pursuant to the rules of the American Arbitration Association. Any and all disputes that you may have with Cirrus Labs shall be resolved individually, without resort to any form of class action. General Legal Terms \u00b6 The Terms constitute the whole legal agreement between You and Cirrus Labs and govern Your use of the Service and completely replace any prior agreements between You and Cirrus Labs in relation to the Service. If any part of the Terms of Service is held invalid or unenforceable, that portion shall be construed in a manner consistent with applicable law to reflect, as nearly as possible, the original intentions of the parties, and the remaining portions shall remain in full force and effect. The failure of Cirrus Labs to exercise or enforce any right or provision of the Terms of Service shall not constitute a waiver of such right or provision. The failure of either party to exercise in any respect any right provided for herein shall not be deemed a waiver of any further rights hereunder. You agree that if Cirrus Labs does not exercise or enforce any legal right or remedy which is contained in the Terms (or which Cirrus Labs has the benefit of under any applicable law), this will not be taken to be a formal waiver of Cirrus Labs' rights and that those rights or remedies will still be available to Cirrus Labs. Cirrus Labs shall not be liable for failing or delaying performance of its obligations resulting from any condition beyond its reasonable control, including but not limited to, governmental action, acts of terrorism, earthquake, fire, flood or other acts of God, labor conditions, power failures, and Internet disturbances. We may assign this contract at any time to any parent, subsidiary, or any affiliated company, or as part of the sale to, merger with, or other transfer of our company to another entity. This page was last updated on 02/03/2019.","title":"Terms of Service"},{"location":"legal/terms/#terms-of-service","text":"In addition to these Terms of Service, Cirrus Labs also has a Privacy Policy .","title":"Terms of Service"},{"location":"legal/terms/#the-gist","text":"Cirrus Labs Inc (\"Cirrus Labs\") operates the Cirrus CI service, which we hope you use. If you use it, please use it responsibly. If you don't, we'll have to terminate your subscription. For paid plans, you'll be charged on a monthly basis. You can cancel anytime, but there are no refunds. You own the source code that you provide to Cirrus CI and you're responsible for keeping it safe. The Terms of Service, the Cirrus CI Service, and our prices can change at any time. We'll warn you 30 days in advance of any price changes. We'll try to warn you about major changes to the Terms of Service or Cirrus CI, but we make no guarantees. That's the basic idea, but you must read through the entire Terms of Service below and agree with all the details before you use any of our websites or services (whether or not you have signed up).","title":"The Gist"},{"location":"legal/terms/#reuse","text":"This document is an adaptation of the Code Climate Terms of Service , which is an adaptation of the Heroku Terms of Service , which is turn an adaptation of the Google App Engine Terms of Service . The original work has been modified with permission under the Creative Commons Attribution 3.0 License . Neither Code Climate, Inc, nor Heroku, Inc. nor Google, Inc. is connected with and they do not sponsor or endorse Cirrus CI or its use of the work. You're welcome to adapt and use this document for your own needs. If you make an improvement, we'd appreciate it if you would let us know so we can consider improving our own document.","title":"Reuse"},{"location":"legal/terms/#your-agreement-with-cirrus-labs-inc","text":"Your use of the Cirrus CI Service is governed by this agreement (the \"Terms\"). The \"Service\" means the services Cirrus CI makes available include our web sites ( https://cirrus-ci.org/ , https://cirrus-ci.com/ ), our blog, our API, and any other software, sites, and services offered by Cirrus Labs in connection to any of those. \"Customer Source Code\" means any source code you directly or indirectly submit to Cirrus CI for the purpose of using the Service. \"Content\" means all content generated by Cirrus CI on your behalf (including metric data) and does not include Customer Source Code. In order to use the Service, You (the \"Customer\", \"You\", or \"Your\") must first agree to the Terms. You understand and agree that Cirrus Labs will treat Your use of the Service as acceptance of the Terms from that point onwards. Cirrus Labs may make changes to the Terms from time to time. You may reject the changes by terminating Your subscription. You understand and agree that if You use the Service after the date on which the Terms have changed, Cirrus Labs will treat Your use as acceptance of the updated Terms. If you have any question about the Terms, please contact us .","title":"Your Agreement with Cirrus Labs Inc"},{"location":"legal/terms/#your-cirrus-ci-user","text":"You may not use the Service if You are a person barred from receiving the Service under the laws of the United States or other countries, including the country in which You are resident or from which You use the Service. You may not use the service unless you are over the age of 13. You must be a human. Sign ups via automated methods are not permitted.","title":"Your Cirrus CI User"},{"location":"legal/terms/#use-of-the-service","text":"You must provide accurate and complete registration information any time You register to use the Service. You are responsible for the security of Your passwords and for any use of Your user. Your use of the Service must comply with all applicable laws, regulations and ordinances. You agree to not engage in any activity that interferes with or disrupts the Service. Cirrus Labs reserves the right to enforce quotas and usage limits (to any resources, including the API) at its sole discretion, with or without notice, which may result in Cirrus Labs disabling or throttling your usage of the Service for any amount of time. Shared users are forbidden unless you pay for all Git commit authors from the last 30 days.","title":"Use of the Service"},{"location":"legal/terms/#service-policies-and-privacy","text":"The Service shall be subject to the privacy policy for the Service available at Privacy Policy , hereby expressly into the Terms of Service by reference. You agree to the use of Your data in accordance with Cirrus CI's privacy policies.","title":"Service Policies and Privacy"},{"location":"legal/terms/#fees-for-use-of-the-service","text":"The Service may be provided to You without charge up with certain limits or for a certain \"trial\" period of time. All payments for use of the Service will go through GitHub according to GitHub Marketplace Terms of Service and GitHub Marketplace Developer Agreement . Cirrus Labs may change its fees and payment policies for the Service by notifying You at least thirty (30) days before the beginning of the billing cycle in which such change will take effect.","title":"Fees for Use of the Service"},{"location":"legal/terms/#cancellation-and-termination","text":"You must cancel your subscription via GitHub Marketplace with respect to GitHub Marketplace Terms of Service . You agree that Cirrus Labs, in its sole discretion and for any or no reason, may terminate or suspend Your subscription. You agree that any termination of Your access to the Service may be without prior notice, and You agree that Cirrus CI will not be liable to You or any third party for such termination.","title":"Cancellation and Termination"},{"location":"legal/terms/#customer-source-code","text":"Cirrus Labs claims no ownership or control over any Customer Source Code. You retain copyright and any other rights You already hold in the Customer Source Code and You are responsible for protecting those rights, as appropriate. You agree to assume full responsibility for configuring the Service to allow appropriate access to any Customer Source Code provided to the Service. You understand that private projects will display Customer Source Code to You and any collaborators that you designate for that project. You retain sole responsibility for any collaborators or third-party services that you allow to view Customer Source Code and entrust them at your own risk. Cirrus Labs is not responsible if you fail to configure, or misconfigure, your project and inadvertently allow unauthorized parties to view any Customer Source Code.","title":"Customer Source Code"},{"location":"legal/terms/#ideas-and-feedback","text":"You may choose to or we may invite You to submit comments or ideas about the Service, including but not limited to ideas about improving the Service or our products (\"Ideas\"). By submitting any Idea, You agree that Your disclosure is unsolicited and without restriction and will not place Cirrus Labs under any fiduciary or other obligation, and that we are free to use the Idea without any additional compensation to You, and/or to disclose the Idea on a non-confidential basis or otherwise to anyone.","title":"Ideas and Feedback"},{"location":"legal/terms/#modification-of-the-service","text":"You acknowledge and agree that the Service may change from time to time without prior notice to You. Changes include, without limitation, changes to fee and payment policies, security patches, added or removed functionality, and other enhancements or restrictions. Cirrus Labs shall not be liable to you or to any third party for any modification, price change, suspension or discontinuance of the Service.","title":"Modification of the Service"},{"location":"legal/terms/#external-resources","text":"The Service may include hyperlinks to other websites or content or resources or email content. You acknowledge and agree that Cirrus Labs is not responsible for the availability of any such external sites or resources, and does not endorse any advertising, products or other materials on or available from such web sites or resources.","title":"External Resources"},{"location":"legal/terms/#license-from-cirrus-ci-and-restrictions","text":"All of the content available on or through the Service, including without limitation, text, photographs, graphics, logos, trade/service marks, and/or audiovisual content, but expressly excluding Customer Source Code, is owned and/or controlled by Cirrus Labs, or other licensors or Service users and is protected, as applicable, by copyright, trademark, trade dress, patent, and trade secret laws, other proprietary rights, and international treaties. You acknowledge that the Service and any underlying technology or software used in connection with the Service contain our proprietary information. Subject to and conditioned upon your compliance with these Terms of Service, we grant to you a personal, worldwide, royalty-free, non-assignable and non-exclusive license to use the software provided to You by Cirrus Labs as part of the Service as provided to You by Cirrus Labs. This license is for the sole purpose of enabling You to use and enjoy the benefit of the Service as provided by Cirrus Labs, in the manner permitted by the Terms. You may not (and You may not permit anyone else to): (a) copy, modify, create a derivative work of, reverse engineer, decompile or otherwise attempt to extract the source code of the Service or any part thereof, unless this is expressly permitted or required by law, or unless You have been specifically told that You may do so by Cirrus Labs, in writing (e.g., through an open source software license); or (b) attempt to disable or circumvent any security mechanisms used by the Service. Open source software licenses for components of the Service released under an open source license constitute separate written agreements. To the limited extent that the open source software licenses expressly supersede these Terms of Service, the open source licenses govern Your agreement with Cirrus Labs for the use of the components of the Service released under an open source license. You may not use the Service in any manner that could damage, disable, overburden or impair our servers or networks, or interfere with any other users' use or enjoyment of the Service. You may not attempt to gain unauthorized access to any of the Service, member accounts, or computer systems or networks, through hacking, password mining or any other means. Without limiting anything else contained herein, you agree that you shall not (and you agree not to allow any third party to): remove any notices of copyright, trademark or other proprietary rights contained in/on or accessible through the Service or in any content or other material obtained via the Service; use any robot, spider, website search/retrieval application, or other automated device, process or means to access, retrieve or index any portion of the Service; reformat or frame any portion of the web pages that are part of the Service; use the Service for commercial purposes not permitted under these Terms; create users by automated means or under false or fraudulent pretenses; attempt to defeat any security or verification measure relating to the Service; provide or use tracking or monitoring functionality in connection with the Service, including, without limitation, to identify other users\u2019 actions or activities; impersonate or attempt to impersonate Cirrus Labs or any employee, contractor or associate of Cirrus Labs, or any other person or entity; or collect or store personal data about other users in connection with the prohibited activities described in this paragraph.","title":"License from Cirrus CI and Restrictions"},{"location":"legal/terms/#our-copyright-dispute-policy","text":"Cirrus Labs respects the intellectual property of others and requires that our users do the same. It is our policy to terminate the membership of repeat infringers. If you believe that material or content residing on or accessible through the Service infringes a copyright, please send a notice of copyright infringement containing the following information to the Designated Copyright Agent listed below: identification of the copyrighted work claimed to have been infringed, or, if multiple copyrighted works are covered by a single notification, a representative list of such works; identification of the claimed infringing material and information reasonably sufficient to permit us to locate the material on the Cirrus CI Service (providing the URL(s) of the claimed infringing material satisfies this requirement); information reasonably sufficient to permit us to contact you, such as an address, telephone number, and an email address; a statement by you that you have a good faith belief that the disputed use is not authorized by the copyright owner, its agent, or the law; a statement by you, made under penalty of perjury, that the above information in your notification is accurate and that you are the copyright owner or are authorized to act on the copyright owner's behalf; and your physical or electronic signature. Our Designated Copyright Agent for notification of claimed infringement can be reached by email at: hello@cirruslabs.org . The Service may contain advertisements and/or links to other websites (\u201cThird Party Sites\u201d). Cirrus Labs does not endorse, sanction or verify the accuracy or ownership of the information contained in/on any Third Party Site or any products or services advertised on Third Party Sites. If you decide to leave the Site and navigate to Third Party Sites, or install any software or download content from any such Third Party Sites, you do so at your own risk. Once you access a Third Party Site through a link on our Site, you may no longer be protected by these Terms of Service and you may be subject to the terms and conditions of such Third Party Site. You should review the applicable policies, including privacy and data gathering practices, of any Third Party Site to which you navigate from the Site, or relating to any software you use or install from a Third Party Site. Concerns regarding a Third Party Site should be directed to the Third Party Site itself. Cirrus CI bears no responsibility for any action associated with any Third Party Site.","title":"Our Copyright Dispute Policy"},{"location":"legal/terms/#disclaimer-of-warranties","text":"IF YOU ACCESS THE SERVICE, YOU DO SO AT YOUR OWN RISK. WE PROVIDE THE SERVICE \u201cAS IS\u201d, \u201cWITH ALL FAULTS\u201d AND \u201cAS AVAILABLE.\u201d WE MAKE NO EXPRESS OR IMPLIED WARRANTIES OR GUARANTEES ABOUT THE SERVICE. TO THE MAXIMUM EXTENT PERMITTED BY LAW, WE HEREBY DISCLAIM ALL SUCH WARRANTIES, INCLUDING ALL STATUTORY WARRANTIES, WITH RESPECT TO THE SERVICE, INCLUDING WITHOUT LIMITATION ANY WARRANTIES THAT THE SERVICE IS MERCHANTABLE, OF SATISFACTORY QUALITY, ACCURATE, FIT FOR A PARTICULAR PURPOSE OR NEED, OR NON-INFRINGING. WE DO NOT GUARANTEE THAT THE RESULTS THAT MAY BE OBTAINED FROM THE USE OF THE SERVICE WILL BE EFFECTIVE, RELIABLE OR ACCURATE OR WILL MEET YOUR REQUIREMENTS. WE DO NOT GUARANTEE THAT YOU WILL BE ABLE TO ACCESS OR USE THE SERVICE (EITHER DIRECTLY OR THROUGH THIRD-PARTY NETWORKS) AT TIMES OR LOCATIONS OF YOUR CHOOSING. WE ARE NOT RESPONSIBLE FOR THE ACCURACY, RELIABILITY, TIMELINESS OR COMPLETENESS OF INFORMATION PROVIDED BY ANY OTHER USERS OF THE SERVICE OR ANY OTHER DATA OR INFORMATION PROVIDED OR RECEIVED THROUGH THE SERVICE. EXCEPT AS EXPRESSLY SET FORTH HEREIN, CIRRUS LABS MAKES NO WARRANTIES ABOUT THE INFORMATION SYSTEMS, SOFTWARE AND FUNCTIONS MADE ACCESSIBLE BY OR THROUGH THE SERVICE OR ANY SECURITY ASSOCIATED WITH THE TRANSMISSION OF SENSITIVE INFORMATION. CIRRUS LABS DOES NOT WARRANT THAT THE SERVICE WILL OPERATE ERROR-FREE, THAT ERRORS IN THE SERVICE WILL BE FIXED, THAT LOSS OF DATA WILL NOT OCCUR, OR THAT THE SERVICE OR SOFTWARE ARE FREE OF COMPUTER VIRUSES, CONTAMINANTS OR OTHER HARMFUL ITEMS. UNDER NO CIRCUMSTANCES WILL CIRRUS LABS, ANY OF OUR AFFILIATES, DISTRIBUTORS, PARTNERS, LICENSORS, AND/OR ANY OF OUR OR THEIR DIRECTORS, OFFICERS, EMPLOYEES, CONSULTANTS, AGENTS, OR OTHER REPRESENTATIVES BE LIABLE FOR ANY LOSS OR DAMAGE CAUSED BY YOUR RELIANCE ON INFORMATION OBTAINED THROUGH THE SERVICE.","title":"Disclaimer of Warranties"},{"location":"legal/terms/#limitations-on-liability","text":"YOUR SOLE AND EXCLUSIVE REMEDY FOR ANY DISPUTE WITH US IS THE CANCELLATION OF YOUR REGISTRATION. IN NO EVENT SHALL OUR TOTAL CUMULATIVE LIABILITY TO YOU FOR ANY AND ALL CLAIMS RELATING TO OR ARISING OUT OF YOUR USE OF THE SERVICE, REGARDLESS OF THE FORM OF ACTION, EXCEED THE GREATER OF: (A) THE TOTAL AMOUNT OF FEES, IF ANY, THAT YOU PAID TO UTILIZE THE SERVICE OR (B) ONE HUNDRED DOLLARS ($100). IN NO EVENT SHALL WE BE LIABLE TO YOU (OR TO ANY THIRD PARTY CLAIMING UNDER OR THROUGH YOU) FOR ANY DIRECT, INDIRECT, SPECIAL, INCIDENTAL, CONSEQUENTIAL, PUNITIVE OR EXEMPLARY DAMAGES OR ANY BODILY INJURY, EMOTIONAL DISTRESS, DEATH OR ANY OTHER DAMAGES ARISING FROM YOUR USE OF OR INABILITY TO USE THE SERVICE, WHETHER ON-LINE OR OFF-LINE, OR OTHERWISE IN CONNECTION WITH THE SERVICE. THESE EXCLUSIONS APPLY TO ANY CLAIMS FOR LOST PROFITS, LOST DATA, LOSS OF GOODWILL OR BUSINESS REPUTATION, COST OF PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES, WORK STOPPAGE, COMPUTER FAILURE OR MALFUNCTION, ANY OTHER COMMERCIAL DAMAGES OR LOSSES, OR ANY PERSONAL INJURY OR PROPERTY DAMAGES, EVEN IF WE KNEW OR SHOULD HAVE KNOWN OF THE POSSIBILITY OF SUCH DAMAGES. BECAUSE SOME STATES OR JURISDICTIONS DO NOT ALLOW THE EXCLUSION OR THE LIMITATION OF LIABILITY FOR CONSEQUENTIAL OR INCIDENTAL DAMAGES, IN SUCH STATES OR JURISDICTIONS, OUR LIABILITY SHALL BE LIMITED TO THE EXTENT PERMITTED BY LAW. IF YOU ARE A CALIFORNIA RESIDENT, YOU WAIVE YOUR RIGHTS WITH RESPECT TO CALIFORNIA CIVIL CODE SECTION 1542, WHICH SAYS \"A GENERAL RELEASE DOES NOT EXTEND TO CLAIMS WHICH THE CREDITOR DOES NOT KNOW OR SUSPECT TO EXIST IN HIS FAVOR AT THE TIME OF EXECUTING THE RELEASE, WHICH, IF KNOWN BY HIM MUST HAVE MATERIALLY AFFECTED HIS SETTLEMENT WITH THE DEBTOR.\u201d","title":"Limitations on Liability"},{"location":"legal/terms/#indemnification","text":"You agree to hold harmless and indemnify Cirrus Labs, and its subsidiaries, affiliates, officers, agents, employees, advertisers, licensors, suppliers or partners (collectively \"Cirrus Labs and Partners\") from and against any third party claim arising from or in any way related to (a) Your breach of the Terms, (b) Your use of the Service, \u00a9 Your violation of applicable laws, rules or regulations in connection with the Service, or (d) Your Customer Source Code, including any liability or expense arising from all claims, losses, damages (actual and consequential), suits, judgments, litigation costs and attorneys' fees, of every kind and nature. In such a case, Cirrus Labs will provide You with written notice of such claim, suit or action.","title":"Indemnification"},{"location":"legal/terms/#choice-of-law-and-dispute-resolution","text":"The Terms of Service shall be deemed to have been entered into and shall be construed and enforced in accordance with the laws of the State of New York as applied to contracts made and performed entirely within New York, without giving effect to any conflicts of law statutes. Any controversy, dispute or claim arising out of or related to the Terms of Service or the Service shall be settled by final and binding arbitration to be conducted by an arbitration tribunal in the State of New York and the County of New York, pursuant to the rules of the American Arbitration Association. Any and all disputes that you may have with Cirrus Labs shall be resolved individually, without resort to any form of class action.","title":"Choice of Law and Dispute Resolution"},{"location":"legal/terms/#general-legal-terms","text":"The Terms constitute the whole legal agreement between You and Cirrus Labs and govern Your use of the Service and completely replace any prior agreements between You and Cirrus Labs in relation to the Service. If any part of the Terms of Service is held invalid or unenforceable, that portion shall be construed in a manner consistent with applicable law to reflect, as nearly as possible, the original intentions of the parties, and the remaining portions shall remain in full force and effect. The failure of Cirrus Labs to exercise or enforce any right or provision of the Terms of Service shall not constitute a waiver of such right or provision. The failure of either party to exercise in any respect any right provided for herein shall not be deemed a waiver of any further rights hereunder. You agree that if Cirrus Labs does not exercise or enforce any legal right or remedy which is contained in the Terms (or which Cirrus Labs has the benefit of under any applicable law), this will not be taken to be a formal waiver of Cirrus Labs' rights and that those rights or remedies will still be available to Cirrus Labs. Cirrus Labs shall not be liable for failing or delaying performance of its obligations resulting from any condition beyond its reasonable control, including but not limited to, governmental action, acts of terrorism, earthquake, fire, flood or other acts of God, labor conditions, power failures, and Internet disturbances. We may assign this contract at any time to any parent, subsidiary, or any affiliated company, or as part of the sale to, merger with, or other transfer of our company to another entity. This page was last updated on 02/03/2019.","title":"General Legal Terms"}]}